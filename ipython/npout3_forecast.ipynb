{
 "metadata": {
  "name": "",
  "signature": "sha256:6df4cc0cd3d8ac0d64e30f09a57370f2927ea8ec475398611a52507185095e0c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "pd.set_option(\"display.max_columns\", 300)\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('../../MB_PCUST_NPOUT_TRAIN.txt', encoding='utf-8', header=1, sep='\\t', names=['C'+str(i+1) for i in xrange(215)], na_values=['?'])\n",
      "\n",
      "#df = pd.read_csv('../../MB_PCUST_NPOUT_EXAM.txt', encoding='utf-8', sep='\\t', names=['C2']+['C'+str(i+4) for i in xrange(212)], na_values=['?'])\n",
      "#df['C3'] = df['C24'].map(lambda x: 'Y' if x>0 else 'N')\n",
      "#del df['C2']\n",
      "\n",
      "#df = df.loc[df['C1']==7]\n",
      "#df = pd.concat([df.loc[df['C3']=='N'].sample(20000*3/4), df.loc[df['C3']=='Y'].sample(20000*1/4)])\n",
      "df = df.sample(10000)\n",
      "del df['C1']\n",
      "del df['C2']\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C3</th>\n",
        "      <th>C4</th>\n",
        "      <th>C5</th>\n",
        "      <th>C6</th>\n",
        "      <th>C7</th>\n",
        "      <th>C8</th>\n",
        "      <th>C9</th>\n",
        "      <th>C10</th>\n",
        "      <th>C11</th>\n",
        "      <th>C12</th>\n",
        "      <th>C13</th>\n",
        "      <th>C14</th>\n",
        "      <th>C15</th>\n",
        "      <th>C16</th>\n",
        "      <th>C17</th>\n",
        "      <th>C18</th>\n",
        "      <th>C19</th>\n",
        "      <th>C20</th>\n",
        "      <th>C21</th>\n",
        "      <th>C22</th>\n",
        "      <th>C23</th>\n",
        "      <th>C24</th>\n",
        "      <th>C25</th>\n",
        "      <th>C26</th>\n",
        "      <th>C27</th>\n",
        "      <th>C28</th>\n",
        "      <th>C29</th>\n",
        "      <th>C30</th>\n",
        "      <th>C31</th>\n",
        "      <th>C32</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C35</th>\n",
        "      <th>C36</th>\n",
        "      <th>C37</th>\n",
        "      <th>C38</th>\n",
        "      <th>C39</th>\n",
        "      <th>C40</th>\n",
        "      <th>C41</th>\n",
        "      <th>C42</th>\n",
        "      <th>C43</th>\n",
        "      <th>C44</th>\n",
        "      <th>C45</th>\n",
        "      <th>C46</th>\n",
        "      <th>C47</th>\n",
        "      <th>C48</th>\n",
        "      <th>C49</th>\n",
        "      <th>C50</th>\n",
        "      <th>C51</th>\n",
        "      <th>C52</th>\n",
        "      <th>C53</th>\n",
        "      <th>C54</th>\n",
        "      <th>C55</th>\n",
        "      <th>C56</th>\n",
        "      <th>C57</th>\n",
        "      <th>C58</th>\n",
        "      <th>C59</th>\n",
        "      <th>C60</th>\n",
        "      <th>C61</th>\n",
        "      <th>C62</th>\n",
        "      <th>C63</th>\n",
        "      <th>C64</th>\n",
        "      <th>C65</th>\n",
        "      <th>C66</th>\n",
        "      <th>C67</th>\n",
        "      <th>C68</th>\n",
        "      <th>C69</th>\n",
        "      <th>C70</th>\n",
        "      <th>C71</th>\n",
        "      <th>C72</th>\n",
        "      <th>C73</th>\n",
        "      <th>C74</th>\n",
        "      <th>C75</th>\n",
        "      <th>C76</th>\n",
        "      <th>C77</th>\n",
        "      <th>C78</th>\n",
        "      <th>C79</th>\n",
        "      <th>C80</th>\n",
        "      <th>C81</th>\n",
        "      <th>C82</th>\n",
        "      <th>C83</th>\n",
        "      <th>C84</th>\n",
        "      <th>C85</th>\n",
        "      <th>C86</th>\n",
        "      <th>C87</th>\n",
        "      <th>C88</th>\n",
        "      <th>C89</th>\n",
        "      <th>C90</th>\n",
        "      <th>C91</th>\n",
        "      <th>C92</th>\n",
        "      <th>C93</th>\n",
        "      <th>C94</th>\n",
        "      <th>C95</th>\n",
        "      <th>C96</th>\n",
        "      <th>C97</th>\n",
        "      <th>C98</th>\n",
        "      <th>C99</th>\n",
        "      <th>C100</th>\n",
        "      <th>C101</th>\n",
        "      <th>C102</th>\n",
        "      <th>C103</th>\n",
        "      <th>C104</th>\n",
        "      <th>C105</th>\n",
        "      <th>C106</th>\n",
        "      <th>C107</th>\n",
        "      <th>C108</th>\n",
        "      <th>C109</th>\n",
        "      <th>C110</th>\n",
        "      <th>C111</th>\n",
        "      <th>C112</th>\n",
        "      <th>C113</th>\n",
        "      <th>C114</th>\n",
        "      <th>C115</th>\n",
        "      <th>C116</th>\n",
        "      <th>C117</th>\n",
        "      <th>C118</th>\n",
        "      <th>C119</th>\n",
        "      <th>C120</th>\n",
        "      <th>C121</th>\n",
        "      <th>C122</th>\n",
        "      <th>C123</th>\n",
        "      <th>C124</th>\n",
        "      <th>C125</th>\n",
        "      <th>C126</th>\n",
        "      <th>C127</th>\n",
        "      <th>C128</th>\n",
        "      <th>C129</th>\n",
        "      <th>C130</th>\n",
        "      <th>C131</th>\n",
        "      <th>C132</th>\n",
        "      <th>C133</th>\n",
        "      <th>C134</th>\n",
        "      <th>C135</th>\n",
        "      <th>C136</th>\n",
        "      <th>C137</th>\n",
        "      <th>C138</th>\n",
        "      <th>C139</th>\n",
        "      <th>C140</th>\n",
        "      <th>C141</th>\n",
        "      <th>C142</th>\n",
        "      <th>C143</th>\n",
        "      <th>C144</th>\n",
        "      <th>C145</th>\n",
        "      <th>C146</th>\n",
        "      <th>C147</th>\n",
        "      <th>C148</th>\n",
        "      <th>C149</th>\n",
        "      <th>C150</th>\n",
        "      <th>C151</th>\n",
        "      <th>C152</th>\n",
        "      <th>C153</th>\n",
        "      <th>C154</th>\n",
        "      <th>C155</th>\n",
        "      <th>C156</th>\n",
        "      <th>C157</th>\n",
        "      <th>C158</th>\n",
        "      <th>C159</th>\n",
        "      <th>C160</th>\n",
        "      <th>C161</th>\n",
        "      <th>C162</th>\n",
        "      <th>C163</th>\n",
        "      <th>C164</th>\n",
        "      <th>C165</th>\n",
        "      <th>C166</th>\n",
        "      <th>C167</th>\n",
        "      <th>C168</th>\n",
        "      <th>C169</th>\n",
        "      <th>C170</th>\n",
        "      <th>C171</th>\n",
        "      <th>C172</th>\n",
        "      <th>C173</th>\n",
        "      <th>C174</th>\n",
        "      <th>C175</th>\n",
        "      <th>C176</th>\n",
        "      <th>C177</th>\n",
        "      <th>C178</th>\n",
        "      <th>C179</th>\n",
        "      <th>C180</th>\n",
        "      <th>C181</th>\n",
        "      <th>C182</th>\n",
        "      <th>C183</th>\n",
        "      <th>C184</th>\n",
        "      <th>C185</th>\n",
        "      <th>C186</th>\n",
        "      <th>C187</th>\n",
        "      <th>C188</th>\n",
        "      <th>C189</th>\n",
        "      <th>C190</th>\n",
        "      <th>C191</th>\n",
        "      <th>C192</th>\n",
        "      <th>C193</th>\n",
        "      <th>C194</th>\n",
        "      <th>C195</th>\n",
        "      <th>C196</th>\n",
        "      <th>C197</th>\n",
        "      <th>C198</th>\n",
        "      <th>C199</th>\n",
        "      <th>C200</th>\n",
        "      <th>C201</th>\n",
        "      <th>C202</th>\n",
        "      <th>C203</th>\n",
        "      <th>C204</th>\n",
        "      <th>C205</th>\n",
        "      <th>C206</th>\n",
        "      <th>C207</th>\n",
        "      <th>C208</th>\n",
        "      <th>C209</th>\n",
        "      <th>C210</th>\n",
        "      <th>C211</th>\n",
        "      <th>C212</th>\n",
        "      <th>C213</th>\n",
        "      <th>C214</th>\n",
        "      <th>C215</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>47078</th>\n",
        "      <td>Y</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>45.0</td>\n",
        "      <td>\u5c04\u624b\u5ea7</td>\n",
        "      <td>58</td>\n",
        "      <td>\u64da\u9ede16</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u7121\u7d81\u7d04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>5</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>23.01</td>\n",
        "      <td>11.98</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.61</td>\n",
        "      <td>2.42</td>\n",
        "      <td>0.0</td>\n",
        "      <td>7.23</td>\n",
        "      <td>1.38</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.52</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.37</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.31</td>\n",
        "      <td>0.06</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.70</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.93</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>6.32</td>\n",
        "      <td>7.15</td>\n",
        "      <td>6.33</td>\n",
        "      <td>0.58</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.08</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.27</td>\n",
        "      <td>0.31</td>\n",
        "      <td>0.27</td>\n",
        "      <td>0.03</td>\n",
        "      <td>\u6843\u5712\u7e23</td>\n",
        "      <td>\u694a\u6885\u5e02</td>\n",
        "      <td>\u65b0\u7af9\u7e23</td>\n",
        "      <td>\u7af9\u5317\u5e02</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>84.0</td>\n",
        "      <td>55.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>203.856</td>\n",
        "      <td>18.964</td>\n",
        "      <td>125.208</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>23.02</td>\n",
        "      <td>11.98</td>\n",
        "      <td>8.61</td>\n",
        "      <td>2.42</td>\n",
        "      <td>2.42</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.98</td>\n",
        "      <td>42.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14.40</td>\n",
        "      <td>11.98</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.42</td>\n",
        "      <td>0.83</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.17</td>\n",
        "      <td>42.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>33.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>15.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>67364</th>\n",
        "      <td>Y</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>59.0</td>\n",
        "      <td>\u9b54\u7faf\u5ea7</td>\n",
        "      <td>230</td>\n",
        "      <td>\u64da\u9ede03</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-28.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>1.156119e+05</td>\n",
        "      <td>9.40</td>\n",
        "      <td>7.33</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.07</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.07</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.78</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.20</td>\n",
        "      <td>2.80</td>\n",
        "      <td>0.40</td>\n",
        "      <td>2.93</td>\n",
        "      <td>1.43</td>\n",
        "      <td>0.13</td>\n",
        "      <td>1.50</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.30</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.31</td>\n",
        "      <td>0.15</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.16</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u65b0\u5317\u5e02</td>\n",
        "      <td>\u677f\u6a4b\u5340</td>\n",
        "      <td>\u65b0\u5317\u5e02</td>\n",
        "      <td>\u677f\u6a4b\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>282.0</td>\n",
        "      <td>63.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>462.090</td>\n",
        "      <td>193.995</td>\n",
        "      <td>199.062</td>\n",
        "      <td>0.0</td>\n",
        "      <td>23.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>231987.0</td>\n",
        "      <td>6689085.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>22528693.0</td>\n",
        "      <td>766535.0</td>\n",
        "      <td>74604993.0</td>\n",
        "      <td>12621712.0</td>\n",
        "      <td>14495936.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>36638061.0</td>\n",
        "      <td>29621868.0</td>\n",
        "      <td>43412132.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1334988.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.168564e+07</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.959580e+07</td>\n",
        "      <td>1.789259e+07</td>\n",
        "      <td>1.028161e+07</td>\n",
        "      <td>0.0</td>\n",
        "      <td>51724080.0</td>\n",
        "      <td>303701451.0</td>\n",
        "      <td>45980803.0</td>\n",
        "      <td>9.40</td>\n",
        "      <td>7.34</td>\n",
        "      <td>2.07</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>7.34</td>\n",
        "      <td>14.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>7.33</td>\n",
        "      <td>7.33</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>14.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>6.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>104.0</td>\n",
        "      <td>16383.008789</td>\n",
        "      <td>0.141707</td>\n",
        "      <td>104.0</td>\n",
        "      <td>1.183866e+08</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>76156</th>\n",
        "      <td>N</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>40.0</td>\n",
        "      <td>\u5929\u79e4\u5ea7</td>\n",
        "      <td>167</td>\n",
        "      <td>\u64da\u9ede13</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d\u9ad8</td>\n",
        "      <td>4G</td>\n",
        "      <td>1336.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-68.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>1.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>1.650420e+07</td>\n",
        "      <td>199.41</td>\n",
        "      <td>44.57</td>\n",
        "      <td>0.0</td>\n",
        "      <td>117.01</td>\n",
        "      <td>24.40</td>\n",
        "      <td>0.0</td>\n",
        "      <td>32.78</td>\n",
        "      <td>78.48</td>\n",
        "      <td>1.35</td>\n",
        "      <td>4.4</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.59</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.16</td>\n",
        "      <td>0.39</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.90</td>\n",
        "      <td>14.07</td>\n",
        "      <td>26.53</td>\n",
        "      <td>17.15</td>\n",
        "      <td>21.25</td>\n",
        "      <td>58.13</td>\n",
        "      <td>22.88</td>\n",
        "      <td>21.50</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.09</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.09</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.29</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u82d7\u6817\u7e23</td>\n",
        "      <td>\u7af9\u5357\u93ae</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>88.0</td>\n",
        "      <td>58.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>234.866</td>\n",
        "      <td>144.920</td>\n",
        "      <td>59.150</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>21.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>29.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>20.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>26.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>21.0</td>\n",
        "      <td>206580961.0</td>\n",
        "      <td>284888425.0</td>\n",
        "      <td>151814762.0</td>\n",
        "      <td>373630597.0</td>\n",
        "      <td>9543589.0</td>\n",
        "      <td>476953561.0</td>\n",
        "      <td>331526689.0</td>\n",
        "      <td>322410805.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.090888e+09</td>\n",
        "      <td>174538590.0</td>\n",
        "      <td>513340527.0</td>\n",
        "      <td>1.160692e+09</td>\n",
        "      <td>10490604.0</td>\n",
        "      <td>1.875277e+09</td>\n",
        "      <td>1.325382e+09</td>\n",
        "      <td>2.653526e+09</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>199.42</td>\n",
        "      <td>44.57</td>\n",
        "      <td>117.01</td>\n",
        "      <td>24.40</td>\n",
        "      <td>24.40</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>58.00</td>\n",
        "      <td>165.0</td>\n",
        "      <td>56.0</td>\n",
        "      <td>89.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>45.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>45.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>16.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>68.97</td>\n",
        "      <td>44.56</td>\n",
        "      <td>0.0</td>\n",
        "      <td>24.41</td>\n",
        "      <td>0.65</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.35</td>\n",
        "      <td>165.0</td>\n",
        "      <td>56.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>89.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>34.0</td>\n",
        "      <td>49.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>74.0</td>\n",
        "      <td>56.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>91.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>200.0</td>\n",
        "      <td>905435.687500</td>\n",
        "      <td>0.054861</td>\n",
        "      <td>200.0</td>\n",
        "      <td>1.690030e+10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19985</th>\n",
        "      <td>N</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>18.0</td>\n",
        "      <td>\u8655\u5973\u5ea7</td>\n",
        "      <td>170</td>\n",
        "      <td>\u64da\u9ede03</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>983.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-52.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u4e2d\u9ad8</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>5.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>113.84</td>\n",
        "      <td>88.63</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14.01</td>\n",
        "      <td>11.20</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.08</td>\n",
        "      <td>8.63</td>\n",
        "      <td>2.30</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.78</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.10</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.08</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>3.13</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.57</td>\n",
        "      <td>2.90</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>10.65</td>\n",
        "      <td>11.90</td>\n",
        "      <td>21.42</td>\n",
        "      <td>12.42</td>\n",
        "      <td>48.87</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.09</td>\n",
        "      <td>0.10</td>\n",
        "      <td>0.19</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.43</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>113.85</td>\n",
        "      <td>88.63</td>\n",
        "      <td>14.01</td>\n",
        "      <td>11.20</td>\n",
        "      <td>11.20</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>88.63</td>\n",
        "      <td>63.0</td>\n",
        "      <td>45.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>99.83</td>\n",
        "      <td>88.63</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.20</td>\n",
        "      <td>0.89</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.11</td>\n",
        "      <td>63.0</td>\n",
        "      <td>45.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>51.0</td>\n",
        "      <td>45.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>18.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>109868</th>\n",
        "      <td>N</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>47.0</td>\n",
        "      <td>\u8655\u5973\u5ea7</td>\n",
        "      <td>197</td>\n",
        "      <td>\u64da\u9ede02</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>4G</td>\n",
        "      <td>436.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>3.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>4</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Yes</td>\n",
        "      <td>No</td>\n",
        "      <td>2.735482e+05</td>\n",
        "      <td>110.53</td>\n",
        "      <td>100.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.20</td>\n",
        "      <td>0.33</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.70</td>\n",
        "      <td>1.50</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.90</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.09</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.08</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>48.07</td>\n",
        "      <td>53.18</td>\n",
        "      <td>5.52</td>\n",
        "      <td>1.25</td>\n",
        "      <td>0.35</td>\n",
        "      <td>1.25</td>\n",
        "      <td>0.92</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.43</td>\n",
        "      <td>0.48</td>\n",
        "      <td>0.05</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u57fa\u9686\u5e02</td>\n",
        "      <td>\u4fe1\u7fa9\u5340</td>\n",
        "      <td>\u57fa\u9686\u5e02</td>\n",
        "      <td>\u4fe1\u7fa9\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>227.0</td>\n",
        "      <td>111.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>37888822.0</td>\n",
        "      <td>1962207.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>592203.0</td>\n",
        "      <td>7501.0</td>\n",
        "      <td>52864.0</td>\n",
        "      <td>21166211.0</td>\n",
        "      <td>240012.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>96337.0</td>\n",
        "      <td>827232.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.733650e+05</td>\n",
        "      <td>867633.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.465448e+06</td>\n",
        "      <td>202330.0</td>\n",
        "      <td>7.975380e+05</td>\n",
        "      <td>3.548772e+07</td>\n",
        "      <td>6.666390e+05</td>\n",
        "      <td>0.0</td>\n",
        "      <td>663845.0</td>\n",
        "      <td>15018366.0</td>\n",
        "      <td>82348.0</td>\n",
        "      <td>110.53</td>\n",
        "      <td>100.00</td>\n",
        "      <td>10.20</td>\n",
        "      <td>0.33</td>\n",
        "      <td>0.33</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.00</td>\n",
        "      <td>22.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>100.33</td>\n",
        "      <td>100.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.33</td>\n",
        "      <td>1.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>22.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>162.0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>162.0</td>\n",
        "      <td>2.801133e+08</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "       C3    C4 C5    C6   C7   C8    C9 C10 C11 C12     C13  C14   C15  C16  \\\n",
        "47078   Y  NVIP  F  45.0  \u5c04\u624b\u5ea7   58  \u64da\u9ede16   N  \u6975\u4f4e  3G   183.0  \u7121\u7d81\u7d04   NaN  0.0   \n",
        "67364   Y  NVIP  M  59.0  \u9b54\u7faf\u5ea7  230  \u64da\u9ede03   N   \u4f4e  3G   183.0  \u901a\u4fe1\u7d04 -28.0  1.0   \n",
        "76156   N  NVIP  M  40.0  \u5929\u79e4\u5ea7  167  \u64da\u9ede13   N  \u4e2d\u9ad8  4G  1336.0  \u8cfc\u6a5f\u7d04 -68.0  9.0   \n",
        "19985   N  NVIP  M  18.0  \u8655\u5973\u5ea7  170  \u64da\u9ede03   N   \u4f4e  3G   983.0  \u901a\u4fe1\u7d04 -52.0  1.0   \n",
        "109868  N  NVIP  M  47.0  \u8655\u5973\u5ea7  197  \u64da\u9ede02   N  \u6975\u4f4e  4G   436.0  \u901a\u4fe1\u7d04  -2.0  2.0   \n",
        "\n",
        "        C17 C18 C19  C20  C21  C22 C23  C24  C25  C26  C27  C28  C29  C30  \\\n",
        "47078   0.0  \u96f6\u5143  \u96f6\u5143  NaN  NaN  \u7af6\u696dA   N    1  NaN  NaN  1.0    1  NaN  NaN   \n",
        "67364   1.0  \u4f4e\u4e2d  \u4f4e\u4e2d  1.0  1.0  \u7af6\u696dA   N    1  NaN  NaN  1.0    1  NaN  NaN   \n",
        "76156   8.0  \u4f4e\u4e2d  \u96f6\u5143  1.0  6.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "19985   2.0  \u4e2d\u9ad8  \u4f4e\u4e2d  5.0  1.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "109868  2.0  \u4f4e\u4e2d  \u4f4e\u4e2d  3.0  1.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "\n",
        "        C31  C32  C33  C34  C35  C36  C37  C38  C39  C40  C41  C42  C43  C44  \\\n",
        "47078   \u7121NP  NaN  NaN  NaN    5    3    0    1    0    0    1    0    2  NaN   \n",
        "67364   \u7121NP  NaN  NaN  NaN    2    1    0    1    0    0    0    0    1  NaN   \n",
        "76156   \u7121NP  NaN  NaN  NaN    3    1    1    1    0    0    0    0    1  NaN   \n",
        "19985   \u7121NP  NaN  NaN  NaN    1    1    0    0    0    0    0    0    1  NaN   \n",
        "109868  \u7121NP  NaN  NaN  NaN    8    4    1    1    0    1    1    0    4  NaN   \n",
        "\n",
        "        C45 C46           C47     C48     C49  C50     C51    C52  C53    C54  \\\n",
        "47078   NaN  No           NaN   23.01   11.98  0.0    8.61   2.42  0.0   7.23   \n",
        "67364   NaN  No  1.156119e+05    9.40    7.33  0.0    2.07   0.00  0.0   2.07   \n",
        "76156   NaN  No  1.650420e+07  199.41   44.57  0.0  117.01  24.40  0.0  32.78   \n",
        "19985   NaN  No           NaN  113.84   88.63  0.0   14.01  11.20  0.0   3.08   \n",
        "109868  Yes  No  2.735482e+05  110.53  100.00  0.0   10.20   0.33  0.0   8.70   \n",
        "\n",
        "          C55   C56  C57   C58  C59   C60   C61  C62   C63   C64   C65   C66  \\\n",
        "47078    1.38  0.00  0.0  0.52  0.0  0.37  0.11  0.0  0.00  0.31  0.06  0.00   \n",
        "67364    0.00  0.00  0.0  0.78  0.0  0.22  0.00  0.0  0.00  0.22  0.00  0.00   \n",
        "76156   78.48  1.35  4.4  0.22  0.0  0.59  0.12  0.0  0.07  0.16  0.39  0.01   \n",
        "19985    8.63  2.30  0.0  0.78  0.0  0.12  0.10  0.0  0.00  0.03  0.08  0.02   \n",
        "109868   1.50  0.00  0.0  0.90  0.0  0.09  0.00  0.0  0.00  0.08  0.01  0.00   \n",
        "\n",
        "         C67   C68  C69  C70    C71    C72    C73    C74    C75    C76    C77  \\\n",
        "47078   0.00  0.00  0.0  0.0   0.70   0.00   1.93   0.00   0.00   6.32   7.15   \n",
        "67364   0.00  0.00  0.0  0.0   0.00   0.20   2.80   0.40   2.93   1.43   0.13   \n",
        "76156   0.02  0.00  0.0  0.0  17.90  14.07  26.53  17.15  21.25  58.13  22.88   \n",
        "19985   0.00  3.13  0.0  0.0   2.57   2.90   0.00   0.00  10.65  11.90  21.42   \n",
        "109868  0.00  0.00  0.0  0.0   0.00  48.07  53.18   5.52   1.25   0.35   1.25   \n",
        "\n",
        "          C78    C79   C80  C81  C82   C83   C84   C85   C86   C87   C88  \\\n",
        "47078    6.33   0.58  0.00  0.0  0.0  0.03  0.00  0.08  0.00  0.00  0.27   \n",
        "67364    1.50   0.00  0.00  0.0  0.0  0.00  0.02  0.30  0.04  0.31  0.15   \n",
        "76156   21.50   0.00  0.00  0.0  0.0  0.09  0.07  0.13  0.09  0.11  0.29   \n",
        "19985   12.42  48.87  0.03  0.0  0.0  0.02  0.03  0.00  0.00  0.09  0.10   \n",
        "109868   0.92   0.00  0.00  0.0  0.0  0.00  0.43  0.48  0.05  0.01  0.00   \n",
        "\n",
        "         C89   C90   C91  C92  C93  C94  C95 C96 C97  C98  C99   C100   C101  \\\n",
        "47078   0.31  0.27  0.03  \u6843\u5712\u7e23  \u694a\u6885\u5e02  \u65b0\u7af9\u7e23  \u7af9\u5317\u5e02  No  No  1.0  0.0   84.0   55.0   \n",
        "67364   0.01  0.16  0.00  \u65b0\u5317\u5e02  \u677f\u6a4b\u5340  \u65b0\u5317\u5e02  \u677f\u6a4b\u5340  No  No  0.0  1.0  282.0   63.0   \n",
        "76156   0.11  0.11  0.00  \u82d7\u6817\u7e23  \u7af9\u5357\u93ae   \\N   \\N  No  No  0.0  0.0   88.0   58.0   \n",
        "19985   0.19  0.11  0.43  NaN  NaN  NaN  NaN  No  No  NaN  NaN    NaN    NaN   \n",
        "109868  0.01  0.01  0.00  \u57fa\u9686\u5e02  \u4fe1\u7fa9\u5340  \u57fa\u9686\u5e02  \u4fe1\u7fa9\u5340  No  No  0.0  0.0  227.0  111.0   \n",
        "\n",
        "        C102     C103     C104     C105  C106  C107  C108  C109  C110  C111  \\\n",
        "47078    0.0  203.856   18.964  125.208   0.0   0.0   0.0   0.0   0.0   0.0   \n",
        "67364    0.0  462.090  193.995  199.062   0.0  23.0   0.0   0.0   0.0   0.0   \n",
        "76156    0.0  234.866  144.920   59.150   0.0   1.0   0.0   0.0   0.0   8.0   \n",
        "19985    NaN      NaN      NaN      NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "109868   0.0    0.000    0.000    0.000   0.0   0.0   0.0   0.0   0.0   0.0   \n",
        "\n",
        "        C112  C113  C114  C115  C116  C117  C118  C119  C120  C121  C122  \\\n",
        "47078    0.0   0.0   0.0   2.0   0.0   1.0   0.0  11.0  13.0   0.0   1.0   \n",
        "67364    0.0   2.0   2.0   3.0   0.0   0.0   1.0   2.0   1.0   0.0   0.0   \n",
        "76156   13.0  21.0  14.0  29.0   8.0  20.0  10.0  17.0  26.0  18.0  21.0   \n",
        "19985    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "109868   0.0   1.0   0.0   5.0   3.0   0.0   7.0   2.0   5.0   0.0   0.0   \n",
        "\n",
        "               C123         C124         C125         C126       C127  \\\n",
        "47078           0.0          0.0          0.0          0.0        0.0   \n",
        "67364      231987.0    6689085.0          0.0   22528693.0   766535.0   \n",
        "76156   206580961.0  284888425.0  151814762.0  373630597.0  9543589.0   \n",
        "19985           NaN          NaN          NaN          NaN        NaN   \n",
        "109868   37888822.0    1962207.0          0.0     592203.0     7501.0   \n",
        "\n",
        "               C128         C129         C130  C131        C132        C133  \\\n",
        "47078           0.0          0.0          0.0   0.0         0.0         0.0   \n",
        "67364    74604993.0   12621712.0   14495936.0   0.0  36638061.0  29621868.0   \n",
        "76156   476953561.0  331526689.0  322410805.0   0.0         0.0         0.0   \n",
        "19985           NaN          NaN          NaN   NaN         NaN         NaN   \n",
        "109868      52864.0   21166211.0     240012.0   0.0     96337.0    827232.0   \n",
        "\n",
        "              C134          C135         C136         C137          C138  \\\n",
        "47078          0.0  0.000000e+00          0.0          0.0  0.000000e+00   \n",
        "67364   43412132.0  0.000000e+00    1334988.0          0.0  8.168564e+07   \n",
        "76156          0.0  1.090888e+09  174538590.0  513340527.0  1.160692e+09   \n",
        "19985          NaN           NaN          NaN          NaN           NaN   \n",
        "109868         0.0  6.733650e+05     867633.0          0.0  2.465448e+06   \n",
        "\n",
        "              C139          C140          C141          C142  C143  \\\n",
        "47078          0.0  0.000000e+00  0.000000e+00  0.000000e+00   0.0   \n",
        "67364          0.0  5.959580e+07  1.789259e+07  1.028161e+07   0.0   \n",
        "76156   10490604.0  1.875277e+09  1.325382e+09  2.653526e+09   0.0   \n",
        "19985          NaN           NaN           NaN           NaN   NaN   \n",
        "109868    202330.0  7.975380e+05  3.548772e+07  6.666390e+05   0.0   \n",
        "\n",
        "              C144         C145        C146    C147    C148    C149   C150  \\\n",
        "47078          0.0          0.0         0.0   23.02   11.98    8.61   2.42   \n",
        "67364   51724080.0  303701451.0  45980803.0    9.40    7.34    2.07   0.00   \n",
        "76156          0.0          0.0         0.0  199.42   44.57  117.01  24.40   \n",
        "19985          NaN          NaN         NaN  113.85   88.63   14.01  11.20   \n",
        "109868    663845.0   15018366.0     82348.0  110.53  100.00   10.20   0.33   \n",
        "\n",
        "         C151  C152  C153    C154   C155  C156  C157  C158  C159  C160  C161  \\\n",
        "47078    2.42   0.0   0.0   11.98   42.0  19.0   9.0  14.0  14.0   0.0   0.0   \n",
        "67364    0.00   0.0   0.0    7.34   14.0  10.0   4.0   0.0   0.0   0.0   0.0   \n",
        "76156   24.40   0.0   0.0   58.00  165.0  56.0  89.0  18.0  18.0   0.0   0.0   \n",
        "19985   11.20   0.0   0.0   88.63   63.0  45.0  12.0   6.0   6.0   0.0   0.0   \n",
        "109868   0.33   0.0   0.0  100.00   22.0  12.0   9.0   1.0   1.0   0.0   0.0   \n",
        "\n",
        "        C162  C163  C164  C165  C166  C167  C168  C169  C170  C171  C172  \\\n",
        "47078    9.0   3.0   0.0   4.0   2.0   0.0   3.0   1.0   0.0   0.0   0.0   \n",
        "67364    9.0   7.0   0.0   2.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   \n",
        "76156   45.0  19.0   0.0  16.0   9.0   0.0   8.0   6.0   1.0   1.0   0.0   \n",
        "19985   13.0   7.0   0.0   4.0   2.0   0.0   1.0   2.0   1.0   0.0   0.0   \n",
        "109868   9.0   5.0   0.0   3.0   1.0   0.0   2.0   1.0   0.0   0.0   0.0   \n",
        "\n",
        "        C173  C174  C175  C176  C177  C178  C179  C180  C181  C182  C183  \\\n",
        "47078    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   9.0   3.0   \n",
        "67364    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   9.0   7.0   \n",
        "76156    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  45.0  19.0   \n",
        "19985    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  13.0   7.0   \n",
        "109868   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   9.0   5.0   \n",
        "\n",
        "        C184  C185  C186    C187    C188  C189   C190  C191  C192  C193  \\\n",
        "47078    4.0   2.0   0.0   14.40   11.98   0.0   2.42  0.83   0.0  0.17   \n",
        "67364    2.0   0.0   0.0    7.33    7.33   0.0   0.00  1.00   0.0  0.00   \n",
        "76156   16.0   9.0   0.0   68.97   44.56   0.0  24.41  0.65   0.0  0.35   \n",
        "19985    4.0   2.0   0.0   99.83   88.63   0.0  11.20  0.89   0.0  0.11   \n",
        "109868   3.0   1.0   0.0  100.33  100.00   0.0   0.33  1.00   0.0  0.00   \n",
        "\n",
        "         C194  C195  C196  C197  C198  C199  C200  C201  C202  C203  C204  \\\n",
        "47078    42.0  19.0   0.0   9.0  14.0   0.0   7.0   2.0   0.0   0.0  33.0   \n",
        "67364    14.0  10.0   0.0   4.0   0.0   0.0   4.0   0.0   0.0   0.0  10.0   \n",
        "76156   165.0  56.0   0.0  89.0  18.0   0.0  34.0  49.0   1.0   5.0  74.0   \n",
        "19985    63.0  45.0   0.0  12.0   6.0   0.0   1.0   9.0   2.0   0.0  51.0   \n",
        "109868   22.0  12.0   0.0   9.0   1.0   0.0   4.0   5.0   0.0   0.0  13.0   \n",
        "\n",
        "        C205  C206  C207 C208  C209  C210   C211           C212      C213  \\\n",
        "47078   19.0   0.0  14.0   \u696d\u8005  15.0   0.0    0.0            NaN       NaN   \n",
        "67364   10.0   0.0   0.0   \u696d\u8005   6.0   7.0  104.0   16383.008789  0.141707   \n",
        "76156   56.0   0.0  18.0   \u696d\u8005  91.0   0.0  200.0  905435.687500  0.054861   \n",
        "19985   45.0   0.0   6.0   \u696d\u8005  18.0   3.0    0.0            NaN       NaN   \n",
        "109868  12.0   0.0   1.0   \u696d\u8005   4.0   0.0  162.0       0.000000  0.000000   \n",
        "\n",
        "         C214          C215  \n",
        "47078     0.0  0.000000e+00  \n",
        "67364   104.0  1.183866e+08  \n",
        "76156   200.0  1.690030e+10  \n",
        "19985     0.0  0.000000e+00  \n",
        "109868  162.0  2.801133e+08  "
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##column independency"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfco = df.corr()\n",
      "indices = np.where(dfco > 0.8)\n",
      "cols = [(dfco.index[x], dfco.columns[y]) for x, y in zip(*indices) if x != y and x < y]\n",
      "\n",
      "for col in cols:\n",
      "  if col[1] in df.columns and col[1]!='C3': del df[col[1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##chi-squared test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import chi2_contingency\n",
      "\n",
      "for col in [df.columns[i] for i in xrange(len(df.columns)) if df.dtypes[i]=='object' and df.columns[i]!='C3']:\n",
      "    chi2, p, dof, expected = chi2_contingency(pd.crosstab(df[col], df['C3']))\n",
      "    if p>=0.05: # H0 (independent - no affects)\"\n",
      "        print \"%s does NOT affect C3\" % col\n",
      "        del df[col]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C5 does NOT affect C3\n",
        "C7 does NOT affect C3\n",
        "C44 does NOT affect C3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C45 does NOT affect C3\n",
        "C46 does NOT affect C3\n",
        "C95 does NOT affect C3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##anova test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import f_oneway\n",
      "\n",
      "for col in [df.columns[i] for i in xrange(len(df.columns)) if df.dtypes[i]!='object' and df.columns[i]!='C3']:\n",
      "    df_y = df.loc[df['C3']=='Y', col].fillna(0) # or dropna ?\n",
      "    df_n = df.loc[df['C3']=='N', col].fillna(0) # or dropna ?\n",
      "    fVal, p = f_oneway(df_y, df_n)\n",
      "    if p>=0.05: # H0 (%s df_y's mean = df_n's mean)\n",
      "        print \"%s no difference\" % (col)\n",
      "        del df[col]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C39 no difference\n",
        "C47 no difference\n",
        "C50 no difference\n",
        "C53 no difference\n",
        "C56 no difference\n",
        "C61 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C62 no difference\n",
        "C68 no difference\n",
        "C69 no difference\n",
        "C70 no difference\n",
        "C71 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C74 no difference\n",
        "C79 no difference\n",
        "C80 no difference\n",
        "C81 no difference\n",
        "C82 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C83 no difference\n",
        "C84 no difference\n",
        "C85 no difference\n",
        "C86 no difference\n",
        "C87 no difference\n",
        "C109 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C112 no difference\n",
        "C113 no difference\n",
        "C114 no difference\n",
        "C116 no difference\n",
        "C118 no difference\n",
        "C119 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C121 no difference\n",
        "C123 no difference\n",
        "C124 no difference\n",
        "C125 no difference\n",
        "C126 no difference\n",
        "C131 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C132 no difference\n",
        "C133 no difference\n",
        "C134 no difference\n",
        "C135 no difference\n",
        "C136 no difference\n",
        "C137 no difference\n",
        "C138 no difference\n",
        "C139 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C143 no difference\n",
        "C144 no difference\n",
        "C145 no difference\n",
        "C146 no difference\n",
        "C152 no difference\n",
        "C158 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C160 no difference\n",
        "C166 no difference\n",
        "C167 no difference\n",
        "C173 no difference\n",
        "C176 no difference\n",
        "C177 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C178 no difference\n",
        "C179 no difference\n",
        "C180 no difference\n",
        "C181 no difference\n",
        "C189 no difference\n",
        "C191 no difference\n",
        "C192 no difference\n",
        "C210 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C212 no difference\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(df.columns), \", \".join(df.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "88 C3, C4, C6, C8, C9, C10, C11, C12, C13, C14, C15, C16, C18, C19, C20, C22, C23, C24, C31, C33, C34, C35, C37, C38, C40, C42, C43, C48, C51, C52, C55, C57, C58, C59, C60, C63, C64, C65, C66, C67, C72, C73, C75, C76, C77, C78, C88, C89, C90, C91, C92, C93, C94, C96, C97, C98, C99, C100, C102, C103, C104, C106, C107, C108, C110, C111, C115, C117, C120, C122, C127, C128, C129, C130, C140, C155, C164, C170, C171, C172, C174, C175, C196, C202, C203, C208, C211, C213\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Preprocessing (for Feature Selection)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "dfc = df.loc[:, [df.columns[i] for i in xrange(len(df.columns)) if df.dtypes[i]!='object' and df.columns[i]!='C3']]\n",
      "for col in dfc.columns:\n",
      "    dfc[col].fillna(0, inplace=True)\n",
      "    dfc[col] = StandardScaler().fit_transform(dfc[col]) #(df['DT1_DATA_RTD_DUR_L'] - df['DT1_DATA_RTD_DUR_L'].mean())/df['DT1_DATA_RTD_DUR_L'].std(ddof=0)\n",
      "\n",
      "dfc.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C6</th>\n",
        "      <th>C8</th>\n",
        "      <th>C13</th>\n",
        "      <th>C15</th>\n",
        "      <th>C16</th>\n",
        "      <th>C20</th>\n",
        "      <th>C24</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C35</th>\n",
        "      <th>C37</th>\n",
        "      <th>C38</th>\n",
        "      <th>C40</th>\n",
        "      <th>C42</th>\n",
        "      <th>C43</th>\n",
        "      <th>C48</th>\n",
        "      <th>C51</th>\n",
        "      <th>C52</th>\n",
        "      <th>C55</th>\n",
        "      <th>C57</th>\n",
        "      <th>C58</th>\n",
        "      <th>C59</th>\n",
        "      <th>C60</th>\n",
        "      <th>C63</th>\n",
        "      <th>C64</th>\n",
        "      <th>C65</th>\n",
        "      <th>C66</th>\n",
        "      <th>C67</th>\n",
        "      <th>C72</th>\n",
        "      <th>C73</th>\n",
        "      <th>C75</th>\n",
        "      <th>C76</th>\n",
        "      <th>C77</th>\n",
        "      <th>C78</th>\n",
        "      <th>C88</th>\n",
        "      <th>C89</th>\n",
        "      <th>C90</th>\n",
        "      <th>C91</th>\n",
        "      <th>C98</th>\n",
        "      <th>C99</th>\n",
        "      <th>C100</th>\n",
        "      <th>C102</th>\n",
        "      <th>C103</th>\n",
        "      <th>C104</th>\n",
        "      <th>C106</th>\n",
        "      <th>C107</th>\n",
        "      <th>C108</th>\n",
        "      <th>C110</th>\n",
        "      <th>C111</th>\n",
        "      <th>C115</th>\n",
        "      <th>C117</th>\n",
        "      <th>C120</th>\n",
        "      <th>C122</th>\n",
        "      <th>C127</th>\n",
        "      <th>C128</th>\n",
        "      <th>C129</th>\n",
        "      <th>C130</th>\n",
        "      <th>C140</th>\n",
        "      <th>C155</th>\n",
        "      <th>C164</th>\n",
        "      <th>C170</th>\n",
        "      <th>C171</th>\n",
        "      <th>C172</th>\n",
        "      <th>C174</th>\n",
        "      <th>C175</th>\n",
        "      <th>C196</th>\n",
        "      <th>C202</th>\n",
        "      <th>C203</th>\n",
        "      <th>C211</th>\n",
        "      <th>C213</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>47078</th>\n",
        "      <td>0.043597</td>\n",
        "      <td>-0.584142</td>\n",
        "      <td>-0.912775</td>\n",
        "      <td>0.957070</td>\n",
        "      <td>-1.196258</td>\n",
        "      <td>-1.099385</td>\n",
        "      <td>0.169619</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>0.104964</td>\n",
        "      <td>-0.286183</td>\n",
        "      <td>0.319522</td>\n",
        "      <td>-0.483994</td>\n",
        "      <td>-0.097196</td>\n",
        "      <td>0.186343</td>\n",
        "      <td>-0.318880</td>\n",
        "      <td>-0.216468</td>\n",
        "      <td>-0.360115</td>\n",
        "      <td>-0.317372</td>\n",
        "      <td>-0.143895</td>\n",
        "      <td>0.214759</td>\n",
        "      <td>-0.249715</td>\n",
        "      <td>0.376709</td>\n",
        "      <td>-0.265969</td>\n",
        "      <td>1.087657</td>\n",
        "      <td>-0.342731</td>\n",
        "      <td>-0.243693</td>\n",
        "      <td>-0.224184</td>\n",
        "      <td>-0.378411</td>\n",
        "      <td>-0.353540</td>\n",
        "      <td>-0.448425</td>\n",
        "      <td>-0.167395</td>\n",
        "      <td>-0.119927</td>\n",
        "      <td>-0.117626</td>\n",
        "      <td>0.839966</td>\n",
        "      <td>1.157580</td>\n",
        "      <td>1.051681</td>\n",
        "      <td>-0.215195</td>\n",
        "      <td>1.050334</td>\n",
        "      <td>-0.231655</td>\n",
        "      <td>-0.497965</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.432761</td>\n",
        "      <td>-0.268830</td>\n",
        "      <td>-0.210914</td>\n",
        "      <td>-0.405495</td>\n",
        "      <td>-0.11573</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.576051</td>\n",
        "      <td>-0.455619</td>\n",
        "      <td>0.789140</td>\n",
        "      <td>0.783728</td>\n",
        "      <td>0.475800</td>\n",
        "      <td>-0.205565</td>\n",
        "      <td>-0.322149</td>\n",
        "      <td>-0.336020</td>\n",
        "      <td>-0.304838</td>\n",
        "      <td>-0.350912</td>\n",
        "      <td>-0.075502</td>\n",
        "      <td>-0.318557</td>\n",
        "      <td>-0.372005</td>\n",
        "      <td>-0.368197</td>\n",
        "      <td>-0.174955</td>\n",
        "      <td>-0.116982</td>\n",
        "      <td>-0.102016</td>\n",
        "      <td>-0.201305</td>\n",
        "      <td>-0.226002</td>\n",
        "      <td>-0.223668</td>\n",
        "      <td>-0.549090</td>\n",
        "      <td>-0.582294</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>67364</th>\n",
        "      <td>1.053629</td>\n",
        "      <td>1.768995</td>\n",
        "      <td>-0.912775</td>\n",
        "      <td>-0.007770</td>\n",
        "      <td>-0.655967</td>\n",
        "      <td>-0.533625</td>\n",
        "      <td>0.169619</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>-0.099179</td>\n",
        "      <td>-0.286183</td>\n",
        "      <td>0.319522</td>\n",
        "      <td>-0.483994</td>\n",
        "      <td>-0.097196</td>\n",
        "      <td>-0.352999</td>\n",
        "      <td>-0.408625</td>\n",
        "      <td>-0.360723</td>\n",
        "      <td>-0.507802</td>\n",
        "      <td>-0.383237</td>\n",
        "      <td>-0.143895</td>\n",
        "      <td>1.028416</td>\n",
        "      <td>-0.249715</td>\n",
        "      <td>-0.186490</td>\n",
        "      <td>-0.265969</td>\n",
        "      <td>0.586671</td>\n",
        "      <td>-0.671012</td>\n",
        "      <td>-0.243693</td>\n",
        "      <td>-0.224184</td>\n",
        "      <td>-0.365572</td>\n",
        "      <td>-0.310809</td>\n",
        "      <td>-0.289164</td>\n",
        "      <td>-0.409582</td>\n",
        "      <td>-0.459089</td>\n",
        "      <td>-0.281604</td>\n",
        "      <td>0.061403</td>\n",
        "      <td>-0.826537</td>\n",
        "      <td>0.316828</td>\n",
        "      <td>-0.471227</td>\n",
        "      <td>-0.226978</td>\n",
        "      <td>1.173166</td>\n",
        "      <td>0.871041</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.577090</td>\n",
        "      <td>2.290631</td>\n",
        "      <td>-0.210914</td>\n",
        "      <td>2.790770</td>\n",
        "      <td>-0.11573</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.576051</td>\n",
        "      <td>-0.300668</td>\n",
        "      <td>-0.184386</td>\n",
        "      <td>-0.847990</td>\n",
        "      <td>-0.232763</td>\n",
        "      <td>-0.203005</td>\n",
        "      <td>-0.144692</td>\n",
        "      <td>-0.313363</td>\n",
        "      <td>-0.278981</td>\n",
        "      <td>-0.286358</td>\n",
        "      <td>-0.518980</td>\n",
        "      <td>-0.318557</td>\n",
        "      <td>-0.372005</td>\n",
        "      <td>-0.368197</td>\n",
        "      <td>-0.174955</td>\n",
        "      <td>-0.116982</td>\n",
        "      <td>-0.102016</td>\n",
        "      <td>-0.201305</td>\n",
        "      <td>-0.226002</td>\n",
        "      <td>-0.223668</td>\n",
        "      <td>-0.229716</td>\n",
        "      <td>1.298857</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>76156</th>\n",
        "      <td>-0.317128</td>\n",
        "      <td>0.907091</td>\n",
        "      <td>1.864457</td>\n",
        "      <td>-1.386114</td>\n",
        "      <td>3.666361</td>\n",
        "      <td>-0.533625</td>\n",
        "      <td>-0.774810</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>-0.031132</td>\n",
        "      <td>2.016172</td>\n",
        "      <td>0.319522</td>\n",
        "      <td>-0.483994</td>\n",
        "      <td>-0.097196</td>\n",
        "      <td>-0.352999</td>\n",
        "      <td>0.844309</td>\n",
        "      <td>2.174555</td>\n",
        "      <td>0.981272</td>\n",
        "      <td>3.362510</td>\n",
        "      <td>0.480656</td>\n",
        "      <td>-0.724077</td>\n",
        "      <td>-0.249715</td>\n",
        "      <td>1.202736</td>\n",
        "      <td>0.392486</td>\n",
        "      <td>0.252681</td>\n",
        "      <td>1.462814</td>\n",
        "      <td>-0.091318</td>\n",
        "      <td>0.058253</td>\n",
        "      <td>0.524783</td>\n",
        "      <td>0.854709</td>\n",
        "      <td>0.706622</td>\n",
        "      <td>2.398590</td>\n",
        "      <td>0.640048</td>\n",
        "      <td>0.397393</td>\n",
        "      <td>0.969726</td>\n",
        "      <td>-0.165164</td>\n",
        "      <td>-0.017196</td>\n",
        "      <td>-0.471227</td>\n",
        "      <td>-0.226978</td>\n",
        "      <td>-0.231655</td>\n",
        "      <td>-0.470308</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.570178</td>\n",
        "      <td>1.573012</td>\n",
        "      <td>-0.210914</td>\n",
        "      <td>-0.266527</td>\n",
        "      <td>-0.11573</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.048515</td>\n",
        "      <td>3.728068</td>\n",
        "      <td>19.286132</td>\n",
        "      <td>2.551422</td>\n",
        "      <td>14.647060</td>\n",
        "      <td>-0.173686</td>\n",
        "      <td>0.812344</td>\n",
        "      <td>0.259103</td>\n",
        "      <td>0.270264</td>\n",
        "      <td>1.680390</td>\n",
        "      <td>1.872633</td>\n",
        "      <td>-0.318557</td>\n",
        "      <td>0.825307</td>\n",
        "      <td>1.035529</td>\n",
        "      <td>-0.174955</td>\n",
        "      <td>-0.116982</td>\n",
        "      <td>-0.102016</td>\n",
        "      <td>-0.201305</td>\n",
        "      <td>0.035151</td>\n",
        "      <td>1.195906</td>\n",
        "      <td>0.065091</td>\n",
        "      <td>0.145982</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19985</th>\n",
        "      <td>-1.904321</td>\n",
        "      <td>0.948134</td>\n",
        "      <td>1.014185</td>\n",
        "      <td>-0.834777</td>\n",
        "      <td>-0.655967</td>\n",
        "      <td>1.729416</td>\n",
        "      <td>-0.774810</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>-0.167227</td>\n",
        "      <td>-0.286183</td>\n",
        "      <td>-0.563136</td>\n",
        "      <td>-0.483994</td>\n",
        "      <td>-0.097196</td>\n",
        "      <td>-0.352999</td>\n",
        "      <td>0.280057</td>\n",
        "      <td>-0.097358</td>\n",
        "      <td>0.175707</td>\n",
        "      <td>0.028661</td>\n",
        "      <td>-0.143895</td>\n",
        "      <td>1.028416</td>\n",
        "      <td>-0.249715</td>\n",
        "      <td>-0.561957</td>\n",
        "      <td>-0.265969</td>\n",
        "      <td>-0.470966</td>\n",
        "      <td>-0.233304</td>\n",
        "      <td>0.061057</td>\n",
        "      <td>-0.224184</td>\n",
        "      <td>-0.192252</td>\n",
        "      <td>-0.448333</td>\n",
        "      <td>0.130457</td>\n",
        "      <td>0.108964</td>\n",
        "      <td>0.569510</td>\n",
        "      <td>0.089128</td>\n",
        "      <td>-0.262999</td>\n",
        "      <td>0.363933</td>\n",
        "      <td>-0.017196</td>\n",
        "      <td>3.198568</td>\n",
        "      <td>-0.226978</td>\n",
        "      <td>-0.231655</td>\n",
        "      <td>-1.078755</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.470599</td>\n",
        "      <td>-0.546139</td>\n",
        "      <td>-0.210914</td>\n",
        "      <td>-0.405495</td>\n",
        "      <td>-0.11573</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.576051</td>\n",
        "      <td>-0.765522</td>\n",
        "      <td>-0.184386</td>\n",
        "      <td>-0.983966</td>\n",
        "      <td>-0.232763</td>\n",
        "      <td>-0.205565</td>\n",
        "      <td>-0.322149</td>\n",
        "      <td>-0.336020</td>\n",
        "      <td>-0.304838</td>\n",
        "      <td>-0.350912</td>\n",
        "      <td>0.257106</td>\n",
        "      <td>-0.318557</td>\n",
        "      <td>0.825307</td>\n",
        "      <td>-0.368197</td>\n",
        "      <td>-0.174955</td>\n",
        "      <td>-0.116982</td>\n",
        "      <td>-0.102016</td>\n",
        "      <td>-0.201305</td>\n",
        "      <td>0.296305</td>\n",
        "      <td>-0.223668</td>\n",
        "      <td>-0.549090</td>\n",
        "      <td>-0.582294</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>109868</th>\n",
        "      <td>0.187888</td>\n",
        "      <td>1.317521</td>\n",
        "      <td>-0.303374</td>\n",
        "      <td>0.888153</td>\n",
        "      <td>-0.115676</td>\n",
        "      <td>0.597895</td>\n",
        "      <td>-0.774810</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>0.309107</td>\n",
        "      <td>2.016172</td>\n",
        "      <td>0.319522</td>\n",
        "      <td>1.449660</td>\n",
        "      <td>-0.097196</td>\n",
        "      <td>1.265026</td>\n",
        "      <td>0.258231</td>\n",
        "      <td>-0.181397</td>\n",
        "      <td>-0.487663</td>\n",
        "      <td>-0.311644</td>\n",
        "      <td>-0.143895</td>\n",
        "      <td>1.403950</td>\n",
        "      <td>-0.249715</td>\n",
        "      <td>-0.674597</td>\n",
        "      <td>-0.265969</td>\n",
        "      <td>-0.192640</td>\n",
        "      <td>-0.616298</td>\n",
        "      <td>-0.243693</td>\n",
        "      <td>-0.224184</td>\n",
        "      <td>2.707343</td>\n",
        "      <td>2.163645</td>\n",
        "      <td>-0.380481</td>\n",
        "      <td>-0.463071</td>\n",
        "      <td>-0.404978</td>\n",
        "      <td>-0.301295</td>\n",
        "      <td>-0.911801</td>\n",
        "      <td>-0.826537</td>\n",
        "      <td>-0.685243</td>\n",
        "      <td>-0.471227</td>\n",
        "      <td>-0.226978</td>\n",
        "      <td>-0.231655</td>\n",
        "      <td>0.490762</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.470599</td>\n",
        "      <td>-0.546139</td>\n",
        "      <td>-0.210914</td>\n",
        "      <td>-0.405495</td>\n",
        "      <td>-0.11573</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.576051</td>\n",
        "      <td>0.009235</td>\n",
        "      <td>-0.184386</td>\n",
        "      <td>-0.304084</td>\n",
        "      <td>-0.232763</td>\n",
        "      <td>-0.205540</td>\n",
        "      <td>-0.322024</td>\n",
        "      <td>-0.298025</td>\n",
        "      <td>-0.304410</td>\n",
        "      <td>-0.350048</td>\n",
        "      <td>-0.392272</td>\n",
        "      <td>-0.318557</td>\n",
        "      <td>-0.372005</td>\n",
        "      <td>-0.368197</td>\n",
        "      <td>-0.174955</td>\n",
        "      <td>-0.116982</td>\n",
        "      <td>-0.102016</td>\n",
        "      <td>-0.201305</td>\n",
        "      <td>-0.226002</td>\n",
        "      <td>-0.223668</td>\n",
        "      <td>-0.051604</td>\n",
        "      <td>-0.582294</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "              C6        C8       C13       C15       C16       C20       C24  \\\n",
        "47078   0.043597 -0.584142 -0.912775  0.957070 -1.196258 -1.099385  0.169619   \n",
        "67364   1.053629  1.768995 -0.912775 -0.007770 -0.655967 -0.533625  0.169619   \n",
        "76156  -0.317128  0.907091  1.864457 -1.386114  3.666361 -0.533625 -0.774810   \n",
        "19985  -1.904321  0.948134  1.014185 -0.834777 -0.655967  1.729416 -0.774810   \n",
        "109868  0.187888  1.317521 -0.303374  0.888153 -0.115676  0.597895 -0.774810   \n",
        "\n",
        "             C33      C34       C35       C37       C38       C40       C42  \\\n",
        "47078  -0.587986 -0.61213  0.104964 -0.286183  0.319522 -0.483994 -0.097196   \n",
        "67364  -0.587986 -0.61213 -0.099179 -0.286183  0.319522 -0.483994 -0.097196   \n",
        "76156  -0.587986 -0.61213 -0.031132  2.016172  0.319522 -0.483994 -0.097196   \n",
        "19985  -0.587986 -0.61213 -0.167227 -0.286183 -0.563136 -0.483994 -0.097196   \n",
        "109868 -0.587986 -0.61213  0.309107  2.016172  0.319522  1.449660 -0.097196   \n",
        "\n",
        "             C43       C48       C51       C52       C55       C57       C58  \\\n",
        "47078   0.186343 -0.318880 -0.216468 -0.360115 -0.317372 -0.143895  0.214759   \n",
        "67364  -0.352999 -0.408625 -0.360723 -0.507802 -0.383237 -0.143895  1.028416   \n",
        "76156  -0.352999  0.844309  2.174555  0.981272  3.362510  0.480656 -0.724077   \n",
        "19985  -0.352999  0.280057 -0.097358  0.175707  0.028661 -0.143895  1.028416   \n",
        "109868  1.265026  0.258231 -0.181397 -0.487663 -0.311644 -0.143895  1.403950   \n",
        "\n",
        "             C59       C60       C63       C64       C65       C66       C67  \\\n",
        "47078  -0.249715  0.376709 -0.265969  1.087657 -0.342731 -0.243693 -0.224184   \n",
        "67364  -0.249715 -0.186490 -0.265969  0.586671 -0.671012 -0.243693 -0.224184   \n",
        "76156  -0.249715  1.202736  0.392486  0.252681  1.462814 -0.091318  0.058253   \n",
        "19985  -0.249715 -0.561957 -0.265969 -0.470966 -0.233304  0.061057 -0.224184   \n",
        "109868 -0.249715 -0.674597 -0.265969 -0.192640 -0.616298 -0.243693 -0.224184   \n",
        "\n",
        "             C72       C73       C75       C76       C77       C78       C88  \\\n",
        "47078  -0.378411 -0.353540 -0.448425 -0.167395 -0.119927 -0.117626  0.839966   \n",
        "67364  -0.365572 -0.310809 -0.289164 -0.409582 -0.459089 -0.281604  0.061403   \n",
        "76156   0.524783  0.854709  0.706622  2.398590  0.640048  0.397393  0.969726   \n",
        "19985  -0.192252 -0.448333  0.130457  0.108964  0.569510  0.089128 -0.262999   \n",
        "109868  2.707343  2.163645 -0.380481 -0.463071 -0.404978 -0.301295 -0.911801   \n",
        "\n",
        "             C89       C90       C91       C98       C99      C100  C102  \\\n",
        "47078   1.157580  1.051681 -0.215195  1.050334 -0.231655 -0.497965   0.0   \n",
        "67364  -0.826537  0.316828 -0.471227 -0.226978  1.173166  0.871041   0.0   \n",
        "76156  -0.165164 -0.017196 -0.471227 -0.226978 -0.231655 -0.470308   0.0   \n",
        "19985   0.363933 -0.017196  3.198568 -0.226978 -0.231655 -1.078755   0.0   \n",
        "109868 -0.826537 -0.685243 -0.471227 -0.226978 -0.231655  0.490762   0.0   \n",
        "\n",
        "            C103      C104      C106      C107     C108  C110      C111  \\\n",
        "47078   0.432761 -0.268830 -0.210914 -0.405495 -0.11573   0.0 -0.576051   \n",
        "67364   1.577090  2.290631 -0.210914  2.790770 -0.11573   0.0 -0.576051   \n",
        "76156   0.570178  1.573012 -0.210914 -0.266527 -0.11573   0.0  1.048515   \n",
        "19985  -0.470599 -0.546139 -0.210914 -0.405495 -0.11573   0.0 -0.576051   \n",
        "109868 -0.470599 -0.546139 -0.210914 -0.405495 -0.11573   0.0 -0.576051   \n",
        "\n",
        "            C115       C117      C120       C122      C127      C128  \\\n",
        "47078  -0.455619   0.789140  0.783728   0.475800 -0.205565 -0.322149   \n",
        "67364  -0.300668  -0.184386 -0.847990  -0.232763 -0.203005 -0.144692   \n",
        "76156   3.728068  19.286132  2.551422  14.647060 -0.173686  0.812344   \n",
        "19985  -0.765522  -0.184386 -0.983966  -0.232763 -0.205565 -0.322149   \n",
        "109868  0.009235  -0.184386 -0.304084  -0.232763 -0.205540 -0.322024   \n",
        "\n",
        "            C129      C130      C140      C155      C164      C170      C171  \\\n",
        "47078  -0.336020 -0.304838 -0.350912 -0.075502 -0.318557 -0.372005 -0.368197   \n",
        "67364  -0.313363 -0.278981 -0.286358 -0.518980 -0.318557 -0.372005 -0.368197   \n",
        "76156   0.259103  0.270264  1.680390  1.872633 -0.318557  0.825307  1.035529   \n",
        "19985  -0.336020 -0.304838 -0.350912  0.257106 -0.318557  0.825307 -0.368197   \n",
        "109868 -0.298025 -0.304410 -0.350048 -0.392272 -0.318557 -0.372005 -0.368197   \n",
        "\n",
        "            C172      C174      C175      C196      C202      C203      C211  \\\n",
        "47078  -0.174955 -0.116982 -0.102016 -0.201305 -0.226002 -0.223668 -0.549090   \n",
        "67364  -0.174955 -0.116982 -0.102016 -0.201305 -0.226002 -0.223668 -0.229716   \n",
        "76156  -0.174955 -0.116982 -0.102016 -0.201305  0.035151  1.195906  0.065091   \n",
        "19985  -0.174955 -0.116982 -0.102016 -0.201305  0.296305 -0.223668 -0.549090   \n",
        "109868 -0.174955 -0.116982 -0.102016 -0.201305 -0.226002 -0.223668 -0.051604   \n",
        "\n",
        "            C213  \n",
        "47078  -0.582294  \n",
        "67364   1.298857  \n",
        "76156   0.145982  \n",
        "19985  -0.582294  \n",
        "109868 -0.582294  "
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Feature Selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectKBest, f_classif\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn import svm\n",
      "\n",
      "#coding\n",
      "X, y = dfc, df['C3'].replace({'N':0, 'Y':1})\n",
      "anova_svm = Pipeline([('anova', SelectKBest(f_classif, k=9)), ('svc', svm.SVC(kernel='linear'))])\n",
      "anova_svm.set_params(svc__C=0.1).fit(X, y)\n",
      "\n",
      "print anova_svm.score(X, y)\n",
      "\n",
      "filtered = [dfc.columns[i] for i in anova_svm.named_steps['anova'].get_support(indices=True)]\n",
      "print filtered\n",
      "\n",
      "#ranked_features = sorted(enumerate(anova_svm.named_steps['anova'].scores_), key=lambda x:x[1], reverse=True)\n",
      "#print [dfc.columns[e[0]] for e in ranked_features]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n",
        "['C6', 'C8', 'C13', 'C16', 'C24', 'C33', 'C34', 'C60', 'C100']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [41 47] are constant.\n",
        "  UserWarning)\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "\n",
      "dfc = df.loc[:, [df.columns[i] for i in xrange(len(df.columns)) if df.dtypes[i]=='object' and df.columns[i]!='C3']]\n",
      "for col in dfc.columns:\n",
      "    dfc[col] = df[col].replace({name: n for n, name in enumerate(df[col].unique())})\n",
      "\n",
      "selector = SelectKBest(chi2, k=9).fit(dfc, y)\n",
      "filtered2 = [dfc.columns[i] for i in selector.get_support(indices=True)]\n",
      "print filtered2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['C4', 'C10', 'C12', 'C19', 'C22', 'C31', 'C93', 'C94', 'C208']\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Preprocessing (for Prediction)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "choosed = filtered + filtered2\n",
      "choosed.remove('C22')\n",
      "choosed.remove('C24')\n",
      "\n",
      "X = df.loc[:, choosed]\n",
      "y = df['C3'].replace({'N':0, 'Y':1})\n",
      "for col in X.columns:\n",
      "  try:\n",
      "    X[col].fillna(0, inplace=True)\n",
      "    X[col] = StandardScaler().fit_transform(X[col])\n",
      "  except:\n",
      "    X[col] = X[col].replace({name: n for n, name in enumerate(X[col].unique())})\n",
      "\n",
      "X.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C6</th>\n",
        "      <th>C8</th>\n",
        "      <th>C13</th>\n",
        "      <th>C16</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C60</th>\n",
        "      <th>C100</th>\n",
        "      <th>C4</th>\n",
        "      <th>C10</th>\n",
        "      <th>C12</th>\n",
        "      <th>C19</th>\n",
        "      <th>C31</th>\n",
        "      <th>C93</th>\n",
        "      <th>C94</th>\n",
        "      <th>C208</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>47078</th>\n",
        "      <td>0.043597</td>\n",
        "      <td>-0.584142</td>\n",
        "      <td>-0.912775</td>\n",
        "      <td>-1.196258</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>0.376709</td>\n",
        "      <td>-0.497965</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>67364</th>\n",
        "      <td>1.053629</td>\n",
        "      <td>1.768995</td>\n",
        "      <td>-0.912775</td>\n",
        "      <td>-0.655967</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>-0.186490</td>\n",
        "      <td>0.871041</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>76156</th>\n",
        "      <td>-0.317128</td>\n",
        "      <td>0.907091</td>\n",
        "      <td>1.864457</td>\n",
        "      <td>3.666361</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>1.202736</td>\n",
        "      <td>-0.470308</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19985</th>\n",
        "      <td>-1.904321</td>\n",
        "      <td>0.948134</td>\n",
        "      <td>1.014185</td>\n",
        "      <td>-0.655967</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>-0.561957</td>\n",
        "      <td>-1.078755</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>109868</th>\n",
        "      <td>0.187888</td>\n",
        "      <td>1.317521</td>\n",
        "      <td>-0.303374</td>\n",
        "      <td>-0.115676</td>\n",
        "      <td>-0.587986</td>\n",
        "      <td>-0.61213</td>\n",
        "      <td>-0.674597</td>\n",
        "      <td>0.490762</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>4</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "              C6        C8       C13       C16       C33      C34       C60  \\\n",
        "47078   0.043597 -0.584142 -0.912775 -1.196258 -0.587986 -0.61213  0.376709   \n",
        "67364   1.053629  1.768995 -0.912775 -0.655967 -0.587986 -0.61213 -0.186490   \n",
        "76156  -0.317128  0.907091  1.864457  3.666361 -0.587986 -0.61213  1.202736   \n",
        "19985  -1.904321  0.948134  1.014185 -0.655967 -0.587986 -0.61213 -0.561957   \n",
        "109868  0.187888  1.317521 -0.303374 -0.115676 -0.587986 -0.61213 -0.674597   \n",
        "\n",
        "            C100  C4  C10  C12  C19  C31  C93  C94  C208  \n",
        "47078  -0.497965   0    0    0    0    0    0    0     1  \n",
        "67364   0.871041   0    0    0    1    0    1    1     1  \n",
        "76156  -0.470308   0    0    1    0    0    2    2     1  \n",
        "19985  -1.078755   0    0    0    1    0    3    3     1  \n",
        "109868  0.490762   0    0    1    1    0    4    4     1  "
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Decision Tree Classifier (CART)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn import tree\n",
      "\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf0 = tree.DecisionTreeClassifier().fit(X_train, y_train) #CART\n",
      "clf0.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "0.60299999999999998"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_code(tree, feature_names):\n",
      "  left = tree.tree_.children_left\n",
      "  right = tree.tree_.children_right\n",
      "  threshold = tree.tree_.threshold\n",
      "  features = [feature_names[i] for i in tree.tree_.feature]\n",
      "  value = tree.tree_.value\n",
      "\n",
      "  def recurse(left, right, threshold, features, node):\n",
      "    if threshold[node] != -2:\n",
      "      print \"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\"\n",
      "      if left[node] != -1:\n",
      "        recurse (left, right, threshold, features,left[node])\n",
      "      print \"} else {\"\n",
      "      if right[node] != -1:\n",
      "        recurse (left, right, threshold, features,right[node])\n",
      "      print \"}\"\n",
      "    else:\n",
      "      print \"return \" + str(value[node])\n",
      "  \n",
      "  recurse(left, right, threshold, features, 0)\n",
      "\n",
      "#get_code(clf, X.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Naive Bayes Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf1 = GaussianNB().fit(X_train, y_train)\n",
      "clf1.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "0.51100000000000001"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Logistic Regression (aka logit, MaxEnt) Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf2 = LogisticRegression().fit(X_train, y_train)\n",
      "clf2.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "0.65349999999999997"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Random Forest Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf3 = RandomForestClassifier(n_estimators=10, class_weight={0:1, 1:10}).fit(X_train, y_train)\n",
      "print clf3.score(X_test, y_test)\n",
      "\n",
      "print sorted(zip(choosed, clf3.feature_importances_), key=lambda x: x[1], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.65\n",
        "[('C8', 0.15826650826265989), ('C6', 0.13315443595478266), ('C60', 0.10854505102121718), ('C93', 0.10035500212667003), ('C100', 0.096429737316480635), ('C94', 0.072388115069482742), ('C13', 0.068502409400197847), ('C16', 0.063692606266879365), ('C19', 0.053671471545537662), ('C33', 0.037930589582304691), ('C208', 0.023463057630566407), ('C12', 0.020325197479996022), ('C31', 0.018447984936018756), ('C4', 0.017607886999605752), ('C10', 0.016256710040754536), ('C34', 0.010963236366845815)]\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##SVM Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn import svm\n",
      "\n",
      "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "#clf4 = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
      "clf4 = svm.SVC(kernel='rbf', probability=True).fit(X_train, y_train)\n",
      "clf4.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "0.62424999999999997"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Clustering and Choose Classifier for each group"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "\n",
      "#X_cData = X.loc[:, [c for c in filtered[:8] if c!='C24']].fillna(0)\n",
      "choosed_for_clustering = ['C8', 'C6', 'C60'] #[c for c in filtered[:8] if c!='C24']\n",
      "X_cData = X.loc[:, choosed_for_clustering]\n",
      "\n",
      "kmeans = KMeans(init='k-means++', n_clusters=3)\n",
      "kmeans.fit(X_cData)\n",
      "df['clabel'] = kmeans.labels_\n",
      "#df['clabel'].value_counts(sort=True)\n",
      "\n",
      "clfs = [None for i in xrange(3)]\n",
      "for i in xrange(3):\n",
      "    _X = df.loc[df['clabel']==i, choosed]\n",
      "    _y = df.loc[df['clabel']==i, 'C3'].replace({'N':0, 'Y':1})\n",
      "    for col in _X.columns:\n",
      "      try:\n",
      "        _X[col].fillna(0, inplace=True)\n",
      "        _X[col] = StandardScaler().fit_transform(_X[col])\n",
      "      except:\n",
      "        _X[col] = _X[col].replace({name: n for n, name in enumerate(_X[col].unique())})\n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(_X, _y, test_size=0.4, random_state=0)\n",
      "    clfs[i] = RandomForestClassifier(n_estimators=10, class_weight={0:1, 1:10}).fit(X_train, y_train)\n",
      "    score = clfs[i].score(X_test, y_test)\n",
      "    if score<0.65: clfs[i] = svm.SVC(kernel='rbf', probability=True).fit(X_train, y_train)\n",
      "    print clfs[i].score(X_test, y_test)\n",
      "\n",
      "#X_train.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.635311143271\n",
        "0.658241758242"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.587478057343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Voting Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import VotingClassifier\n",
      "\n",
      "vclf = VotingClassifier(estimators=[('naiveBayes', clf1), ('LogisticR', clf2), ('randomF', clf3), ('svc', clf4)], voting='soft', weights=[1,3,3,3]).fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "dfp = pd.read_csv('../../MB_PCUST_NPOUT_EXAM.txt', encoding='utf-8', sep='\\t', names=['C2']+['C'+str(i+4) for i in xrange(212)], na_values=['?'])\n",
      "\n",
      "Xp = dfp.loc[:, choosed]\n",
      "for col in Xp.columns:\n",
      "  try:\n",
      "    Xp[col].fillna(0, inplace=True)\n",
      "    Xp[col] = StandardScaler().fit_transform(Xp[col])\n",
      "  except:\n",
      "    Xp[col] = Xp[col].replace({name: n for n, name in enumerate(Xp[col].unique())})\n",
      "\n",
      "dfp['pred_C3'] = clf2.predict(Xp)\n",
      "dfp['C3'] = dfp['C24'].map(lambda x: 1 if x>0 else 0)\n",
      "\n",
      "print accuracy_score(dfp['C3'], dfp['pred_C3'])\n",
      "\n",
      "dfp.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.6472\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C2</th>\n",
        "      <th>C4</th>\n",
        "      <th>C5</th>\n",
        "      <th>C6</th>\n",
        "      <th>C7</th>\n",
        "      <th>C8</th>\n",
        "      <th>C9</th>\n",
        "      <th>C10</th>\n",
        "      <th>C11</th>\n",
        "      <th>C12</th>\n",
        "      <th>C13</th>\n",
        "      <th>C14</th>\n",
        "      <th>C15</th>\n",
        "      <th>C16</th>\n",
        "      <th>C17</th>\n",
        "      <th>C18</th>\n",
        "      <th>C19</th>\n",
        "      <th>C20</th>\n",
        "      <th>C21</th>\n",
        "      <th>C22</th>\n",
        "      <th>C23</th>\n",
        "      <th>C24</th>\n",
        "      <th>C25</th>\n",
        "      <th>C26</th>\n",
        "      <th>C27</th>\n",
        "      <th>C28</th>\n",
        "      <th>C29</th>\n",
        "      <th>C30</th>\n",
        "      <th>C31</th>\n",
        "      <th>C32</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C35</th>\n",
        "      <th>C36</th>\n",
        "      <th>C37</th>\n",
        "      <th>C38</th>\n",
        "      <th>C39</th>\n",
        "      <th>C40</th>\n",
        "      <th>C41</th>\n",
        "      <th>C42</th>\n",
        "      <th>C43</th>\n",
        "      <th>C44</th>\n",
        "      <th>C45</th>\n",
        "      <th>C46</th>\n",
        "      <th>C47</th>\n",
        "      <th>C48</th>\n",
        "      <th>C49</th>\n",
        "      <th>C50</th>\n",
        "      <th>C51</th>\n",
        "      <th>C52</th>\n",
        "      <th>C53</th>\n",
        "      <th>C54</th>\n",
        "      <th>C55</th>\n",
        "      <th>C56</th>\n",
        "      <th>C57</th>\n",
        "      <th>C58</th>\n",
        "      <th>C59</th>\n",
        "      <th>C60</th>\n",
        "      <th>C61</th>\n",
        "      <th>C62</th>\n",
        "      <th>C63</th>\n",
        "      <th>C64</th>\n",
        "      <th>C65</th>\n",
        "      <th>C66</th>\n",
        "      <th>C67</th>\n",
        "      <th>C68</th>\n",
        "      <th>C69</th>\n",
        "      <th>C70</th>\n",
        "      <th>C71</th>\n",
        "      <th>C72</th>\n",
        "      <th>C73</th>\n",
        "      <th>C74</th>\n",
        "      <th>C75</th>\n",
        "      <th>C76</th>\n",
        "      <th>C77</th>\n",
        "      <th>C78</th>\n",
        "      <th>C79</th>\n",
        "      <th>C80</th>\n",
        "      <th>C81</th>\n",
        "      <th>C82</th>\n",
        "      <th>C83</th>\n",
        "      <th>C84</th>\n",
        "      <th>C85</th>\n",
        "      <th>C86</th>\n",
        "      <th>C87</th>\n",
        "      <th>C88</th>\n",
        "      <th>C89</th>\n",
        "      <th>C90</th>\n",
        "      <th>C91</th>\n",
        "      <th>C92</th>\n",
        "      <th>C93</th>\n",
        "      <th>C94</th>\n",
        "      <th>C95</th>\n",
        "      <th>C96</th>\n",
        "      <th>C97</th>\n",
        "      <th>C98</th>\n",
        "      <th>C99</th>\n",
        "      <th>C100</th>\n",
        "      <th>C101</th>\n",
        "      <th>C102</th>\n",
        "      <th>C103</th>\n",
        "      <th>C104</th>\n",
        "      <th>C105</th>\n",
        "      <th>C106</th>\n",
        "      <th>C107</th>\n",
        "      <th>C108</th>\n",
        "      <th>C109</th>\n",
        "      <th>C110</th>\n",
        "      <th>C111</th>\n",
        "      <th>C112</th>\n",
        "      <th>C113</th>\n",
        "      <th>C114</th>\n",
        "      <th>C115</th>\n",
        "      <th>C116</th>\n",
        "      <th>C117</th>\n",
        "      <th>C118</th>\n",
        "      <th>C119</th>\n",
        "      <th>C120</th>\n",
        "      <th>C121</th>\n",
        "      <th>C122</th>\n",
        "      <th>C123</th>\n",
        "      <th>C124</th>\n",
        "      <th>C125</th>\n",
        "      <th>C126</th>\n",
        "      <th>C127</th>\n",
        "      <th>C128</th>\n",
        "      <th>C129</th>\n",
        "      <th>C130</th>\n",
        "      <th>C131</th>\n",
        "      <th>C132</th>\n",
        "      <th>C133</th>\n",
        "      <th>C134</th>\n",
        "      <th>C135</th>\n",
        "      <th>C136</th>\n",
        "      <th>C137</th>\n",
        "      <th>C138</th>\n",
        "      <th>C139</th>\n",
        "      <th>C140</th>\n",
        "      <th>C141</th>\n",
        "      <th>C142</th>\n",
        "      <th>C143</th>\n",
        "      <th>C144</th>\n",
        "      <th>C145</th>\n",
        "      <th>C146</th>\n",
        "      <th>C147</th>\n",
        "      <th>C148</th>\n",
        "      <th>C149</th>\n",
        "      <th>C150</th>\n",
        "      <th>C151</th>\n",
        "      <th>C152</th>\n",
        "      <th>C153</th>\n",
        "      <th>C154</th>\n",
        "      <th>C155</th>\n",
        "      <th>C156</th>\n",
        "      <th>C157</th>\n",
        "      <th>C158</th>\n",
        "      <th>C159</th>\n",
        "      <th>C160</th>\n",
        "      <th>C161</th>\n",
        "      <th>C162</th>\n",
        "      <th>C163</th>\n",
        "      <th>C164</th>\n",
        "      <th>C165</th>\n",
        "      <th>C166</th>\n",
        "      <th>C167</th>\n",
        "      <th>C168</th>\n",
        "      <th>C169</th>\n",
        "      <th>C170</th>\n",
        "      <th>C171</th>\n",
        "      <th>C172</th>\n",
        "      <th>C173</th>\n",
        "      <th>C174</th>\n",
        "      <th>C175</th>\n",
        "      <th>C176</th>\n",
        "      <th>C177</th>\n",
        "      <th>C178</th>\n",
        "      <th>C179</th>\n",
        "      <th>C180</th>\n",
        "      <th>C181</th>\n",
        "      <th>C182</th>\n",
        "      <th>C183</th>\n",
        "      <th>C184</th>\n",
        "      <th>C185</th>\n",
        "      <th>C186</th>\n",
        "      <th>C187</th>\n",
        "      <th>C188</th>\n",
        "      <th>C189</th>\n",
        "      <th>C190</th>\n",
        "      <th>C191</th>\n",
        "      <th>C192</th>\n",
        "      <th>C193</th>\n",
        "      <th>C194</th>\n",
        "      <th>C195</th>\n",
        "      <th>C196</th>\n",
        "      <th>C197</th>\n",
        "      <th>C198</th>\n",
        "      <th>C199</th>\n",
        "      <th>C200</th>\n",
        "      <th>C201</th>\n",
        "      <th>C202</th>\n",
        "      <th>C203</th>\n",
        "      <th>C204</th>\n",
        "      <th>C205</th>\n",
        "      <th>C206</th>\n",
        "      <th>C207</th>\n",
        "      <th>C208</th>\n",
        "      <th>C209</th>\n",
        "      <th>C210</th>\n",
        "      <th>C211</th>\n",
        "      <th>C212</th>\n",
        "      <th>C213</th>\n",
        "      <th>C214</th>\n",
        "      <th>C215</th>\n",
        "      <th>pred_C3</th>\n",
        "      <th>C3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>C0088856</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>45.0</td>\n",
        "      <td>\u96d9\u9b5a\u5ea7</td>\n",
        "      <td>14</td>\n",
        "      <td>\u64da\u9ede02</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u7121\u7d81\u7d04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>6</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Yes</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>C0268970</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>38.0</td>\n",
        "      <td>\u7345\u5b50\u5ea7</td>\n",
        "      <td>174</td>\n",
        "      <td>\u64da\u9ede07</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>4G</td>\n",
        "      <td>1136.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-70.0</td>\n",
        "      <td>8</td>\n",
        "      <td>6</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>\u9ad8</td>\n",
        "      <td>1.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>Yes</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>5.165101e+06</td>\n",
        "      <td>99.34</td>\n",
        "      <td>77.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>7.21</td>\n",
        "      <td>12.93</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>2.93</td>\n",
        "      <td>0.00</td>\n",
        "      <td>4.28</td>\n",
        "      <td>0.78</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.57</td>\n",
        "      <td>1.12</td>\n",
        "      <td>3.95</td>\n",
        "      <td>5.38</td>\n",
        "      <td>0.78</td>\n",
        "      <td>4.22</td>\n",
        "      <td>20.43</td>\n",
        "      <td>59.15</td>\n",
        "      <td>0.75</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.05</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.21</td>\n",
        "      <td>0.60</td>\n",
        "      <td>0.01</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u65b0\u71df\u5340</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u65b0\u71df\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>132.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>108701933.0</td>\n",
        "      <td>151396249.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>640602330.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>113758047.0</td>\n",
        "      <td>85067978.0</td>\n",
        "      <td>135352031.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>51434728.0</td>\n",
        "      <td>1.795074e+09</td>\n",
        "      <td>439151.0</td>\n",
        "      <td>326260868.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.906637e+09</td>\n",
        "      <td>0.0</td>\n",
        "      <td>557196876.0</td>\n",
        "      <td>5.169043e+09</td>\n",
        "      <td>448633971.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.716211e+09</td>\n",
        "      <td>570153410.0</td>\n",
        "      <td>99.35</td>\n",
        "      <td>77.32</td>\n",
        "      <td>7.21</td>\n",
        "      <td>12.93</td>\n",
        "      <td>12.93</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>79.21</td>\n",
        "      <td>59.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>90.26</td>\n",
        "      <td>77.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.94</td>\n",
        "      <td>0.86</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.14</td>\n",
        "      <td>59.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>37.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>232.0</td>\n",
        "      <td>903739.278320</td>\n",
        "      <td>0.174970</td>\n",
        "      <td>232.0</td>\n",
        "      <td>5.289064e+09</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>C0298512</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>62.0</td>\n",
        "      <td>\u5c04\u624b\u5ea7</td>\n",
        "      <td>73</td>\n",
        "      <td>\u64da\u9ede07</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-63.0</td>\n",
        "      <td>2</td>\n",
        "      <td>3</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>2.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>N</td>\n",
        "      <td>2</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>72.0</td>\n",
        "      <td>72.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>25.49</td>\n",
        "      <td>6.35</td>\n",
        "      <td>0.0</td>\n",
        "      <td>19.14</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.62</td>\n",
        "      <td>13.52</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.25</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.75</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.53</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.53</td>\n",
        "      <td>8.97</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.38</td>\n",
        "      <td>0.00</td>\n",
        "      <td>6.05</td>\n",
        "      <td>8.55</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.06</td>\n",
        "      <td>0.35</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.34</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u67f3\u71df\u5340</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>538.0</td>\n",
        "      <td>179.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>21.645</td>\n",
        "      <td>3.652</td>\n",
        "      <td>7.830</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>25.48</td>\n",
        "      <td>6.35</td>\n",
        "      <td>19.14</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.52</td>\n",
        "      <td>16.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.36</td>\n",
        "      <td>6.36</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>16.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>C0249782</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>56.0</td>\n",
        "      <td>\u91d1\u725b\u5ea7</td>\n",
        "      <td>226</td>\n",
        "      <td>\u64da\u9ede07</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-77.0</td>\n",
        "      <td>4</td>\n",
        "      <td>2</td>\n",
        "      <td>\u4f4e</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>Yes</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>21.43</td>\n",
        "      <td>5.22</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.64</td>\n",
        "      <td>2.57</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.07</td>\n",
        "      <td>9.57</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.64</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.19</td>\n",
        "      <td>0.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.40</td>\n",
        "      <td>2.57</td>\n",
        "      <td>7.13</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.00</td>\n",
        "      <td>9.17</td>\n",
        "      <td>2.87</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.32</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.41</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u65b0\u71df\u5340</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u67f3\u71df\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>Yes</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>244.0</td>\n",
        "      <td>92.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>45.672</td>\n",
        "      <td>33.880</td>\n",
        "      <td>5.709</td>\n",
        "      <td>5.704305</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>22.35</td>\n",
        "      <td>6.14</td>\n",
        "      <td>13.64</td>\n",
        "      <td>2.57</td>\n",
        "      <td>2.57</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.14</td>\n",
        "      <td>16.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.70</td>\n",
        "      <td>6.14</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.56</td>\n",
        "      <td>0.71</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.29</td>\n",
        "      <td>14.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>7.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>C0180972</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>46.0</td>\n",
        "      <td>\u9b54\u7faf\u5ea7</td>\n",
        "      <td>83</td>\n",
        "      <td>\u64da\u9ede04</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>3G</td>\n",
        "      <td>383.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-73.0</td>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "      <td>\u4f4e</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>3.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7af6\u696dD</td>\n",
        "      <td>82.0</td>\n",
        "      <td>106.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>9.011243e+05</td>\n",
        "      <td>58.42</td>\n",
        "      <td>14.80</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.35</td>\n",
        "      <td>26.27</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.35</td>\n",
        "      <td>0.62</td>\n",
        "      <td>9.88</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.25</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.30</td>\n",
        "      <td>0.45</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.17</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>8.97</td>\n",
        "      <td>14.07</td>\n",
        "      <td>8.05</td>\n",
        "      <td>23.27</td>\n",
        "      <td>3.23</td>\n",
        "      <td>0.83</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.15</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.14</td>\n",
        "      <td>0.40</td>\n",
        "      <td>0.06</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u5f70\u5316\u7e23</td>\n",
        "      <td>\u548c\u7f8e\u93ae</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>93.0</td>\n",
        "      <td>72.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>45.726</td>\n",
        "      <td>46.141</td>\n",
        "      <td>28.992</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>562953.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6514284.0</td>\n",
        "      <td>45907574.0</td>\n",
        "      <td>581620.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.128205e+06</td>\n",
        "      <td>0.0</td>\n",
        "      <td>567134600.0</td>\n",
        "      <td>2.739706e+08</td>\n",
        "      <td>21208770.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>58.42</td>\n",
        "      <td>14.80</td>\n",
        "      <td>16.85</td>\n",
        "      <td>26.27</td>\n",
        "      <td>26.27</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>26.27</td>\n",
        "      <td>51.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>27.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>27.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>41.07</td>\n",
        "      <td>14.80</td>\n",
        "      <td>0.0</td>\n",
        "      <td>26.27</td>\n",
        "      <td>0.36</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.64</td>\n",
        "      <td>51.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>40.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>\u56fa\u7db2</td>\n",
        "      <td>24.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>259.0</td>\n",
        "      <td>57456.744141</td>\n",
        "      <td>0.063761</td>\n",
        "      <td>259.0</td>\n",
        "      <td>9.227513e+08</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "         C2    C4 C5    C6   C7   C8    C9 C10 C11 C12     C13  C14   C15  \\\n",
        "0  C0088856  NVIP  M  45.0  \u96d9\u9b5a\u5ea7   14  \u64da\u9ede02   N  \u6975\u4f4e  3G   183.0  \u7121\u7d81\u7d04   NaN   \n",
        "1  C0268970  NVIP  F  38.0  \u7345\u5b50\u5ea7  174  \u64da\u9ede07   N   \u4e2d  4G  1136.0  \u8cfc\u6a5f\u7d04 -70.0   \n",
        "2  C0298512  NVIP  M  62.0  \u5c04\u624b\u5ea7   73  \u64da\u9ede07   N  \u6975\u4f4e  3G   183.0  \u901a\u4fe1\u7d04 -63.0   \n",
        "3  C0249782  NVIP  M  56.0  \u91d1\u725b\u5ea7  226  \u64da\u9ede07   N  \u6975\u4f4e  3G   183.0  \u8cfc\u6a5f\u7d04 -77.0   \n",
        "4  C0180972  NVIP  M  46.0  \u9b54\u7faf\u5ea7   83  \u64da\u9ede04   N   \u4e2d  3G   383.0  \u901a\u4fe1\u7d04 -73.0   \n",
        "\n",
        "   C16  C17 C18 C19  C20  C21  C22 C23  C24  C25  C26  C27  C28  C29  C30  \\\n",
        "0    0    0  \u96f6\u5143  \u96f6\u5143  NaN  NaN    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "1    8    6   \u4e2d   \u9ad8  1.0  4.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "2    2    3  \u4f4e\u4e2d  \u4f4e\u4e2d  2.0  3.0  \u7af6\u696dB   N    2  1.0  1.0  NaN    1  NaN  1.0   \n",
        "3    4    2   \u4f4e  \u96f6\u5143  2.0  1.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "4    2    2   \u4f4e  \u4f4e\u4e2d  3.0  2.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "\n",
        "   C31   C32    C33  C34  C35  C36  C37  C38  C39  C40  C41  C42  C43  C44  \\\n",
        "0  \u7121NP   NaN    NaN  NaN    6    3    1    0    0    1    1    0    2  NaN   \n",
        "1  \u7121NP   NaN    NaN  NaN    4    1    0    1    0    1    1    0    2  Yes   \n",
        "2  \u7af6\u696dA  72.0   72.0  1.0    3    2    0    1    0    0    0    0    2  NaN   \n",
        "3  \u7121NP   NaN    NaN  NaN    8    3    1    2    0    1    1    0    1  Yes   \n",
        "4  \u7af6\u696dD  82.0  106.0  2.0    1    1    0    0    0    0    0    0    1  NaN   \n",
        "\n",
        "   C45 C46           C47    C48    C49  C50    C51    C52  C53   C54    C55  \\\n",
        "0  Yes  No           NaN    NaN    NaN  NaN    NaN    NaN  NaN   NaN    NaN   \n",
        "1  NaN  No  5.165101e+06  99.34  77.32  0.0   7.21  12.93  0.0  0.00   2.93   \n",
        "2  NaN  No           NaN  25.49   6.35  0.0  19.14   0.00  0.0  5.62  13.52   \n",
        "3  NaN  No           NaN  21.43   5.22  0.0  13.64   2.57  0.0  4.07   9.57   \n",
        "4  NaN  No  9.011243e+05  58.42  14.80  0.0  17.35  26.27  0.0  6.35   0.62   \n",
        "\n",
        "    C56   C57   C58  C59   C60   C61  C62   C63   C64   C65   C66   C67  C68  \\\n",
        "0   NaN   NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
        "1  0.00  4.28  0.78  0.0  0.07  0.13  0.0  0.02  0.00  0.03  0.00  0.04  0.0   \n",
        "2  0.00  0.00  0.25  0.0  0.75  0.00  0.0  0.00  0.22  0.53  0.00  0.00  0.0   \n",
        "3  0.00  0.00  0.24  0.0  0.64  0.12  0.0  0.00  0.19  0.45  0.00  0.00  0.0   \n",
        "4  9.88  0.00  0.25  0.0  0.30  0.45  0.0  0.00  0.11  0.01  0.17  0.00  0.0   \n",
        "\n",
        "   C69  C70   C71   C72    C73   C74    C75   C76    C77    C78   C79  C80  \\\n",
        "0  NaN  NaN   NaN   NaN    NaN   NaN    NaN   NaN    NaN    NaN   NaN  NaN   \n",
        "1  0.0  0.0  3.57  1.12   3.95  5.38   0.78  4.22  20.43  59.15  0.75  0.0   \n",
        "2  0.0  0.0  0.00  1.53   8.97  0.00   0.38  0.00   6.05   8.55  0.00  0.0   \n",
        "3  0.0  0.0  0.00  0.40   2.57  7.13   0.22  0.00   9.17   2.87  0.00  0.0   \n",
        "4  0.0  0.0  0.00  8.97  14.07  8.05  23.27  3.23   0.83   0.00  0.00  0.0   \n",
        "\n",
        "   C81  C82   C83   C84   C85   C86   C87   C88   C89   C90   C91  C92  C93  \\\n",
        "0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN  NaN   \n",
        "1  0.0  0.0  0.04  0.01  0.04  0.05  0.01  0.04  0.21  0.60  0.01  \u53f0\u5357\u5e02  \u65b0\u71df\u5340   \n",
        "2  0.0  0.0  0.00  0.06  0.35  0.00  0.01  0.00  0.24  0.34  0.00  \u53f0\u5357\u5e02  \u67f3\u71df\u5340   \n",
        "3  0.0  0.0  0.00  0.02  0.11  0.32  0.01  0.00  0.41  0.13  0.00  \u53f0\u5357\u5e02  \u65b0\u71df\u5340   \n",
        "4  0.0  0.0  0.00  0.15  0.24  0.14  0.40  0.06  0.01  0.00  0.00  \u5f70\u5316\u7e23  \u548c\u7f8e\u93ae   \n",
        "\n",
        "   C94  C95 C96  C97  C98  C99   C100   C101  C102    C103    C104    C105  \\\n",
        "0  NaN  NaN  No   No  NaN  NaN    NaN    NaN   NaN     NaN     NaN     NaN   \n",
        "1  \u53f0\u5357\u5e02  \u65b0\u71df\u5340  No   No  0.0  0.0  132.0    0.0   0.0   0.000   0.000   0.000   \n",
        "2   \\N   \\N  No   No  0.0  0.0  538.0  179.0   0.0  21.645   3.652   7.830   \n",
        "3  \u53f0\u5357\u5e02  \u67f3\u71df\u5340  No  Yes  1.0  0.0  244.0   92.0   0.0  45.672  33.880   5.709   \n",
        "4   \\N   \\N  No   No  1.0  0.0   93.0   72.0   0.0  45.726  46.141  28.992   \n",
        "\n",
        "       C106  C107  C108  C109  C110  C111  C112  C113  C114  C115  C116  C117  \\\n",
        "0       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "1  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   3.0   0.0   0.0   \n",
        "2  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   \n",
        "3  5.704305   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
        "4  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   8.0   1.0   0.0   \n",
        "\n",
        "   C118  C119  C120  C121  C122         C123         C124  C125         C126  \\\n",
        "0   NaN   NaN   NaN   NaN   NaN          NaN          NaN   NaN          NaN   \n",
        "1   0.0   6.0   4.0   1.0   0.0  108701933.0  151396249.0   0.0  640602330.0   \n",
        "2   0.0   0.0   0.0   1.0   0.0          0.0          0.0   0.0          0.0   \n",
        "3   0.0   0.0   0.0   0.0   0.0          0.0          0.0   0.0          0.0   \n",
        "4   0.0   6.0  13.0   0.0   0.0          0.0     562953.0   0.0          0.0   \n",
        "\n",
        "   C127         C128        C129         C130  C131        C132          C133  \\\n",
        "0   NaN          NaN         NaN          NaN   NaN         NaN           NaN   \n",
        "1   0.0  113758047.0  85067978.0  135352031.0   0.0  51434728.0  1.795074e+09   \n",
        "2   0.0          0.0         0.0          0.0   0.0         0.0  0.000000e+00   \n",
        "3   0.0          0.0         0.0          0.0   0.0         0.0  0.000000e+00   \n",
        "4   0.0    6514284.0  45907574.0     581620.0   0.0         0.0  0.000000e+00   \n",
        "\n",
        "       C134         C135  C136  C137          C138  C139         C140  \\\n",
        "0       NaN          NaN   NaN   NaN           NaN   NaN          NaN   \n",
        "1  439151.0  326260868.0   0.0   0.0  1.906637e+09   0.0  557196876.0   \n",
        "2       0.0          0.0   0.0   0.0  0.000000e+00   0.0          0.0   \n",
        "3       0.0          0.0   0.0   0.0  0.000000e+00   0.0          0.0   \n",
        "4       0.0          0.0   0.0   0.0  1.128205e+06   0.0  567134600.0   \n",
        "\n",
        "           C141         C142  C143  C144          C145         C146   C147  \\\n",
        "0           NaN          NaN   NaN   NaN           NaN          NaN    NaN   \n",
        "1  5.169043e+09  448633971.0   0.0   0.0  1.716211e+09  570153410.0  99.35   \n",
        "2  0.000000e+00          0.0   0.0   0.0  0.000000e+00          0.0  25.48   \n",
        "3  0.000000e+00          0.0   0.0   0.0  0.000000e+00          0.0  22.35   \n",
        "4  2.739706e+08   21208770.0   0.0   0.0  0.000000e+00          0.0  58.42   \n",
        "\n",
        "    C148   C149   C150   C151  C152  C153   C154  C155  C156  C157  C158  \\\n",
        "0    NaN    NaN    NaN    NaN   NaN   NaN    NaN   NaN   NaN   NaN   NaN   \n",
        "1  77.32   7.21  12.93  12.93   0.0   0.0  79.21  59.0  24.0  19.0  13.0   \n",
        "2   6.35  19.14   0.00   0.00   0.0   0.0  13.52  16.0   4.0  12.0   0.0   \n",
        "3   6.14  13.64   2.57   2.57   0.0   0.0   6.14  16.0   8.0   6.0   2.0   \n",
        "4  14.80  16.85  26.27  26.27   0.0   0.0  26.27  51.0  12.0  10.0  28.0   \n",
        "\n",
        "   C159  C160  C161  C162  C163  C164  C165  C166  C167  C168  C169  C170  \\\n",
        "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "1  13.0   0.0   0.0  13.0   3.0   0.0   2.0   6.0   0.0   0.0   1.0   0.0   \n",
        "2   0.0   0.0   0.0   9.0   3.0   0.0   6.0   0.0   0.0   1.0   5.0   0.0   \n",
        "3   2.0   0.0   0.0   9.0   4.0   0.0   3.0   2.0   0.0   2.0   1.0   0.0   \n",
        "4  28.0   0.0   0.0  27.0   6.0   0.0   8.0  13.0   0.0   5.0   1.0   1.0   \n",
        "\n",
        "   C171  C172  C173  C174  C175  C176  C177  C178  C179  C180  C181  C182  \\\n",
        "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  13.0   \n",
        "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   9.0   \n",
        "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  10.0   \n",
        "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  27.0   \n",
        "\n",
        "   C183  C184  C185  C186   C187   C188  C189   C190  C191  C192  C193  C194  \\\n",
        "0   NaN   NaN   NaN   NaN   0.00   0.00   0.0   0.00  0.00   0.0  0.00   NaN   \n",
        "1   3.0   2.0   6.0   0.0  90.26  77.32   0.0  12.94  0.86   0.0  0.14  59.0   \n",
        "2   3.0   6.0   0.0   0.0   6.36   6.36   0.0   0.00  1.00   0.0  0.00  16.0   \n",
        "3   5.0   3.0   2.0   0.0   8.70   6.14   0.0   2.56  0.71   0.0  0.29  14.0   \n",
        "4   6.0   7.0  13.0   0.0  41.07  14.80   0.0  26.27  0.36   0.0  0.64  51.0   \n",
        "\n",
        "   C195  C196  C197  C198  C199  C200  C201  C202  C203  C204  C205  C206  \\\n",
        "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   0.0   0.0   0.0   \n",
        "1  24.0   0.0  19.0  13.0   0.0   0.0  17.0   0.0   2.0  37.0  24.0   0.0   \n",
        "2   4.0   0.0  12.0   0.0   0.0   3.0   9.0   0.0   0.0   4.0   4.0   0.0   \n",
        "3   6.0   0.0   6.0   2.0   0.0   3.0   3.0   0.0   0.0  10.0   8.0   0.0   \n",
        "4  12.0   0.0  11.0  28.0   0.0   6.0   1.0   3.0   0.0  40.0  12.0   0.0   \n",
        "\n",
        "   C207 C208  C209  C210   C211           C212      C213   C214          C215  \\\n",
        "0   0.0  NaN   NaN   0.0    0.0            NaN       NaN    NaN           NaN   \n",
        "1  13.0   \u696d\u8005   9.0   2.0  232.0  903739.278320  0.174970  232.0  5.289064e+09   \n",
        "2   0.0  \u7af6\u696dB   3.0   0.0    0.0            NaN       NaN    0.0  0.000000e+00   \n",
        "3   2.0   \u696d\u8005   7.0   1.0    0.0            NaN       NaN    0.0  0.000000e+00   \n",
        "4  28.0   \u56fa\u7db2  24.0   0.0  259.0   57456.744141  0.063761  259.0  9.227513e+08   \n",
        "\n",
        "   pred_C3  C3  \n",
        "0        0   0  \n",
        "1        0   0  \n",
        "2        1   1  \n",
        "3        1   0  \n",
        "4        1   0  "
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Prediction (each cluster)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xp_cData = dfp.loc[:, choosed_for_clustering]\n",
      "\n",
      "for col in Xp_cData.columns:\n",
      "    Xp_cData[col].fillna(0, inplace=True)\n",
      "    Xp_cData[col] = StandardScaler().fit_transform(Xp_cData[col])\n",
      "\n",
      "dfp['clabel'] = kmeans.predict(Xp_cData)\n",
      "\n",
      "for i in xrange(3):\n",
      "    _X = dfp.loc[dfp['clabel']==i, choosed]\n",
      "    for col in _X.columns:\n",
      "      try:\n",
      "        _X[col].fillna(0, inplace=True)\n",
      "        _X[col] = StandardScaler().fit_transform(_X[col])\n",
      "      except:\n",
      "        _X[col] = _X[col].replace({name: n for n, name in enumerate(_X[col].unique())})\n",
      "    dfp.loc[dfp['clabel']==i, 'pred_C3'] = clfs[i].predict(_X)\n",
      "\n",
      "print accuracy_score(dfp['C3'], dfp['pred_C3'])\n",
      "\n",
      "dfp.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.6254\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C2</th>\n",
        "      <th>C4</th>\n",
        "      <th>C5</th>\n",
        "      <th>C6</th>\n",
        "      <th>C7</th>\n",
        "      <th>C8</th>\n",
        "      <th>C9</th>\n",
        "      <th>C10</th>\n",
        "      <th>C11</th>\n",
        "      <th>C12</th>\n",
        "      <th>C13</th>\n",
        "      <th>C14</th>\n",
        "      <th>C15</th>\n",
        "      <th>C16</th>\n",
        "      <th>C17</th>\n",
        "      <th>C18</th>\n",
        "      <th>C19</th>\n",
        "      <th>C20</th>\n",
        "      <th>C21</th>\n",
        "      <th>C22</th>\n",
        "      <th>C23</th>\n",
        "      <th>C24</th>\n",
        "      <th>C25</th>\n",
        "      <th>C26</th>\n",
        "      <th>C27</th>\n",
        "      <th>C28</th>\n",
        "      <th>C29</th>\n",
        "      <th>C30</th>\n",
        "      <th>C31</th>\n",
        "      <th>C32</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C35</th>\n",
        "      <th>C36</th>\n",
        "      <th>C37</th>\n",
        "      <th>C38</th>\n",
        "      <th>C39</th>\n",
        "      <th>C40</th>\n",
        "      <th>C41</th>\n",
        "      <th>C42</th>\n",
        "      <th>C43</th>\n",
        "      <th>C44</th>\n",
        "      <th>C45</th>\n",
        "      <th>C46</th>\n",
        "      <th>C47</th>\n",
        "      <th>C48</th>\n",
        "      <th>C49</th>\n",
        "      <th>C50</th>\n",
        "      <th>C51</th>\n",
        "      <th>C52</th>\n",
        "      <th>C53</th>\n",
        "      <th>C54</th>\n",
        "      <th>C55</th>\n",
        "      <th>C56</th>\n",
        "      <th>C57</th>\n",
        "      <th>C58</th>\n",
        "      <th>C59</th>\n",
        "      <th>C60</th>\n",
        "      <th>C61</th>\n",
        "      <th>C62</th>\n",
        "      <th>C63</th>\n",
        "      <th>C64</th>\n",
        "      <th>C65</th>\n",
        "      <th>C66</th>\n",
        "      <th>C67</th>\n",
        "      <th>C68</th>\n",
        "      <th>C69</th>\n",
        "      <th>C70</th>\n",
        "      <th>C71</th>\n",
        "      <th>C72</th>\n",
        "      <th>C73</th>\n",
        "      <th>C74</th>\n",
        "      <th>C75</th>\n",
        "      <th>C76</th>\n",
        "      <th>C77</th>\n",
        "      <th>C78</th>\n",
        "      <th>C79</th>\n",
        "      <th>C80</th>\n",
        "      <th>C81</th>\n",
        "      <th>C82</th>\n",
        "      <th>C83</th>\n",
        "      <th>C84</th>\n",
        "      <th>C85</th>\n",
        "      <th>C86</th>\n",
        "      <th>C87</th>\n",
        "      <th>C88</th>\n",
        "      <th>C89</th>\n",
        "      <th>C90</th>\n",
        "      <th>C91</th>\n",
        "      <th>C92</th>\n",
        "      <th>C93</th>\n",
        "      <th>C94</th>\n",
        "      <th>C95</th>\n",
        "      <th>C96</th>\n",
        "      <th>C97</th>\n",
        "      <th>C98</th>\n",
        "      <th>C99</th>\n",
        "      <th>C100</th>\n",
        "      <th>C101</th>\n",
        "      <th>C102</th>\n",
        "      <th>C103</th>\n",
        "      <th>C104</th>\n",
        "      <th>C105</th>\n",
        "      <th>C106</th>\n",
        "      <th>C107</th>\n",
        "      <th>C108</th>\n",
        "      <th>C109</th>\n",
        "      <th>C110</th>\n",
        "      <th>C111</th>\n",
        "      <th>C112</th>\n",
        "      <th>C113</th>\n",
        "      <th>C114</th>\n",
        "      <th>C115</th>\n",
        "      <th>C116</th>\n",
        "      <th>C117</th>\n",
        "      <th>C118</th>\n",
        "      <th>C119</th>\n",
        "      <th>C120</th>\n",
        "      <th>C121</th>\n",
        "      <th>C122</th>\n",
        "      <th>C123</th>\n",
        "      <th>C124</th>\n",
        "      <th>C125</th>\n",
        "      <th>C126</th>\n",
        "      <th>C127</th>\n",
        "      <th>C128</th>\n",
        "      <th>C129</th>\n",
        "      <th>C130</th>\n",
        "      <th>C131</th>\n",
        "      <th>C132</th>\n",
        "      <th>C133</th>\n",
        "      <th>C134</th>\n",
        "      <th>C135</th>\n",
        "      <th>C136</th>\n",
        "      <th>C137</th>\n",
        "      <th>C138</th>\n",
        "      <th>C139</th>\n",
        "      <th>C140</th>\n",
        "      <th>C141</th>\n",
        "      <th>C142</th>\n",
        "      <th>C143</th>\n",
        "      <th>C144</th>\n",
        "      <th>C145</th>\n",
        "      <th>C146</th>\n",
        "      <th>C147</th>\n",
        "      <th>C148</th>\n",
        "      <th>C149</th>\n",
        "      <th>C150</th>\n",
        "      <th>C151</th>\n",
        "      <th>C152</th>\n",
        "      <th>C153</th>\n",
        "      <th>C154</th>\n",
        "      <th>C155</th>\n",
        "      <th>C156</th>\n",
        "      <th>C157</th>\n",
        "      <th>C158</th>\n",
        "      <th>C159</th>\n",
        "      <th>C160</th>\n",
        "      <th>C161</th>\n",
        "      <th>C162</th>\n",
        "      <th>C163</th>\n",
        "      <th>C164</th>\n",
        "      <th>C165</th>\n",
        "      <th>C166</th>\n",
        "      <th>C167</th>\n",
        "      <th>C168</th>\n",
        "      <th>C169</th>\n",
        "      <th>C170</th>\n",
        "      <th>C171</th>\n",
        "      <th>C172</th>\n",
        "      <th>C173</th>\n",
        "      <th>C174</th>\n",
        "      <th>C175</th>\n",
        "      <th>C176</th>\n",
        "      <th>C177</th>\n",
        "      <th>C178</th>\n",
        "      <th>C179</th>\n",
        "      <th>C180</th>\n",
        "      <th>C181</th>\n",
        "      <th>C182</th>\n",
        "      <th>C183</th>\n",
        "      <th>C184</th>\n",
        "      <th>C185</th>\n",
        "      <th>C186</th>\n",
        "      <th>C187</th>\n",
        "      <th>C188</th>\n",
        "      <th>C189</th>\n",
        "      <th>C190</th>\n",
        "      <th>C191</th>\n",
        "      <th>C192</th>\n",
        "      <th>C193</th>\n",
        "      <th>C194</th>\n",
        "      <th>C195</th>\n",
        "      <th>C196</th>\n",
        "      <th>C197</th>\n",
        "      <th>C198</th>\n",
        "      <th>C199</th>\n",
        "      <th>C200</th>\n",
        "      <th>C201</th>\n",
        "      <th>C202</th>\n",
        "      <th>C203</th>\n",
        "      <th>C204</th>\n",
        "      <th>C205</th>\n",
        "      <th>C206</th>\n",
        "      <th>C207</th>\n",
        "      <th>C208</th>\n",
        "      <th>C209</th>\n",
        "      <th>C210</th>\n",
        "      <th>C211</th>\n",
        "      <th>C212</th>\n",
        "      <th>C213</th>\n",
        "      <th>C214</th>\n",
        "      <th>C215</th>\n",
        "      <th>pred_C3</th>\n",
        "      <th>C3</th>\n",
        "      <th>clabel</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>9995</th>\n",
        "      <td>C0294226</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>47.0</td>\n",
        "      <td>\u5929\u79e4\u5ea7</td>\n",
        "      <td>88</td>\n",
        "      <td>\u64da\u9ede05</td>\n",
        "      <td>Y</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>4G</td>\n",
        "      <td>1336.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>4</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>2.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>86.0</td>\n",
        "      <td>86.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>1.567282e+06</td>\n",
        "      <td>108.99</td>\n",
        "      <td>33.08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>62.34</td>\n",
        "      <td>13.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>25.57</td>\n",
        "      <td>34.97</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.8</td>\n",
        "      <td>0.30</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.57</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.23</td>\n",
        "      <td>0.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.25</td>\n",
        "      <td>2.77</td>\n",
        "      <td>7.70</td>\n",
        "      <td>33.17</td>\n",
        "      <td>7.47</td>\n",
        "      <td>12.62</td>\n",
        "      <td>10.92</td>\n",
        "      <td>31.07</td>\n",
        "      <td>1.77</td>\n",
        "      <td>1.27</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.30</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.10</td>\n",
        "      <td>0.29</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.01</td>\n",
        "      <td>\u5c4f\u6771\u7e23</td>\n",
        "      <td>\u5c4f\u6771\u5e02</td>\n",
        "      <td>\u5c4f\u6771\u7e23</td>\n",
        "      <td>\u5c4f\u6771\u5e02</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>228.0</td>\n",
        "      <td>15.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>307.476</td>\n",
        "      <td>41.996</td>\n",
        "      <td>253.324</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>16.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>26.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14259319.0</td>\n",
        "      <td>439665398.0</td>\n",
        "      <td>2.949158e+08</td>\n",
        "      <td>7.857726e+07</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>42562618.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11569936.0</td>\n",
        "      <td>305027092.0</td>\n",
        "      <td>7.929694e+08</td>\n",
        "      <td>7.430331e+08</td>\n",
        "      <td>4.815118e+08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9922937.0</td>\n",
        "      <td>76581435.0</td>\n",
        "      <td>9431279.0</td>\n",
        "      <td>108.98</td>\n",
        "      <td>33.09</td>\n",
        "      <td>62.34</td>\n",
        "      <td>13.32</td>\n",
        "      <td>13.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>33.34</td>\n",
        "      <td>103.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>37.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>29.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>29.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>46.41</td>\n",
        "      <td>33.08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.33</td>\n",
        "      <td>0.71</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.29</td>\n",
        "      <td>103.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>37.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>65.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>26.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>195.0</td>\n",
        "      <td>1.928009e+05</td>\n",
        "      <td>0.123016</td>\n",
        "      <td>195.0</td>\n",
        "      <td>1.604897e+09</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9996</th>\n",
        "      <td>C0263886</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>59.0</td>\n",
        "      <td>\u7261\u7f8a\u5ea7</td>\n",
        "      <td>188</td>\n",
        "      <td>\u64da\u9ede07</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-2.0</td>\n",
        "      <td>3</td>\n",
        "      <td>2</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Yes</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>5.67</td>\n",
        "      <td>10.38</td>\n",
        "      <td>0.40</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.34</td>\n",
        "      <td>0.63</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>16.45</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.45</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.00</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>\u56fa\u7db2</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9997</th>\n",
        "      <td>C0167683</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>32.0</td>\n",
        "      <td>\u5929\u880d\u5ea7</td>\n",
        "      <td>129</td>\n",
        "      <td>\u64da\u9ede06</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>4G</td>\n",
        "      <td>1336.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-31.0</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u7af6\u696dC</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>Yes</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>2.453259e+07</td>\n",
        "      <td>144.78</td>\n",
        "      <td>115.93</td>\n",
        "      <td>0.0</td>\n",
        "      <td>18.77</td>\n",
        "      <td>10.08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>18.77</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.80</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>5.3</td>\n",
        "      <td>0.72</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.28</td>\n",
        "      <td>11.20</td>\n",
        "      <td>8.67</td>\n",
        "      <td>16.10</td>\n",
        "      <td>5.20</td>\n",
        "      <td>55.65</td>\n",
        "      <td>30.87</td>\n",
        "      <td>10.17</td>\n",
        "      <td>0.63</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.08</td>\n",
        "      <td>0.06</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.38</td>\n",
        "      <td>0.21</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u65b0\u5317\u5e02</td>\n",
        "      <td>\u571f\u57ce\u5340</td>\n",
        "      <td>\u65b0\u5317\u5e02</td>\n",
        "      <td>\u571f\u57ce\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>51.077</td>\n",
        "      <td>115.313</td>\n",
        "      <td>13.258</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>612945661.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>177152309.0</td>\n",
        "      <td>60247083.0</td>\n",
        "      <td>532005101.0</td>\n",
        "      <td>1.634267e+09</td>\n",
        "      <td>1.884671e+09</td>\n",
        "      <td>0.0</td>\n",
        "      <td>152925231.0</td>\n",
        "      <td>21941803.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.000222e+09</td>\n",
        "      <td>52418707.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>231547895.0</td>\n",
        "      <td>3.251698e+09</td>\n",
        "      <td>1.069934e+10</td>\n",
        "      <td>5.767356e+09</td>\n",
        "      <td>0.0</td>\n",
        "      <td>91557009.0</td>\n",
        "      <td>679913317.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>144.78</td>\n",
        "      <td>115.93</td>\n",
        "      <td>18.77</td>\n",
        "      <td>10.08</td>\n",
        "      <td>10.08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>115.93</td>\n",
        "      <td>73.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>126.00</td>\n",
        "      <td>115.92</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.08</td>\n",
        "      <td>0.92</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.08</td>\n",
        "      <td>73.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>62.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>26.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>227.0</td>\n",
        "      <td>1.653876e+06</td>\n",
        "      <td>0.067415</td>\n",
        "      <td>227.0</td>\n",
        "      <td>2.512137e+10</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9998</th>\n",
        "      <td>C0132373</td>\n",
        "      <td>VIP4</td>\n",
        "      <td>M</td>\n",
        "      <td>62.0</td>\n",
        "      <td>\u5929\u79e4\u5ea7</td>\n",
        "      <td>248</td>\n",
        "      <td>\u64da\u9ede13</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>3G</td>\n",
        "      <td>983.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-50.0</td>\n",
        "      <td>5</td>\n",
        "      <td>5</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>3.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>257.13</td>\n",
        "      <td>46.80</td>\n",
        "      <td>0.0</td>\n",
        "      <td>149.55</td>\n",
        "      <td>60.58</td>\n",
        "      <td>0.0</td>\n",
        "      <td>115.73</td>\n",
        "      <td>33.82</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.18</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.58</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.45</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.70</td>\n",
        "      <td>4.35</td>\n",
        "      <td>47.37</td>\n",
        "      <td>122.25</td>\n",
        "      <td>24.65</td>\n",
        "      <td>30.93</td>\n",
        "      <td>4.32</td>\n",
        "      <td>10.50</td>\n",
        "      <td>6.12</td>\n",
        "      <td>5.95</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.18</td>\n",
        "      <td>0.48</td>\n",
        "      <td>0.10</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.02</td>\n",
        "      <td>\u82d7\u6817\u7e23</td>\n",
        "      <td>\u901a\u9704\u93ae</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>12.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>163.0</td>\n",
        "      <td>75.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>480.431</td>\n",
        "      <td>131.628</td>\n",
        "      <td>129.690</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.0</td>\n",
        "      <td>15.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>257.13</td>\n",
        "      <td>46.80</td>\n",
        "      <td>149.55</td>\n",
        "      <td>60.58</td>\n",
        "      <td>60.58</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>115.73</td>\n",
        "      <td>136.0</td>\n",
        "      <td>32.0</td>\n",
        "      <td>68.0</td>\n",
        "      <td>35.0</td>\n",
        "      <td>35.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>23.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>23.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>107.38</td>\n",
        "      <td>46.79</td>\n",
        "      <td>0.0</td>\n",
        "      <td>60.59</td>\n",
        "      <td>0.44</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.56</td>\n",
        "      <td>136.0</td>\n",
        "      <td>32.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>68.0</td>\n",
        "      <td>35.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>37.0</td>\n",
        "      <td>31.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>67.0</td>\n",
        "      <td>32.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>35.0</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>54.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9999</th>\n",
        "      <td>C0010487</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>45.0</td>\n",
        "      <td>\u5929\u880d\u5ea7</td>\n",
        "      <td>74</td>\n",
        "      <td>\u64da\u9ede02</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u7121\u7d81\u7d04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7af6\u696dD</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>6.86</td>\n",
        "      <td>4.43</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>2.43</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.65</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.35</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.27</td>\n",
        "      <td>1.50</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.00</td>\n",
        "      <td>2.97</td>\n",
        "      <td>0.23</td>\n",
        "      <td>0.77</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.18</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.43</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>6.87</td>\n",
        "      <td>4.43</td>\n",
        "      <td>0.00</td>\n",
        "      <td>2.43</td>\n",
        "      <td>2.43</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.43</td>\n",
        "      <td>15.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.86</td>\n",
        "      <td>4.43</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.43</td>\n",
        "      <td>0.65</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.35</td>\n",
        "      <td>15.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>15.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "            C2    C4 C5    C6   C7   C8    C9 C10 C11 C12     C13  C14   C15  \\\n",
        "9995  C0294226  NVIP  F  47.0  \u5929\u79e4\u5ea7   88  \u64da\u9ede05   Y   \u4e2d  4G  1336.0  \u901a\u4fe1\u7d04   NaN   \n",
        "9996  C0263886  NVIP  F  59.0  \u7261\u7f8a\u5ea7  188  \u64da\u9ede07   N  \u6975\u4f4e  3G   183.0  \u8cfc\u6a5f\u7d04  -2.0   \n",
        "9997  C0167683  NVIP  M  32.0  \u5929\u880d\u5ea7  129  \u64da\u9ede06   N   \u4e2d  4G  1336.0  \u901a\u4fe1\u7d04 -31.0   \n",
        "9998  C0132373  VIP4  M  62.0  \u5929\u79e4\u5ea7  248  \u64da\u9ede13   N   \u4e2d  3G   983.0  \u8cfc\u6a5f\u7d04 -50.0   \n",
        "9999  C0010487  NVIP  M  45.0  \u5929\u880d\u5ea7   74  \u64da\u9ede02   N  \u6975\u4f4e  3G   183.0  \u7121\u7d81\u7d04   NaN   \n",
        "\n",
        "      C16  C17 C18 C19  C20  C21  C22 C23  C24  C25  C26  C27  C28  C29  C30  \\\n",
        "9995    4    4   \u4e2d  \u4f4e\u4e2d  2.0  4.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "9996    3    2  \u4f4e\u4e2d  \u4f4e\u4e2d  NaN  1.0  \u7af6\u696dB   N    1  NaN  1.0  NaN    1  NaN  NaN   \n",
        "9997    3    3   \u4e2d   \u4e2d  1.0  2.0  \u7af6\u696dC   N    1  NaN  NaN  NaN    1  NaN  NaN   \n",
        "9998    5    5  \u4f4e\u4e2d  \u96f6\u5143  NaN  3.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "9999    0    0  \u96f6\u5143  \u96f6\u5143  NaN  NaN  \u7af6\u696dD   N    1  NaN  NaN  NaN    1  NaN  NaN   \n",
        "\n",
        "      C31   C32   C33  C34  C35  C36  C37  C38  C39  C40  C41  C42  C43  C44  \\\n",
        "9995  \u7af6\u696dB  86.0  86.0  1.0    3    3    0    0    0    0    0    0    3  NaN   \n",
        "9996  \u7121NP   NaN   NaN  NaN    2    1    0    1    0    0    0    0    2  NaN   \n",
        "9997  \u7121NP   NaN   NaN  NaN    1    1    0    0    0    0    0    0    1  Yes   \n",
        "9998  \u7121NP   NaN   NaN  NaN    4    1    1    1    0    0    1    0    3  NaN   \n",
        "9999  \u7121NP   NaN   NaN  NaN    4    4    0    0    0    0    0    0    3  NaN   \n",
        "\n",
        "      C45 C46           C47     C48     C49  C50     C51    C52  C53     C54  \\\n",
        "9995  NaN  No  1.567282e+06  108.99   33.08  0.0   62.34  13.32  0.0   25.57   \n",
        "9996  Yes  No           NaN   16.45    0.00  0.0    0.00  16.45  0.0    0.00   \n",
        "9997  NaN  No  2.453259e+07  144.78  115.93  0.0   18.77  10.08  0.0    0.00   \n",
        "9998  NaN  No           NaN  257.13   46.80  0.0  149.55  60.58  0.0  115.73   \n",
        "9999  NaN  No           NaN    6.86    4.43  0.0    0.00   2.43  0.0    0.00   \n",
        "\n",
        "        C55  C56  C57   C58  C59   C60   C61  C62  C63   C64   C65  C66   C67  \\\n",
        "9995  34.97  0.0  1.8  0.30  0.0  0.57  0.12  0.0  0.0  0.23  0.32  0.0  0.02   \n",
        "9996   0.00  0.0  0.0  0.00  0.0  0.00  1.00  0.0  0.0  0.00  0.00  0.0  0.00   \n",
        "9997  18.77  0.0  0.0  0.80  0.0  0.13  0.07  0.0  0.0  0.00  0.13  0.0  0.00   \n",
        "9998  33.82  0.0  0.0  0.18  0.0  0.58  0.24  0.0  0.0  0.45  0.13  0.0  0.00   \n",
        "9999   0.00  0.0  0.0  0.65  0.0  0.00  0.35  0.0  0.0  0.00  0.00  0.0  0.00   \n",
        "\n",
        "      C68   C69   C70   C71    C72     C73    C74    C75    C76    C77    C78  \\\n",
        "9995  0.0  0.00  0.25  2.77   7.70   33.17   7.47  12.62  10.92  31.07   1.77   \n",
        "9996  0.0  0.00  0.00  0.00   0.00    5.67  10.38   0.40   0.00   0.00   0.00   \n",
        "9997  5.3  0.72  0.00  0.28  11.20    8.67  16.10   5.20  55.65  30.87  10.17   \n",
        "9998  0.0  0.00  0.70  4.35  47.37  122.25  24.65  30.93   4.32  10.50   6.12   \n",
        "9999  0.0  0.00  0.00  0.00   1.27    1.50   0.13   0.00   2.97   0.23   0.77   \n",
        "\n",
        "       C79   C80  C81  C82   C83   C84   C85   C86   C87   C88   C89   C90  \\\n",
        "9995  1.27  0.00  0.0  0.0  0.03  0.07  0.30  0.07  0.12  0.10  0.29  0.02   \n",
        "9996  0.00  0.00  0.0  0.0  0.00  0.00  0.34  0.63  0.02  0.00  0.00  0.00   \n",
        "9997  0.63  0.04  0.0  0.0  0.00  0.08  0.06  0.11  0.04  0.38  0.21  0.07   \n",
        "9998  5.95  0.00  0.0  0.0  0.02  0.18  0.48  0.10  0.12  0.02  0.04  0.02   \n",
        "9999  0.00  0.00  0.0  0.0  0.00  0.18  0.22  0.02  0.00  0.43  0.03  0.11   \n",
        "\n",
        "       C91  C92  C93  C94  C95  C96  C97   C98  C99   C100  C101  C102  \\\n",
        "9995  0.01  \u5c4f\u6771\u7e23  \u5c4f\u6771\u5e02  \u5c4f\u6771\u7e23  \u5c4f\u6771\u5e02   No   No   0.0  1.0  228.0  15.0   0.0   \n",
        "9996  0.00  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN    NaN   NaN   NaN   \n",
        "9997  0.00  \u65b0\u5317\u5e02  \u571f\u57ce\u5340  \u65b0\u5317\u5e02  \u571f\u57ce\u5340   No   No   0.0  0.0    0.0   0.0   0.0   \n",
        "9998  0.02  \u82d7\u6817\u7e23  \u901a\u9704\u93ae   \\N   \\N   No   No  12.0  4.0  163.0  75.0   0.0   \n",
        "9999  0.00  NaN  NaN  NaN  NaN   No   No   NaN  NaN    NaN   NaN   NaN   \n",
        "\n",
        "         C103     C104     C105  C106  C107  C108  C109  C110  C111  C112  \\\n",
        "9995  307.476   41.996  253.324   0.0   0.0   0.0   0.0   0.0  10.0   0.0   \n",
        "9996      NaN      NaN      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "9997   51.077  115.313   13.258   0.0   2.0   0.0   0.0   0.0   6.0   3.0   \n",
        "9998  480.431  131.628  129.690   0.0   3.0   0.0   0.0   0.0  16.0  15.0   \n",
        "9999      NaN      NaN      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "\n",
        "      C113  C114  C115  C116  C117  C118  C119  C120  C121  C122  C123  \\\n",
        "9995   4.0   0.0  12.0  12.0   1.0  16.0   4.0  26.0   1.0   1.0   0.0   \n",
        "9996   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "9997  13.0   1.0   9.0   2.0   0.0  14.0   5.0  17.0   1.0   0.0   0.0   \n",
        "9998   9.0   2.0  12.0  14.0   0.0  10.0  17.0  24.0   5.0   0.0   0.0   \n",
        "9999   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "\n",
        "             C124  C125         C126        C127         C128          C129  \\\n",
        "9995          0.0   0.0          0.0  14259319.0  439665398.0  2.949158e+08   \n",
        "9996          NaN   NaN          NaN         NaN          NaN           NaN   \n",
        "9997  612945661.0   0.0  177152309.0  60247083.0  532005101.0  1.634267e+09   \n",
        "9998          0.0   0.0          0.0         0.0          0.0  0.000000e+00   \n",
        "9999          NaN   NaN          NaN         NaN          NaN           NaN   \n",
        "\n",
        "              C130  C131         C132        C133  C134          C135  \\\n",
        "9995  7.857726e+07   0.0          0.0         0.0   0.0  0.000000e+00   \n",
        "9996           NaN   NaN          NaN         NaN   NaN           NaN   \n",
        "9997  1.884671e+09   0.0  152925231.0  21941803.0   0.0  3.000222e+09   \n",
        "9998  0.000000e+00   0.0          0.0         0.0   0.0  0.000000e+00   \n",
        "9999           NaN   NaN          NaN         NaN   NaN           NaN   \n",
        "\n",
        "            C136  C137        C138         C139          C140          C141  \\\n",
        "9995  42562618.0   0.0  11569936.0  305027092.0  7.929694e+08  7.430331e+08   \n",
        "9996         NaN   NaN         NaN          NaN           NaN           NaN   \n",
        "9997  52418707.0   0.0         0.0  231547895.0  3.251698e+09  1.069934e+10   \n",
        "9998         0.0   0.0         0.0          0.0  0.000000e+00  0.000000e+00   \n",
        "9999         NaN   NaN         NaN          NaN           NaN           NaN   \n",
        "\n",
        "              C142  C143        C144         C145       C146    C147    C148  \\\n",
        "9995  4.815118e+08   0.0   9922937.0   76581435.0  9431279.0  108.98   33.09   \n",
        "9996           NaN   NaN         NaN          NaN        NaN   16.45    0.00   \n",
        "9997  5.767356e+09   0.0  91557009.0  679913317.0        0.0  144.78  115.93   \n",
        "9998  0.000000e+00   0.0         0.0          0.0        0.0  257.13   46.80   \n",
        "9999           NaN   NaN         NaN          NaN        NaN    6.87    4.43   \n",
        "\n",
        "        C149   C150   C151  C152  C153    C154   C155  C156  C157  C158  C159  \\\n",
        "9995   62.34  13.32  13.32   0.0   0.0   33.34  103.0  57.0  37.0   8.0   8.0   \n",
        "9996    0.00  16.45  16.45   0.0   0.0   16.45   17.0   0.0   0.0  17.0  17.0   \n",
        "9997   18.77  10.08  10.08   0.0   0.0  115.93   73.0  57.0  11.0   5.0   5.0   \n",
        "9998  149.55  60.58  60.58   0.0   0.0  115.73  136.0  32.0  68.0  35.0  35.0   \n",
        "9999    0.00   2.43   2.43   0.0   0.0    4.43   15.0  13.0   0.0   2.0   2.0   \n",
        "\n",
        "      C160  C161  C162  C163  C164  C165  C166  C167  C168  C169  C170  C171  \\\n",
        "9995   0.0   0.0  29.0  10.0   0.0  13.0   5.0   0.0   9.0   3.0   0.0   1.0   \n",
        "9996   0.0   0.0   2.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0   \n",
        "9997   0.0   0.0  18.0  10.0   0.0   5.0   3.0   0.0   0.0   5.0   0.0   0.0   \n",
        "9998   0.0   0.0  23.0   8.0   0.0   9.0   5.0   0.0   3.0   6.0   0.0   0.0   \n",
        "9999   0.0   0.0   4.0   3.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n",
        "\n",
        "      C172  C173  C174  C175  C176  C177  C178  C179  C180  C181  C182  C183  \\\n",
        "9995   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  29.0  10.0   \n",
        "9996   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   \n",
        "9997   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  18.0  10.0   \n",
        "9998   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  23.0   8.0   \n",
        "9999   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0   3.0   \n",
        "\n",
        "      C184  C185  C186    C187    C188  C189   C190  C191  C192  C193   C194  \\\n",
        "9995  13.0   5.0   0.0   46.41   33.08   0.0  13.33  0.71   0.0  0.29  103.0   \n",
        "9996   0.0   2.0   0.0   16.45    0.00   0.0  16.45  0.00   0.0  1.00   17.0   \n",
        "9997   5.0   3.0   0.0  126.00  115.92   0.0  10.08  0.92   0.0  0.08   73.0   \n",
        "9998   9.0   5.0   0.0  107.38   46.79   0.0  60.59  0.44   0.0  0.56  136.0   \n",
        "9999   0.0   1.0   0.0    6.86    4.43   0.0   2.43  0.65   0.0  0.35   15.0   \n",
        "\n",
        "      C195  C196  C197  C198  C199  C200  C201  C202  C203  C204  C205  C206  \\\n",
        "9995  57.0   0.0  37.0   8.0   0.0  28.0   7.0   0.0   2.0  65.0  57.0   0.0   \n",
        "9996   0.0   0.0   0.0  17.0   0.0   0.0   0.0   0.0   0.0  17.0   0.0   0.0   \n",
        "9997  57.0   0.0  11.0   5.0   0.0   0.0  11.0   0.0   0.0  62.0  57.0   0.0   \n",
        "9998  32.0   0.0  68.0  35.0   0.0  37.0  31.0   0.0   0.0  67.0  32.0   0.0   \n",
        "9999  13.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0  15.0  13.0   0.0   \n",
        "\n",
        "      C207 C208  C209  C210   C211          C212      C213   C214  \\\n",
        "9995   8.0   \u696d\u8005  26.0   0.0  195.0  1.928009e+05  0.123016  195.0   \n",
        "9996  17.0   \u56fa\u7db2   3.0   0.0    0.0           NaN       NaN    0.0   \n",
        "9997   5.0   \u696d\u8005  26.0   0.0  227.0  1.653876e+06  0.067415  227.0   \n",
        "9998  35.0  \u7af6\u696dA  54.0   0.0    0.0           NaN       NaN    0.0   \n",
        "9999   2.0   \u696d\u8005   6.0   0.0    0.0           NaN       NaN    0.0   \n",
        "\n",
        "              C215  pred_C3  C3  clabel  \n",
        "9995  1.604897e+09        1   0       1  \n",
        "9996  0.000000e+00        0   1       0  \n",
        "9997  2.512137e+10        0   1       2  \n",
        "9998  0.000000e+00        1   0       0  \n",
        "9999  0.000000e+00        0   1       2  "
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "fpr1, tpr1, _ = roc_curve(y_test, clf1.predict_proba(X_test)[:, 1])\n",
      "fpr2, tpr2, _ = roc_curve(y_test, clf2.predict_proba(X_test)[:, 1])\n",
      "fpr3, tpr3, _ = roc_curve(y_test, clf3.predict_proba(X_test)[:, 1])\n",
      "fpr4, tpr4, _ = roc_curve(y_test, clf4.predict_proba(X_test)[:, 1])\n",
      "fprv, tprv, _ = roc_curve(y_test, vclf.predict_proba(X_test)[:, 1])\n",
      "\n",
      "plt.plot(fpr1, tpr1, label='Naive Bayes')\n",
      "plt.plot(fpr2, tpr2, label='Logistic Regression')\n",
      "plt.plot(fpr3, tpr3, label='Random Forest')\n",
      "plt.plot(fpr4, tpr4, label='SVM')\n",
      "plt.plot(fprv, tprv, label='Voting Classifier')\n",
      "\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('ROC curve')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGBgMBoMhBVMMDAaDwZDi/z8Ll+CeDv+OAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0xd732ff0>"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "C001 \u6708\u4efd C002 \u8a2d\u5099\u6d41\u6c34\u865f C003 \u662f\u5426NPOUT C004 VIP\u7b49\u7d1a C005 \u6027\u5225[\u7528\u6236] C006 \u5e74\u9f61[\u7528\u6236] C007 \u661f\u5ea7[\u7528\u6236] C008 [\u884c\u52d5]\u5e74\u8cc7 C009 \u64da\u9ede C010 \u662f\u5426\u70ba\u7279\u7d04\n",
      "\n",
      "C011 [\u7528\u6236]\u5e33\u55ae\u7e3d\u91d1\u984d(\u4f4e/\u4f4e\u4e2d/\u4e2d/\u4e2d\u9ad8/\u9ad8) C012 [\u884c\u52d5]\u9580\u865f\u8cc7\u8cbb\u985e\u578b C013 [\u884c\u52d5]\u9580\u865f\u8cc7\u8cbb\u8cbb\u7387 C014 \u6700\u5f8c\u7d81\u7d04\u985e\u578b C015 \u7d81\u7d04\u5230\u671f\u6708\u6578 C016 \u624b\u6a5f\u7d81\u7d04\u6b21\u6578(\u81ea\u958b\u53f0) C017 \u624b\u6a5f\u8cfc\u8cb7\u6b21\u6578(\u81ea\u958b\u53f0) C018 \u624b\u6a5f\u5e73\u5747\u8cfc\u8cb7\u91d1\u984d\u7d1a\u8ddd(\u81ea2008\u5e74) C019 \u624b\u6a5f\u6700\u8fd1\u8cfc\u8cb7\u91d1\u984d\u7d1a\u8ddd(\u81ea2008\u5e74) C020 \u901a\u4fe1\u7d81\u7d04\u6b21\u6578\n",
      "\n",
      "C021 \u8cfc\u6a5f\u7d81\u7d04\u6b21\u6578 C022 NP\u696d\u8005[\u7528\u6236] C023 \u5047NP\u72c0\u614b[\u7528\u6236] C024 NP\u6b21\u6578[\u7528\u6236] C025 NPIN\u4e2d\u83ef\u6b21\u6578[\u7528\u6236] C026 NPIN\u7af6\u696dA\u6b21\u6578[\u7528\u6236] C027 NPIN\u7af6\u696dB\u6b21\u6578[\u7528\u6236] C028 NPOUT\u4e2d\u83ef\u6b21\u6578[\u7528\u6236] C029 NPOUT\u7af6\u696dA\u6b21\u6578[\u7528\u6236] C030 NPOUT\u7af6\u696dB\u6b21\u6578[\u7528\u6236]\n",
      "\n",
      "C031 [\u884c\u52d5]\u5148\u524d\u662f\u5426\u70baNPIN C032 [\u884c\u52d5]\u6700\u8fd1\u7684NP\u6642\u9593 C033 [\u884c\u52d5]\u6700\u4e45\u7684NP\u6642\u9593 C034 [\u884c\u52d5]NP\u6b21\u6578 C035 [\u5ba2\u6236]\u7528\u6236\u8a2d\u5099\u7e3d\u6578 C036 [\u5ba2\u6236]\u884c\u52d5\u7528\u6236\u8a2d\u5099\u6578 C037 [\u5ba2\u6236]MOD\u7528\u6236\u8a2d\u5099\u6578 C038 [\u5ba2\u6236]\u5e02\u8a71\u7528\u6236\u8a2d\u5099\u6578 C039 [\u5ba2\u6236]\u56fa\u7db2\u975e\u5e02\u8a71\u7528\u6236\u8a2d\u5099\u6578 C040 [\u5ba2\u6236]\u5149\u4e16\u4ee3\u696d\u52d9\u7528\u6236\u8a2d\u5099\u6578\n",
      "\n",
      "C041 [\u5ba2\u6236]HiNet\u7528\u6236\u8a2d\u5099\u6578 C042 [\u5ba2\u6236]\u5176\u4ed6\u7528\u6236\u8a2d\u5099\u6578 C043 [\u5ba2\u6236]\u540c\u4e00\u5ba2\u6236\u6b78\u5c6c\u4e4b\u5bb6\u6236\u6578 C044 [\u7528\u6236]\u96fb\u5b50\u5e33\u55ae\u8b58\u5225 C045 [\u7528\u6236]\u4e0d\u5bc4\u9001\u5ee3\u544a\u8b58\u5225\u6b04 C046 [\u884c\u52d5]\u4e0d\u63a5\u53d7\u96fb\u8a71\u4fc3\u92b7\u8b58\u5225 C047 [\u884c\u52d5]\u6578\u64da\u7e3dMB\u91cf C048 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7e3d\u5206\u9418\u6578 C049 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u5206\u9418\u6578 C050 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u5206\u9418\u6578\n",
      "\n",
      "C051 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u5206\u9418\u6578 C052 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u5206\u9418\u6578 C053 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u5206\u9418\u6578 C054 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u5206\u9418\u6578 C055 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u5206\u9418\u6578 C056 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u5206\u9418\u6578 C057 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u5206\u9418\u6578 C058 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u5206\u9418\u6578\u6bd4\u4f8b C059 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u5206\u9418\u6578\u6bd4\u4f8b C060 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u5206\u9418\u6578\u6bd4\u4f8b\n",
      "\n",
      "C061 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u5206\u9418\u6578\u6bd4\u4f8b C062 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u5206\u9418\u6578\u6bd4\u4f8b C063 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u52a0\u503c\u5206\u9418\u6578\u6bd4\u4f8b C064 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u5206\u9418\u6578\u6bd4\u4f8b C065 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u5206\u9418\u6578\u6bd4\u4f8b C066 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u5206\u9418\u6578\u6bd4\u4f8b C067 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u5206\u9418\u6578\u6bd4\u4f8b C068 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb500_02 C069 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb502_04 C070 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb504_06\n",
      "\n",
      "C071 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb506_08 C072 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb508_10 C073 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb510_12 C074 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb512_14 C075 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb514_16 C076 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb516_18 C077 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb518_20 C078 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb520_22 C079 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb522_24 C080 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb500_02\u6bd4\u4f8b\n",
      "\n",
      "C081 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb502_04\u6bd4\u4f8b C082 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb504_06\u6bd4\u4f8b C083 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb506_08\u6bd4\u4f8b C084 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb508_10\u6bd4\u4f8b C085 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb510_12\u6bd4\u4f8b C086 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb512_14\u6bd4\u4f8b C087 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb514_16\u6bd4\u4f8b C088 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb516_18\u6bd4\u4f8b C089 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb518_20\u6bd4\u4f8b C090 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb520_22\u6bd4\u4f8b\n",
      "\n",
      "C091 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb522_24\u6bd4\u4f8b C092 [\u884c\u52d5]\u5c45\u4f4f\u5730\u57ce\u5e02 C093 [\u884c\u52d5]\u5c45\u4f4f\u5730\u884c\u653f\u5340 C094 [\u884c\u52d5]\u5de5\u4f5c\u5730\u57ce\u5e02 C095 [\u884c\u52d5]\u5de5\u4f5c\u5730\u884c\u653f\u5340 C096 [\u884c\u52d5]\u66f4\u63db\u5c45\u4f4f\u5730 C097 [\u884c\u52d5]\u66f4\u63db\u4e0a\u73ed\u5730 C098 [\u884c\u52d5]\u5e73\u65e5\u5916\u5bbf\u5929\u6578 C099 [\u884c\u52d5]\u9031\u672b\u5916\u5bbf\u5929\u6578 C100 [\u884c\u52d5]\u5e73\u65e5\u5c45\u5bb6\u6642\u9593\n",
      "\n",
      "C101 [\u884c\u52d5]\u5047\u65e5\u5c45\u5bb6\u6642\u9593 C102 [\u884c\u52d5]\u5e73\u65e5\u79fb\u52d5\u8ddd\u96e2sumKM C103 [\u884c\u52d5]\u9031\u672b\u79fb\u52d5\u8ddd\u96e2sumKM C104 [\u884c\u52d5]\u5e73\u65e5\u79fb\u52d5\u6700\u9060\u8ddd\u96e2maxKM C105 [\u884c\u52d5]\u9031\u672b\u79fb\u52d5\u6700\u9060\u8ddd\u96e2maxKM C106 [\u884c\u52d5]\u901a\u52e4\u8ddd\u96e2 C107 [\u884c\u52d5]\u79d1\u6280\u5712\u5340 C108 [\u884c\u52d5]\u5047\u65e5\u642d\u4e58\u9ad8\u9435\u6b21\u6578 C109 [\u884c\u52d5]\u5e73\u65e5\u642d\u4e58\u9ad8\u9435\u6b21\u6578 C110 [\u884c\u52d5]\u5728\u570b\u5916\u7684\u5929\u6578\n",
      "\n",
      "C111 [\u884c\u52d5]\u4f4d\u65bc\u767e\u8ca8\u516c\u53f8\u7684\u5929\u6578 C112 [\u884c\u52d5]\u4f4d\u65bc\u8cfc\u7269\u4e2d\u5fc3\u7684\u5929\u6578 C113 [\u884c\u52d5]\u4f4d\u65bc\u751f\u6d3b\u91cf\u8ca9\u7684\u5929\u6578 C114 [\u884c\u52d5]\u4f4d\u65bc\u50a2\u98fe\u91cf\u8ca9\u7684\u5929\u6578 C115 [\u884c\u52d5]\u4f4d\u65bc\u65c5\u904a\u666f\u9ede\u7684\u5929\u6578 C116 [\u884c\u52d5]\u4f4d\u65bc\u96fb\u5f71\u9662\u7684\u5929\u6578 C117 [\u884c\u52d5]\u4f4d\u65bc\u5c55\u6f14\u7684\u5929\u6578 C118 [\u884c\u52d5]\u4f4d\u65bc\u9ad4\u80b2\u9928/\u5834\u7684\u5929\u6578 C119 [\u884c\u52d5]\u4f4d\u65bc\u706b\u8eca/\u9ad8\u9435\u7ad9\u7684\u5929\u6578 C120 [\u884c\u52d5]\u4f4d\u65bc\u91ab\u7642\u4fdd\u5065\u7684\u5929\u6578\n",
      "\n",
      "C121 [\u884c\u52d5]\u4f4d\u65bc\u6baf\u846c\u7684\u5929\u6578 C122 [\u884c\u52d5]\u4f4d\u65bc\u9ad8\u723e\u592b\u7403\u5834\u7684\u5929\u6578 C123 [\u884c\u52d5]\u5047\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C124 [\u884c\u52d5]\u5047\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C125 [\u884c\u52d5]\u5047\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C126 [\u884c\u52d5]\u5047\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C127 [\u884c\u52d5]\u5047\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C128 [\u884c\u52d5]\u5047\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C129 [\u884c\u52d5]\u5047\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C130 [\u884c\u52d5]\u5047\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00)\n",
      "\n",
      "C131 [\u884c\u52d5]\u5047\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C132 [\u884c\u52d5]\u5047\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C133 [\u884c\u52d5]\u5047\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C134 [\u884c\u52d5]\u5047\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C135 [\u884c\u52d5]\u5e73\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C136 [\u884c\u52d5]\u5e73\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C137 [\u884c\u52d5]\u5e73\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C138 [\u884c\u52d5]\u5e73\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C139 [\u884c\u52d5]\u5e73\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C140 [\u884c\u52d5]\u5e73\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00)\n",
      "\n",
      "C141 [\u884c\u52d5]\u5e73\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C142 [\u884c\u52d5]\u5e73\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C143 [\u884c\u52d5]\u5e73\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C144 [\u884c\u52d5]\u5e73\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C145 [\u884c\u52d5]\u5e73\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C146 [\u884c\u52d5]\u5e73\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C147 [\u884c\u52d5]\u8a9e\u97f3\u901a\u8a71\u5206\u9418\u6578 C148 [\u884c\u52d5]\u4e2d\u83ef\u884c\u52d5\u901a\u8a71\u5206\u9418\u6578 C149 [\u884c\u52d5]\u975e\u4e2d\u83ef\u884c\u52d5\u901a\u8a71\u5206\u9418\u6578 C150 [\u884c\u52d5]\u5e02\u8a71\u901a\u8a71\u5206\u9418\u6578\n",
      "\n",
      "C151 [\u884c\u52d5]\u4e2d\u83ef\u5e02\u8a71\u901a\u8a71\u5206\u9418\u6578 C152 [\u884c\u52d5]\u975e\u4e2d\u83ef\u5e02\u8a71\u901a\u8a71\u5206\u9418\u6578 C153 [\u884c\u52d5]\u570b\u969b\u901a\u8a71\u5206\u9418\u6578 C154 [\u884c\u52d5]\u6700\u5e38\u767c\u8a71\u884c\u52d5\u96fb\u4fe1\u696d\u8005\u5206\u9418\u6578 C155 [\u884c\u52d5]\u8a9e\u97f3\u901a\u8a71\u901a\u6578 C156 [\u884c\u52d5]\u4e2d\u83ef\u884c\u52d5\u901a\u8a71\u901a\u6578 C157 [\u884c\u52d5]\u975e\u4e2d\u83ef\u884c\u52d5\u901a\u8a71\u901a\u6578 C158 [\u884c\u52d5]\u5e02\u8a71\u901a\u8a71\u901a\u6578 C159 [\u884c\u52d5]\u4e2d\u83ef\u5e02\u8a71\u901a\u8a71\u901a\u6578 C160 [\u884c\u52d5]\u975e\u4e2d\u83ef\u5e02\u8a71\u901a\u8a71\u901a\u6578\n",
      "\n",
      "C161 [\u884c\u52d5]\u570b\u969b\u901a\u8a71\u901a\u6578 C162 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7e3d\u5c0d\u8c61\u6578 C163 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u5c0d\u8c61\u6578 C164 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u5c0d\u8c61\u6578 C165 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u5c0d\u8c61\u6578 C166 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u5c0d\u8c61\u6578 C167 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u5c0d\u8c61\u6578 C168 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u5c0d\u8c61\u6578 C169 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u5c0d\u8c61\u6578 C170 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u5c0d\u8c61\u6578\n",
      "\n",
      "C171 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u5c0d\u8c61\u6578 C172 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u5c0d\u8c61\u6578\u6bd4\u4f8b C173 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u5c0d\u8c61\u6578\u6bd4\u4f8b C174 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u5c0d\u8c61\u6578\u6bd4\u4f8b C175 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u5c0d\u8c61\u6578\u6bd4\u4f8b C176 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u5c0d\u8c61\u6578\u6bd4\u4f8b C177 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u52a0\u503c\u5c0d\u8c61\u6578\u6bd4\u4f8b C178 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u5c0d\u8c61\u6578\u6bd4\u4f8b C179 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u5c0d\u8c61\u6578\u6bd4\u4f8b C180 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u5c0d\u8c61\u6578\u6bd4\u4f8b\n",
      "\n",
      "C181 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u5c0d\u8c61\u6578\u6bd4\u4f8b C182 [\u884c\u52d5]\u767c\u8a71\u5c0d\u8c61\u6578 C183 [\u884c\u52d5]\u4e2d\u83ef\u884c\u52d5\u767c\u8a71\u5c0d\u8c61\u6578 C184 [\u884c\u52d5]\u975e\u4e2d\u83ef\u884c\u52d5\u767c\u8a71\u5c0d\u8c61\u6578 C185 [\u884c\u52d5]\u5e02\u8a71\u767c\u8a71\u5c0d\u8c61\u6578\n",
      "C186 [\u884c\u52d5]\u570b\u969b\u767c\u8a71\u5c0d\u8c61\u6578 C187 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7e3d\u5206\u9418\u6578 C188 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5167\u5206\u9418\u6578 C189 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5916\u5206\u9418\u6578 C190 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u5e02\u8a71\u5206\u9418\u6578\n",
      "\n",
      "C191 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5167\u5206\u9418\u6578\u6bd4\u4f8b C192 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5916\u5206\u9418\u6578\u6bd4\u4f8b C193 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u5e02\u8a71\u5206\u9418\u6578\u6bd4\u4f8b C194 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7e3d\u6b21\u6578 C195 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u6b21\u6578 C196 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u6b21\u6578 C197 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u6b21\u6578 C198 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u6b21\u6578 C199 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u6b21\u6578 C200 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u6b21\u6578\n",
      "\n",
      "C201 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u6b21\u6578 C202 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u6b21\u6578 C203 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u6b21\u6578 C204 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7e3d\u6b21\u6578 C205 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5167\u6b21\u6578 C206 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5916\u6b21\u6578 C207 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u5e02\u8a71\u6b21\u6578 C208 [\u884c\u52d5]\u6700\u5e38\u767c\u8a71\u96fb\u4fe1\u696d\u8005 C209 [\u884c\u52d5]\u66fe\u7d93\u767c\u8a71\u57fa\u7ad9\u6578 C210 [\u884c\u52d5]\u6279\u50f9\u7c21\u8a0a\u6b21\u6578\n",
      "\n",
      "C211 [\u884c\u52d5]\u6279\u50f9\u6578\u64da\u9023\u7dda\u6b21\u6578 C212 [\u884c\u52d5]\u6578\u64da\u4e0a\u50b3MB C213 [\u884c\u52d5]\u6578\u64da\u4e0a\u50b3MB\u6bd4\u4f8b C214 [\u884c\u52d5]\u884c\u52d5\u6578\u64da\u6b21\u6578 C215 [\u884c\u52d5]\u884c\u52d5\u6578\u64da\u6d41\u91cf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('../../df_647.txt', encoding='utf-8', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-102-20d80fdeb1d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../df_647.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
       ]
      }
     ],
     "prompt_number": 102
    }
   ],
   "metadata": {}
  }
 ]
}