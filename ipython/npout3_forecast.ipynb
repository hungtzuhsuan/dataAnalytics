{
 "metadata": {
  "name": "",
  "signature": "sha256:3d6672c6e64c877805272f56b70afc2565ea57da9b230caa9bfbfd4602109095"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "pd.set_option(\"display.max_columns\", 300)\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('../../MB_PCUST_NPOUT_TRAIN.txt', encoding='utf-8', header=1, sep='\\t', names=['C'+str(i+1) for i in xrange(215)], na_values=['?'])\n",
      "\n",
      "#df = pd.read_csv('../../MB_PCUST_NPOUT_EXAM.txt', encoding='utf-8', sep='\\t', names=['C2']+['C'+str(i+4) for i in xrange(212)], na_values=['?'])\n",
      "#df['C3'] = df['C24'].map(lambda x: 'Y' if x>0 else 'N')\n",
      "#del df['C2']\n",
      "\n",
      "#df = df.loc[df['C1']==7]\n",
      "#df = pd.concat([df.loc[df['C3']=='N'].sample(20000*3/4), df.loc[df['C3']=='Y'].sample(20000*1/4)])\n",
      "df = df.sample(10000)\n",
      "del df['C1']\n",
      "del df['C2']\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C3</th>\n",
        "      <th>C4</th>\n",
        "      <th>C5</th>\n",
        "      <th>C6</th>\n",
        "      <th>C7</th>\n",
        "      <th>C8</th>\n",
        "      <th>C9</th>\n",
        "      <th>C10</th>\n",
        "      <th>C11</th>\n",
        "      <th>C12</th>\n",
        "      <th>C13</th>\n",
        "      <th>C14</th>\n",
        "      <th>C15</th>\n",
        "      <th>C16</th>\n",
        "      <th>C17</th>\n",
        "      <th>C18</th>\n",
        "      <th>C19</th>\n",
        "      <th>C20</th>\n",
        "      <th>C21</th>\n",
        "      <th>C22</th>\n",
        "      <th>C23</th>\n",
        "      <th>C24</th>\n",
        "      <th>C25</th>\n",
        "      <th>C26</th>\n",
        "      <th>C27</th>\n",
        "      <th>C28</th>\n",
        "      <th>C29</th>\n",
        "      <th>C30</th>\n",
        "      <th>C31</th>\n",
        "      <th>C32</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C35</th>\n",
        "      <th>C36</th>\n",
        "      <th>C37</th>\n",
        "      <th>C38</th>\n",
        "      <th>C39</th>\n",
        "      <th>C40</th>\n",
        "      <th>C41</th>\n",
        "      <th>C42</th>\n",
        "      <th>C43</th>\n",
        "      <th>C44</th>\n",
        "      <th>C45</th>\n",
        "      <th>C46</th>\n",
        "      <th>C47</th>\n",
        "      <th>C48</th>\n",
        "      <th>C49</th>\n",
        "      <th>C50</th>\n",
        "      <th>C51</th>\n",
        "      <th>C52</th>\n",
        "      <th>C53</th>\n",
        "      <th>C54</th>\n",
        "      <th>C55</th>\n",
        "      <th>C56</th>\n",
        "      <th>C57</th>\n",
        "      <th>C58</th>\n",
        "      <th>C59</th>\n",
        "      <th>C60</th>\n",
        "      <th>C61</th>\n",
        "      <th>C62</th>\n",
        "      <th>C63</th>\n",
        "      <th>C64</th>\n",
        "      <th>C65</th>\n",
        "      <th>C66</th>\n",
        "      <th>C67</th>\n",
        "      <th>C68</th>\n",
        "      <th>C69</th>\n",
        "      <th>C70</th>\n",
        "      <th>C71</th>\n",
        "      <th>C72</th>\n",
        "      <th>C73</th>\n",
        "      <th>C74</th>\n",
        "      <th>C75</th>\n",
        "      <th>C76</th>\n",
        "      <th>C77</th>\n",
        "      <th>C78</th>\n",
        "      <th>C79</th>\n",
        "      <th>C80</th>\n",
        "      <th>C81</th>\n",
        "      <th>C82</th>\n",
        "      <th>C83</th>\n",
        "      <th>C84</th>\n",
        "      <th>C85</th>\n",
        "      <th>C86</th>\n",
        "      <th>C87</th>\n",
        "      <th>C88</th>\n",
        "      <th>C89</th>\n",
        "      <th>C90</th>\n",
        "      <th>C91</th>\n",
        "      <th>C92</th>\n",
        "      <th>C93</th>\n",
        "      <th>C94</th>\n",
        "      <th>C95</th>\n",
        "      <th>C96</th>\n",
        "      <th>C97</th>\n",
        "      <th>C98</th>\n",
        "      <th>C99</th>\n",
        "      <th>C100</th>\n",
        "      <th>C101</th>\n",
        "      <th>C102</th>\n",
        "      <th>C103</th>\n",
        "      <th>C104</th>\n",
        "      <th>C105</th>\n",
        "      <th>C106</th>\n",
        "      <th>C107</th>\n",
        "      <th>C108</th>\n",
        "      <th>C109</th>\n",
        "      <th>C110</th>\n",
        "      <th>C111</th>\n",
        "      <th>C112</th>\n",
        "      <th>C113</th>\n",
        "      <th>C114</th>\n",
        "      <th>C115</th>\n",
        "      <th>C116</th>\n",
        "      <th>C117</th>\n",
        "      <th>C118</th>\n",
        "      <th>C119</th>\n",
        "      <th>C120</th>\n",
        "      <th>C121</th>\n",
        "      <th>C122</th>\n",
        "      <th>C123</th>\n",
        "      <th>C124</th>\n",
        "      <th>C125</th>\n",
        "      <th>C126</th>\n",
        "      <th>C127</th>\n",
        "      <th>C128</th>\n",
        "      <th>C129</th>\n",
        "      <th>C130</th>\n",
        "      <th>C131</th>\n",
        "      <th>C132</th>\n",
        "      <th>C133</th>\n",
        "      <th>C134</th>\n",
        "      <th>C135</th>\n",
        "      <th>C136</th>\n",
        "      <th>C137</th>\n",
        "      <th>C138</th>\n",
        "      <th>C139</th>\n",
        "      <th>C140</th>\n",
        "      <th>C141</th>\n",
        "      <th>C142</th>\n",
        "      <th>C143</th>\n",
        "      <th>C144</th>\n",
        "      <th>C145</th>\n",
        "      <th>C146</th>\n",
        "      <th>C147</th>\n",
        "      <th>C148</th>\n",
        "      <th>C149</th>\n",
        "      <th>C150</th>\n",
        "      <th>C151</th>\n",
        "      <th>C152</th>\n",
        "      <th>C153</th>\n",
        "      <th>C154</th>\n",
        "      <th>C155</th>\n",
        "      <th>C156</th>\n",
        "      <th>C157</th>\n",
        "      <th>C158</th>\n",
        "      <th>C159</th>\n",
        "      <th>C160</th>\n",
        "      <th>C161</th>\n",
        "      <th>C162</th>\n",
        "      <th>C163</th>\n",
        "      <th>C164</th>\n",
        "      <th>C165</th>\n",
        "      <th>C166</th>\n",
        "      <th>C167</th>\n",
        "      <th>C168</th>\n",
        "      <th>C169</th>\n",
        "      <th>C170</th>\n",
        "      <th>C171</th>\n",
        "      <th>C172</th>\n",
        "      <th>C173</th>\n",
        "      <th>C174</th>\n",
        "      <th>C175</th>\n",
        "      <th>C176</th>\n",
        "      <th>C177</th>\n",
        "      <th>C178</th>\n",
        "      <th>C179</th>\n",
        "      <th>C180</th>\n",
        "      <th>C181</th>\n",
        "      <th>C182</th>\n",
        "      <th>C183</th>\n",
        "      <th>C184</th>\n",
        "      <th>C185</th>\n",
        "      <th>C186</th>\n",
        "      <th>C187</th>\n",
        "      <th>C188</th>\n",
        "      <th>C189</th>\n",
        "      <th>C190</th>\n",
        "      <th>C191</th>\n",
        "      <th>C192</th>\n",
        "      <th>C193</th>\n",
        "      <th>C194</th>\n",
        "      <th>C195</th>\n",
        "      <th>C196</th>\n",
        "      <th>C197</th>\n",
        "      <th>C198</th>\n",
        "      <th>C199</th>\n",
        "      <th>C200</th>\n",
        "      <th>C201</th>\n",
        "      <th>C202</th>\n",
        "      <th>C203</th>\n",
        "      <th>C204</th>\n",
        "      <th>C205</th>\n",
        "      <th>C206</th>\n",
        "      <th>C207</th>\n",
        "      <th>C208</th>\n",
        "      <th>C209</th>\n",
        "      <th>C210</th>\n",
        "      <th>C211</th>\n",
        "      <th>C212</th>\n",
        "      <th>C213</th>\n",
        "      <th>C214</th>\n",
        "      <th>C215</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>39086</th>\n",
        "      <td>Y</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>57.0</td>\n",
        "      <td>\u7261\u7f8a\u5ea7</td>\n",
        "      <td>160</td>\n",
        "      <td>\u64da\u9ede10</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-65.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>59.99</td>\n",
        "      <td>7.50</td>\n",
        "      <td>0.0</td>\n",
        "      <td>51.27</td>\n",
        "      <td>1.22</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.45</td>\n",
        "      <td>3.22</td>\n",
        "      <td>0.0</td>\n",
        "      <td>31.6</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.85</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.27</td>\n",
        "      <td>0.05</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.53</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.25</td>\n",
        "      <td>10.45</td>\n",
        "      <td>2.23</td>\n",
        "      <td>8.33</td>\n",
        "      <td>1.27</td>\n",
        "      <td>10.12</td>\n",
        "      <td>9.05</td>\n",
        "      <td>0.62</td>\n",
        "      <td>9.25</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.17</td>\n",
        "      <td>0.17</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.14</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.16</td>\n",
        "      <td>0.15</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.15</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u95dc\u5edf\u5340</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u95dc\u5edf\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>345.0</td>\n",
        "      <td>65.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>454.658</td>\n",
        "      <td>11.755</td>\n",
        "      <td>148.774</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>61.57</td>\n",
        "      <td>9.08</td>\n",
        "      <td>51.27</td>\n",
        "      <td>1.22</td>\n",
        "      <td>1.22</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.45</td>\n",
        "      <td>41.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>33.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.31</td>\n",
        "      <td>9.09</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.22</td>\n",
        "      <td>0.88</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.12</td>\n",
        "      <td>39.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>33.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>58456</th>\n",
        "      <td>Y</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>25.0</td>\n",
        "      <td>\u7345\u5b50\u5ea7</td>\n",
        "      <td>20</td>\n",
        "      <td>\u64da\u9ede06</td>\n",
        "      <td>Y</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>4G</td>\n",
        "      <td>636.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>7.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>N</td>\n",
        "      <td>2</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>20.0</td>\n",
        "      <td>20.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Yes</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>541233.0</td>\n",
        "      <td>221945.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>117298.0</td>\n",
        "      <td>24132354.0</td>\n",
        "      <td>1451792.0</td>\n",
        "      <td>620570.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>78321</th>\n",
        "      <td>N</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>52.0</td>\n",
        "      <td>\u91d1\u725b\u5ea7</td>\n",
        "      <td>66</td>\n",
        "      <td>\u64da\u9ede12</td>\n",
        "      <td>Y</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-44.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>6</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8.28</td>\n",
        "      <td>3.75</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.53</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.30</td>\n",
        "      <td>4.23</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.45</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.55</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.51</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.50</td>\n",
        "      <td>4.33</td>\n",
        "      <td>0.27</td>\n",
        "      <td>2.07</td>\n",
        "      <td>0.85</td>\n",
        "      <td>0.27</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.06</td>\n",
        "      <td>0.52</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.25</td>\n",
        "      <td>0.10</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u53f0\u5317\u5e02</td>\n",
        "      <td>\u5167\u6e56\u5340</td>\n",
        "      <td>\u53f0\u5317\u5e02</td>\n",
        "      <td>\u5927\u5b89\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>171.0</td>\n",
        "      <td>174.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>30.976</td>\n",
        "      <td>9.549</td>\n",
        "      <td>15.579</td>\n",
        "      <td>15.912537</td>\n",
        "      <td>27.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.28</td>\n",
        "      <td>3.75</td>\n",
        "      <td>4.53</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.75</td>\n",
        "      <td>13.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.75</td>\n",
        "      <td>3.75</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>13.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11816</th>\n",
        "      <td>Y</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>40.0</td>\n",
        "      <td>\u5de8\u87f9\u5ea7</td>\n",
        "      <td>30</td>\n",
        "      <td>\u64da\u9ede03</td>\n",
        "      <td>Y</td>\n",
        "      <td>\u4f4e</td>\n",
        "      <td>4G</td>\n",
        "      <td>636.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>5.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>N</td>\n",
        "      <td>2</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7af6\u696dC</td>\n",
        "      <td>30.0</td>\n",
        "      <td>30.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>Yes</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>711043.303711</td>\n",
        "      <td>19.21</td>\n",
        "      <td>9.72</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.67</td>\n",
        "      <td>2.82</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>6.67</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.51</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.35</td>\n",
        "      <td>0.15</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.35</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.32</td>\n",
        "      <td>4.70</td>\n",
        "      <td>1.75</td>\n",
        "      <td>2.87</td>\n",
        "      <td>6.78</td>\n",
        "      <td>2.47</td>\n",
        "      <td>0.32</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.09</td>\n",
        "      <td>0.15</td>\n",
        "      <td>0.35</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>76.471</td>\n",
        "      <td>303.931</td>\n",
        "      <td>46.067</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>15.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>146587499.0</td>\n",
        "      <td>80301524.0</td>\n",
        "      <td>3995012.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>63744500.0</td>\n",
        "      <td>17922939.0</td>\n",
        "      <td>30407496.0</td>\n",
        "      <td>126572722.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>81302922.0</td>\n",
        "      <td>31136375.0</td>\n",
        "      <td>3727374.0</td>\n",
        "      <td>19.20</td>\n",
        "      <td>9.72</td>\n",
        "      <td>6.67</td>\n",
        "      <td>2.82</td>\n",
        "      <td>2.82</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.72</td>\n",
        "      <td>25.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.54</td>\n",
        "      <td>9.72</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.82</td>\n",
        "      <td>0.78</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.22</td>\n",
        "      <td>25.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>22.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>129.0</td>\n",
        "      <td>23592.251953</td>\n",
        "      <td>0.03318</td>\n",
        "      <td>129.0</td>\n",
        "      <td>728108343.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>85592</th>\n",
        "      <td>N</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>27.0</td>\n",
        "      <td>\u5de8\u87f9\u5ea7</td>\n",
        "      <td>68</td>\n",
        "      <td>\u64da\u9ede02</td>\n",
        "      <td>Y</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>584.0</td>\n",
        "      <td>\u7121\u7d81\u7d04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u53f0\u5317\u5e02</td>\n",
        "      <td>\u4e2d\u5c71\u5340</td>\n",
        "      <td>\u53f0\u5317\u5e02</td>\n",
        "      <td>\u4e2d\u5c71\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>304.0</td>\n",
        "      <td>157.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>37.336</td>\n",
        "      <td>2.401</td>\n",
        "      <td>16.616</td>\n",
        "      <td>0.712853</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14922.0</td>\n",
        "      <td>542645.0</td>\n",
        "      <td>36730.0</td>\n",
        "      <td>1217986.0</td>\n",
        "      <td>650677.0</td>\n",
        "      <td>7559650.0</td>\n",
        "      <td>61097685.0</td>\n",
        "      <td>35433856.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>20600.0</td>\n",
        "      <td>1057814.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1587541.0</td>\n",
        "      <td>35886.0</td>\n",
        "      <td>7145775.0</td>\n",
        "      <td>28024709.0</td>\n",
        "      <td>255145385.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1330216.0</td>\n",
        "      <td>6300828.0</td>\n",
        "      <td>109295042.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>12875.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "      C3    C4 C5    C6   C7   C8    C9 C10 C11 C12    C13  C14   C15  C16  \\\n",
        "39086  Y  NVIP  F  57.0  \u7261\u7f8a\u5ea7  160  \u64da\u9ede10   N  \u4e2d\u4f4e  3G  183.0  \u8cfc\u6a5f\u7d04 -65.0  5.0   \n",
        "58456  Y  NVIP  F  25.0  \u7345\u5b50\u5ea7   20  \u64da\u9ede06   Y  \u6975\u4f4e  4G  636.0  \u8cfc\u6a5f\u7d04   7.0  1.0   \n",
        "78321  N  NVIP  M  52.0  \u91d1\u725b\u5ea7   66  \u64da\u9ede12   Y  \u6975\u4f4e  3G  183.0  \u8cfc\u6a5f\u7d04 -44.0  1.0   \n",
        "11816  Y  NVIP  M  40.0  \u5de8\u87f9\u5ea7   30  \u64da\u9ede03   Y   \u4f4e  4G  636.0  \u8cfc\u6a5f\u7d04  -2.0  1.0   \n",
        "85592  N  NVIP  F  27.0  \u5de8\u87f9\u5ea7   68  \u64da\u9ede02   Y  \u6975\u4f4e  3G  584.0  \u7121\u7d81\u7d04   NaN  0.0   \n",
        "\n",
        "       C17 C18 C19  C20  C21  C22 C23  C24  C25  C26  C27  C28  C29  C30  C31  \\\n",
        "39086  4.0  \u4f4e\u4e2d  \u96f6\u5143  NaN  2.0  \u7af6\u696dB   N    1  NaN  1.0  NaN    1  NaN  NaN  \u7121NP   \n",
        "58456  1.0   \u4e2d   \u4e2d  2.0  1.0  \u7af6\u696dA   N    2  1.0  NaN  1.0    1  NaN  1.0  \u7af6\u696dA   \n",
        "78321  1.0  \u96f6\u5143  \u96f6\u5143  NaN  1.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0  \u7121NP   \n",
        "11816  1.0  \u96f6\u5143  \u96f6\u5143  5.0  1.0  \u7af6\u696dB   N    2  1.0  1.0  NaN    1  NaN  NaN  \u7af6\u696dC   \n",
        "85592  0.0  \u96f6\u5143  \u96f6\u5143  NaN  NaN    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0  \u7121NP   \n",
        "\n",
        "        C32   C33  C34  C35  C36  C37  C38  C39  C40  C41  C42  C43  C44  C45  \\\n",
        "39086   NaN   NaN  NaN    1    1    0    0    0    0    0    0    1  NaN  NaN   \n",
        "58456  20.0  20.0  1.0    3    3    0    0    0    0    0    0    2  NaN  Yes   \n",
        "78321   NaN   NaN  NaN    6    3    0    1    0    1    1    0    3  NaN  NaN   \n",
        "11816  30.0  30.0  1.0    2    2    0    0    0    0    0    0    2  Yes  NaN   \n",
        "85592   NaN   NaN  NaN    1    1    0    0    0    0    0    0    1  NaN  NaN   \n",
        "\n",
        "      C46            C47    C48   C49  C50    C51   C52  C53    C54   C55  \\\n",
        "39086  No            NaN  59.99  7.50  0.0  51.27  1.22  0.0  16.45  3.22   \n",
        "58456  No            NaN    NaN   NaN  NaN    NaN   NaN  NaN    NaN   NaN   \n",
        "78321  No            NaN   8.28  3.75  0.0   4.53  0.00  0.0   0.30  4.23   \n",
        "11816  No  711043.303711  19.21  9.72  0.0   6.67  2.82  0.0   0.00  6.67   \n",
        "85592  No            NaN    NaN   NaN  NaN    NaN   NaN  NaN    NaN   NaN   \n",
        "\n",
        "       C56   C57   C58  C59   C60   C61  C62  C63   C64   C65  C66   C67  C68  \\\n",
        "39086  0.0  31.6  0.13  0.0  0.85  0.02  0.0  0.0  0.27  0.05  0.0  0.53  0.0   \n",
        "58456  NaN   NaN   NaN  NaN   NaN   NaN  NaN  NaN   NaN   NaN  NaN   NaN  NaN   \n",
        "78321  0.0   0.0  0.45  0.0  0.55  0.00  0.0  0.0  0.04  0.51  0.0  0.00  0.0   \n",
        "11816  0.0   0.0  0.51  0.0  0.35  0.15  0.0  0.0  0.00  0.35  0.0  0.00  0.0   \n",
        "85592  NaN   NaN   NaN  NaN   NaN   NaN  NaN  NaN   NaN   NaN  NaN   NaN  NaN   \n",
        "\n",
        "       C69  C70    C71    C72   C73   C74   C75    C76   C77   C78   C79  C80  \\\n",
        "39086  0.0  0.0  10.25  10.45  2.23  8.33  1.27  10.12  9.05  0.62  9.25  0.0   \n",
        "58456  NaN  NaN    NaN    NaN   NaN   NaN   NaN    NaN   NaN   NaN   NaN  NaN   \n",
        "78321  0.0  0.0   0.00   0.00  0.50  4.33  0.27   2.07  0.85  0.27  0.00  0.0   \n",
        "11816  0.0  0.0   0.00   0.32  4.70  1.75  2.87   6.78  2.47  0.32  0.00  0.0   \n",
        "85592  NaN  NaN    NaN    NaN   NaN   NaN   NaN    NaN   NaN   NaN   NaN  NaN   \n",
        "\n",
        "       C81  C82   C83   C84   C85   C86   C87   C88   C89   C90   C91  C92  \\\n",
        "39086  0.0  0.0  0.17  0.17  0.04  0.14  0.02  0.16  0.15  0.01  0.15  \u53f0\u5357\u5e02   \n",
        "58456  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \\N   \n",
        "78321  0.0  0.0  0.00  0.00  0.06  0.52  0.03  0.25  0.10  0.03  0.00  \u53f0\u5317\u5e02   \n",
        "11816  0.0  0.0  0.00  0.02  0.24  0.09  0.15  0.35  0.13  0.02  0.00   \\N   \n",
        "85592  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \u53f0\u5317\u5e02   \n",
        "\n",
        "       C93  C94  C95 C96 C97  C98  C99   C100   C101  C102     C103     C104  \\\n",
        "39086  \u95dc\u5edf\u5340  \u53f0\u5357\u5e02  \u95dc\u5edf\u5340  No  No  0.0  0.0  345.0   65.0   0.0  454.658   11.755   \n",
        "58456   \\N   \\N   \\N  No  No  0.0  0.0    0.0    0.0   0.0    0.000    0.000   \n",
        "78321  \u5167\u6e56\u5340  \u53f0\u5317\u5e02  \u5927\u5b89\u5340  No  No  0.0  0.0  171.0  174.0   0.0   30.976    9.549   \n",
        "11816   \\N   \\N   \\N  No  No  0.0  0.0    0.0    0.0   0.0   76.471  303.931   \n",
        "85592  \u4e2d\u5c71\u5340  \u53f0\u5317\u5e02  \u4e2d\u5c71\u5340  No  No  0.0  0.0  304.0  157.0   0.0   37.336    2.401   \n",
        "\n",
        "          C105       C106  C107  C108  C109  C110  C111  C112  C113  C114  \\\n",
        "39086  148.774   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
        "58456    0.000   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
        "78321   15.579  15.912537  27.0   0.0   0.0   0.0   2.0   1.0   0.0   0.0   \n",
        "11816   46.067   0.000000  10.0   0.0   0.0   0.0  12.0   2.0  10.0  15.0   \n",
        "85592   16.616   0.712853   0.0   0.0   0.0   0.0   2.0   1.0   1.0   0.0   \n",
        "\n",
        "       C115  C116  C117  C118  C119  C120  C121  C122     C123      C124  \\\n",
        "39086  14.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0      0.0       0.0   \n",
        "58456   0.0   1.0   0.0   0.0   1.0   1.0   0.0   0.0      0.0       0.0   \n",
        "78321   0.0   1.0   0.0   0.0   2.0   3.0   0.0   0.0      0.0       0.0   \n",
        "11816   3.0  11.0   0.0   3.0   3.0  24.0   1.0   0.0      0.0       0.0   \n",
        "85592   0.0   1.0   0.0   2.0   1.0   3.0   0.0   0.0  14922.0  542645.0   \n",
        "\n",
        "          C125       C126      C127         C128        C129        C130  \\\n",
        "39086      0.0        0.0       0.0          0.0         0.0         0.0   \n",
        "58456      0.0        0.0       0.0          0.0    541233.0    221945.0   \n",
        "78321      0.0        0.0       0.0          0.0         0.0         0.0   \n",
        "11816      0.0        0.0       0.0  146587499.0  80301524.0   3995012.0   \n",
        "85592  36730.0  1217986.0  650677.0    7559650.0  61097685.0  35433856.0   \n",
        "\n",
        "       C131  C132  C133  C134     C135       C136  C137       C138  \\\n",
        "39086   0.0   0.0   0.0   0.0      0.0        0.0   0.0        0.0   \n",
        "58456   0.0   0.0   0.0   0.0      0.0        0.0   0.0        0.0   \n",
        "78321   0.0   0.0   0.0   0.0      0.0        0.0   0.0        0.0   \n",
        "11816   0.0   0.0   0.0   0.0      0.0        0.0   0.0        0.0   \n",
        "85592   0.0   0.0   0.0   0.0  20600.0  1057814.0   0.0  1587541.0   \n",
        "\n",
        "             C139        C140        C141         C142  C143        C144  \\\n",
        "39086         0.0         0.0         0.0          0.0   0.0         0.0   \n",
        "58456    117298.0  24132354.0   1451792.0     620570.0   0.0         0.0   \n",
        "78321         0.0         0.0         0.0          0.0   0.0         0.0   \n",
        "11816  63744500.0  17922939.0  30407496.0  126572722.0   0.0  81302922.0   \n",
        "85592     35886.0   7145775.0  28024709.0  255145385.0   0.0   1330216.0   \n",
        "\n",
        "             C145         C146   C147  C148   C149  C150  C151  C152  C153  \\\n",
        "39086         0.0          0.0  61.57  9.08  51.27  1.22  1.22   0.0   0.0   \n",
        "58456         0.0          0.0    NaN   NaN    NaN   NaN   NaN   NaN   NaN   \n",
        "78321         0.0          0.0   8.28  3.75   4.53  0.00  0.00   0.0   0.0   \n",
        "11816  31136375.0    3727374.0  19.20  9.72   6.67  2.82  2.82   0.0   0.0   \n",
        "85592   6300828.0  109295042.0   0.00  0.00   0.00  0.00  0.00   0.0   0.0   \n",
        "\n",
        "        C154  C155  C156  C157  C158  C159  C160  C161  C162  C163  C164  \\\n",
        "39086  16.45  41.0   6.0  33.0   2.0   2.0   0.0   0.0  14.0   3.0   0.0   \n",
        "58456    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "78321   3.75  13.0   7.0   6.0   0.0   0.0   0.0   0.0   5.0   2.0   0.0   \n",
        "11816   9.72  25.0  12.0  11.0   2.0   2.0   0.0   0.0   5.0   2.0   0.0   \n",
        "85592   0.00   0.0   0.0   0.0   0.0   0.0   0.0   0.0   NaN   NaN   NaN   \n",
        "\n",
        "       C165  C166  C167  C168  C169  C170  C171  C172  C173  C174  C175  C176  \\\n",
        "39086   9.0   2.0   0.0   5.0   3.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n",
        "58456   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "78321   3.0   0.0   0.0   1.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
        "11816   1.0   2.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
        "85592   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "\n",
        "       C177  C178  C179  C180  C181  C182  C183  C184  C185  C186   C187  \\\n",
        "39086   0.0   0.0   0.0   0.0   0.0  16.0   5.0   9.0   2.0   0.0  10.31   \n",
        "58456   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   0.00   \n",
        "78321   0.0   0.0   0.0   0.0   0.0   5.0   2.0   3.0   0.0   0.0   3.75   \n",
        "11816   0.0   0.0   0.0   0.0   0.0   5.0   2.0   1.0   2.0   0.0  12.54   \n",
        "85592   NaN   NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0   0.0   0.00   \n",
        "\n",
        "       C188  C189  C190  C191  C192  C193  C194  C195  C196  C197  C198  C199  \\\n",
        "39086  9.09   0.0  1.22  0.88   0.0  0.12  39.0   4.0   0.0  33.0   2.0   0.0   \n",
        "58456  0.00   0.0  0.00  0.00   0.0  0.00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "78321  3.75   0.0  0.00  1.00   0.0  0.00  13.0   7.0   0.0   6.0   0.0   0.0   \n",
        "11816  9.72   0.0  2.82  0.78   0.0  0.22  25.0  12.0   0.0  11.0   2.0   0.0   \n",
        "85592  0.00   0.0  0.00  0.00   0.0  0.00   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "\n",
        "       C200  C201  C202  C203  C204  C205  C206  C207 C208  C209  C210   C211  \\\n",
        "39086  12.0   9.0   0.0  12.0   8.0   6.0   0.0   2.0  \u7af6\u696dA  12.0   0.0    0.0   \n",
        "58456   NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0  NaN   NaN   0.0    0.0   \n",
        "78321   1.0   5.0   0.0   0.0   7.0   7.0   0.0   0.0   \u696d\u8005  10.0   0.0    0.0   \n",
        "11816   0.0  11.0   0.0   0.0  14.0  12.0   0.0   2.0   \u696d\u8005  22.0   0.0  129.0   \n",
        "85592   NaN   NaN   NaN   NaN   0.0   0.0   0.0   0.0  NaN   NaN   0.0    0.0   \n",
        "\n",
        "               C212     C213   C214         C215  \n",
        "39086           NaN      NaN    0.0          0.0  \n",
        "58456           NaN      NaN    NaN          NaN  \n",
        "78321           NaN      NaN    0.0          0.0  \n",
        "11816  23592.251953  0.03318  129.0  728108343.0  \n",
        "85592           NaN      NaN    1.0      12875.0  "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##column independency"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfco = df.corr()\n",
      "indices = np.where(dfco > 0.8)\n",
      "cols = [(dfco.index[x], dfco.columns[y]) for x, y in zip(*indices) if x != y and x < y]\n",
      "\n",
      "for col in cols:\n",
      "  if col[1] in df.columns and col[1]!='C3': del df[col[1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##chi-squared test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import chi2_contingency\n",
      "\n",
      "for col in [df.columns[i] for i in xrange(len(df.columns)) if df.dtypes[i]=='object' and df.columns[i]!='C3']:\n",
      "    chi2, p, dof, expected = chi2_contingency(pd.crosstab(df[col], df['C3']))\n",
      "    if p>=0.05: # H0 (independent - no affects)\"\n",
      "        print \"%s does NOT affect C3\" % col\n",
      "        del df[col]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C7 does NOT affect C3\n",
        "C44 does NOT affect C3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C45 does NOT affect C3\n",
        "C46 does NOT affect C3\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##anova test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import f_oneway\n",
      "\n",
      "for col in [df.columns[i] for i in xrange(len(df.columns)) if df.dtypes[i]!='object' and df.columns[i]!='C3']:\n",
      "    df_y = df.loc[df['C3']=='Y', col].fillna(0) # or dropna ?\n",
      "    df_n = df.loc[df['C3']=='N', col].fillna(0) # or dropna ?\n",
      "    fVal, p = f_oneway(df_y, df_n)\n",
      "    if p>=0.05: # H0 (%s df_y's mean = df_n's mean)\n",
      "        print \"%s no difference\" % (col)\n",
      "        del df[col]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C20 no difference\n",
        "C39 no difference\n",
        "C42 no difference\n",
        "C47 no difference\n",
        "C50 no difference\n",
        "C55 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C56 no difference\n",
        "C61 no difference\n",
        "C62 no difference\n",
        "C68 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C69 no difference\n",
        "C71 no difference\n",
        "C79 no difference\n",
        "C80 no difference\n",
        "C81 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C82 no difference\n",
        "C83 no difference\n",
        "C85 no difference\n",
        "C86 no difference\n",
        "C87 no difference\n",
        "C88 no difference\n",
        "C108 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C109 no difference\n",
        "C111 no difference\n",
        "C112 no difference\n",
        "C113 no difference\n",
        "C114 no difference\n",
        "C116 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C121 no difference\n",
        "C123 no difference\n",
        "C125 no difference\n",
        "C126 no difference\n",
        "C131 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C132 no difference\n",
        "C133 no difference\n",
        "C134 no difference\n",
        "C135 no difference\n",
        "C136 no difference\n",
        "C137 no difference\n",
        "C138 no difference\n",
        "C143 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C144 no difference\n",
        "C145 no difference\n",
        "C152 no difference\n",
        "C158 no difference\n",
        "C160 no difference\n",
        "C173 no difference\n",
        "C175 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C177 no difference\n",
        "C179 no difference\n",
        "C180 no difference\n",
        "C181 no difference\n",
        "C192 no difference\n",
        "C209 no difference"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "C210 no difference\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(df.columns), \", \".join(df.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "97 C3, C4, C5, C6, C8, C9, C10, C11, C12, C13, C14, C15, C16, C18, C19, C22, C23, C24, C31, C33, C34, C35, C37, C38, C40, C43, C48, C51, C52, C53, C57, C58, C59, C60, C63, C64, C65, C66, C67, C70, C72, C73, C74, C75, C76, C77, C78, C84, C89, C90, C91, C92, C93, C94, C95, C96, C97, C98, C99, C100, C102, C103, C104, C106, C107, C110, C115, C117, C118, C119, C120, C122, C124, C127, C128, C129, C130, C139, C140, C155, C164, C170, C171, C172, C174, C176, C178, C189, C191, C196, C201, C202, C203, C208, C211, C212, C213\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Preprocessing (for Feature Selection)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "dfc = df.loc[:, [df.columns[i] for i in xrange(len(df.columns)) if df.dtypes[i]!='object' and df.columns[i]!='C3']]\n",
      "for col in dfc.columns:\n",
      "    dfc[col].fillna(0, inplace=True)\n",
      "    dfc[col] = StandardScaler().fit_transform(dfc[col]) #(df['DT1_DATA_RTD_DUR_L'] - df['DT1_DATA_RTD_DUR_L'].mean())/df['DT1_DATA_RTD_DUR_L'].std(ddof=0)\n",
      "\n",
      "dfc.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C6</th>\n",
        "      <th>C8</th>\n",
        "      <th>C13</th>\n",
        "      <th>C15</th>\n",
        "      <th>C16</th>\n",
        "      <th>C24</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C35</th>\n",
        "      <th>C37</th>\n",
        "      <th>C38</th>\n",
        "      <th>C40</th>\n",
        "      <th>C43</th>\n",
        "      <th>C48</th>\n",
        "      <th>C51</th>\n",
        "      <th>C52</th>\n",
        "      <th>C53</th>\n",
        "      <th>C57</th>\n",
        "      <th>C58</th>\n",
        "      <th>C59</th>\n",
        "      <th>C60</th>\n",
        "      <th>C63</th>\n",
        "      <th>C64</th>\n",
        "      <th>C65</th>\n",
        "      <th>C66</th>\n",
        "      <th>C67</th>\n",
        "      <th>C70</th>\n",
        "      <th>C72</th>\n",
        "      <th>C73</th>\n",
        "      <th>C74</th>\n",
        "      <th>C75</th>\n",
        "      <th>C76</th>\n",
        "      <th>C77</th>\n",
        "      <th>C78</th>\n",
        "      <th>C84</th>\n",
        "      <th>C89</th>\n",
        "      <th>C90</th>\n",
        "      <th>C91</th>\n",
        "      <th>C98</th>\n",
        "      <th>C99</th>\n",
        "      <th>C100</th>\n",
        "      <th>C102</th>\n",
        "      <th>C103</th>\n",
        "      <th>C104</th>\n",
        "      <th>C106</th>\n",
        "      <th>C107</th>\n",
        "      <th>C110</th>\n",
        "      <th>C115</th>\n",
        "      <th>C117</th>\n",
        "      <th>C118</th>\n",
        "      <th>C119</th>\n",
        "      <th>C120</th>\n",
        "      <th>C122</th>\n",
        "      <th>C124</th>\n",
        "      <th>C127</th>\n",
        "      <th>C128</th>\n",
        "      <th>C129</th>\n",
        "      <th>C130</th>\n",
        "      <th>C139</th>\n",
        "      <th>C140</th>\n",
        "      <th>C155</th>\n",
        "      <th>C164</th>\n",
        "      <th>C170</th>\n",
        "      <th>C171</th>\n",
        "      <th>C172</th>\n",
        "      <th>C174</th>\n",
        "      <th>C176</th>\n",
        "      <th>C178</th>\n",
        "      <th>C189</th>\n",
        "      <th>C191</th>\n",
        "      <th>C196</th>\n",
        "      <th>C201</th>\n",
        "      <th>C202</th>\n",
        "      <th>C203</th>\n",
        "      <th>C211</th>\n",
        "      <th>C212</th>\n",
        "      <th>C213</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>39086</th>\n",
        "      <td>0.920270</td>\n",
        "      <td>0.787711</td>\n",
        "      <td>-0.920991</td>\n",
        "      <td>-1.227806</td>\n",
        "      <td>1.427298</td>\n",
        "      <td>0.156098</td>\n",
        "      <td>-0.582832</td>\n",
        "      <td>-0.607084</td>\n",
        "      <td>-0.145542</td>\n",
        "      <td>-0.260604</td>\n",
        "      <td>-0.530985</td>\n",
        "      <td>-0.511814</td>\n",
        "      <td>-0.307197</td>\n",
        "      <td>-0.084944</td>\n",
        "      <td>0.856588</td>\n",
        "      <td>-0.417385</td>\n",
        "      <td>-0.064754</td>\n",
        "      <td>4.753483</td>\n",
        "      <td>-1.019226</td>\n",
        "      <td>-0.244521</td>\n",
        "      <td>2.144662</td>\n",
        "      <td>-0.270939</td>\n",
        "      <td>0.835349</td>\n",
        "      <td>-0.400377</td>\n",
        "      <td>-0.257106</td>\n",
        "      <td>7.697360</td>\n",
        "      <td>-0.095356</td>\n",
        "      <td>0.213187</td>\n",
        "      <td>-0.326114</td>\n",
        "      <td>-0.006994</td>\n",
        "      <td>-0.339306</td>\n",
        "      <td>0.003158</td>\n",
        "      <td>-0.034065</td>\n",
        "      <td>-0.320668</td>\n",
        "      <td>0.712246</td>\n",
        "      <td>0.111015</td>\n",
        "      <td>-0.682891</td>\n",
        "      <td>0.784748</td>\n",
        "      <td>-0.215873</td>\n",
        "      <td>-0.229521</td>\n",
        "      <td>1.307667</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.491983</td>\n",
        "      <td>-0.379254</td>\n",
        "      <td>-0.174081</td>\n",
        "      <td>-0.411136</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.409890</td>\n",
        "      <td>-0.193784</td>\n",
        "      <td>-0.645244</td>\n",
        "      <td>-0.450151</td>\n",
        "      <td>-0.849279</td>\n",
        "      <td>-0.243344</td>\n",
        "      <td>-0.204674</td>\n",
        "      <td>-0.214339</td>\n",
        "      <td>-0.317650</td>\n",
        "      <td>-0.338173</td>\n",
        "      <td>-0.330850</td>\n",
        "      <td>-0.229224</td>\n",
        "      <td>-0.339555</td>\n",
        "      <td>-0.105457</td>\n",
        "      <td>-0.310863</td>\n",
        "      <td>-0.376732</td>\n",
        "      <td>1.160587</td>\n",
        "      <td>-0.169413</td>\n",
        "      <td>-0.126703</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.077039</td>\n",
        "      <td>-0.02741</td>\n",
        "      <td>0.640425</td>\n",
        "      <td>-0.178466</td>\n",
        "      <td>0.249795</td>\n",
        "      <td>-0.239318</td>\n",
        "      <td>3.462945</td>\n",
        "      <td>-0.660284</td>\n",
        "      <td>-0.201793</td>\n",
        "      <td>-0.560172</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>58456</th>\n",
        "      <td>-1.405516</td>\n",
        "      <td>-1.129874</td>\n",
        "      <td>0.175557</td>\n",
        "      <td>1.224625</td>\n",
        "      <td>-0.688471</td>\n",
        "      <td>1.100429</td>\n",
        "      <td>0.021744</td>\n",
        "      <td>0.673144</td>\n",
        "      <td>-0.030023</td>\n",
        "      <td>-0.260604</td>\n",
        "      <td>-0.530985</td>\n",
        "      <td>-0.511814</td>\n",
        "      <td>0.160592</td>\n",
        "      <td>-0.454470</td>\n",
        "      <td>-0.461415</td>\n",
        "      <td>-0.488431</td>\n",
        "      <td>-0.064754</td>\n",
        "      <td>-0.159741</td>\n",
        "      <td>-1.426257</td>\n",
        "      <td>-0.244521</td>\n",
        "      <td>-1.012913</td>\n",
        "      <td>-0.270939</td>\n",
        "      <td>-0.631262</td>\n",
        "      <td>-0.672460</td>\n",
        "      <td>-0.257106</td>\n",
        "      <td>-0.227657</td>\n",
        "      <td>-0.095356</td>\n",
        "      <td>-0.319257</td>\n",
        "      <td>-0.428944</td>\n",
        "      <td>-0.404146</td>\n",
        "      <td>-0.398203</td>\n",
        "      <td>-0.451278</td>\n",
        "      <td>-0.459311</td>\n",
        "      <td>-0.341828</td>\n",
        "      <td>-0.688791</td>\n",
        "      <td>-0.892680</td>\n",
        "      <td>-0.750410</td>\n",
        "      <td>-0.470836</td>\n",
        "      <td>-0.215873</td>\n",
        "      <td>-0.229521</td>\n",
        "      <td>-1.088115</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.480501</td>\n",
        "      <td>-0.549129</td>\n",
        "      <td>-0.174081</td>\n",
        "      <td>-0.411136</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.770577</td>\n",
        "      <td>-0.193784</td>\n",
        "      <td>-0.645244</td>\n",
        "      <td>-0.450151</td>\n",
        "      <td>-0.849279</td>\n",
        "      <td>-0.243344</td>\n",
        "      <td>-0.204674</td>\n",
        "      <td>-0.214339</td>\n",
        "      <td>-0.317650</td>\n",
        "      <td>-0.337152</td>\n",
        "      <td>-0.330406</td>\n",
        "      <td>-0.229011</td>\n",
        "      <td>-0.314011</td>\n",
        "      <td>-0.745622</td>\n",
        "      <td>-0.310863</td>\n",
        "      <td>-0.376732</td>\n",
        "      <td>-0.395786</td>\n",
        "      <td>-0.169413</td>\n",
        "      <td>-0.126703</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.077039</td>\n",
        "      <td>-0.02741</td>\n",
        "      <td>-1.855064</td>\n",
        "      <td>-0.178466</td>\n",
        "      <td>-0.531302</td>\n",
        "      <td>-0.239318</td>\n",
        "      <td>-0.234774</td>\n",
        "      <td>-0.660284</td>\n",
        "      <td>-0.201793</td>\n",
        "      <td>-0.560172</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>78321</th>\n",
        "      <td>0.556866</td>\n",
        "      <td>-0.499810</td>\n",
        "      <td>-0.920991</td>\n",
        "      <td>-0.512514</td>\n",
        "      <td>-0.688471</td>\n",
        "      <td>-0.788233</td>\n",
        "      <td>-0.582832</td>\n",
        "      <td>-0.607084</td>\n",
        "      <td>0.143255</td>\n",
        "      <td>-0.260604</td>\n",
        "      <td>0.307589</td>\n",
        "      <td>1.556122</td>\n",
        "      <td>0.628380</td>\n",
        "      <td>-0.403467</td>\n",
        "      <td>-0.344962</td>\n",
        "      <td>-0.488431</td>\n",
        "      <td>-0.064754</td>\n",
        "      <td>-0.159741</td>\n",
        "      <td>-0.017305</td>\n",
        "      <td>-0.244521</td>\n",
        "      <td>1.030224</td>\n",
        "      <td>-0.270939</td>\n",
        "      <td>-0.413986</td>\n",
        "      <td>2.102794</td>\n",
        "      <td>-0.257106</td>\n",
        "      <td>-0.227657</td>\n",
        "      <td>-0.095356</td>\n",
        "      <td>-0.319257</td>\n",
        "      <td>-0.405888</td>\n",
        "      <td>-0.197703</td>\n",
        "      <td>-0.385682</td>\n",
        "      <td>-0.358325</td>\n",
        "      <td>-0.419371</td>\n",
        "      <td>-0.332613</td>\n",
        "      <td>-0.688791</td>\n",
        "      <td>-0.223550</td>\n",
        "      <td>-0.547854</td>\n",
        "      <td>-0.470836</td>\n",
        "      <td>-0.215873</td>\n",
        "      <td>-0.229521</td>\n",
        "      <td>0.099360</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.346115</td>\n",
        "      <td>-0.411133</td>\n",
        "      <td>1.919848</td>\n",
        "      <td>3.208841</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.770577</td>\n",
        "      <td>-0.193784</td>\n",
        "      <td>-0.645244</td>\n",
        "      <td>-0.239859</td>\n",
        "      <td>-0.581367</td>\n",
        "      <td>-0.243344</td>\n",
        "      <td>-0.204674</td>\n",
        "      <td>-0.214339</td>\n",
        "      <td>-0.317650</td>\n",
        "      <td>-0.338173</td>\n",
        "      <td>-0.330850</td>\n",
        "      <td>-0.229224</td>\n",
        "      <td>-0.339555</td>\n",
        "      <td>-0.542643</td>\n",
        "      <td>-0.310863</td>\n",
        "      <td>-0.376732</td>\n",
        "      <td>-0.395786</td>\n",
        "      <td>-0.169413</td>\n",
        "      <td>-0.126703</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.077039</td>\n",
        "      <td>-0.02741</td>\n",
        "      <td>0.980719</td>\n",
        "      <td>-0.178466</td>\n",
        "      <td>-0.097359</td>\n",
        "      <td>-0.239318</td>\n",
        "      <td>-0.234774</td>\n",
        "      <td>-0.660284</td>\n",
        "      <td>-0.201793</td>\n",
        "      <td>-0.560172</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11816</th>\n",
        "      <td>-0.315304</td>\n",
        "      <td>-0.992904</td>\n",
        "      <td>0.175557</td>\n",
        "      <td>0.918071</td>\n",
        "      <td>-0.688471</td>\n",
        "      <td>1.100429</td>\n",
        "      <td>0.324032</td>\n",
        "      <td>0.673144</td>\n",
        "      <td>-0.087783</td>\n",
        "      <td>-0.260604</td>\n",
        "      <td>-0.530985</td>\n",
        "      <td>-0.511814</td>\n",
        "      <td>0.160592</td>\n",
        "      <td>-0.336140</td>\n",
        "      <td>-0.289949</td>\n",
        "      <td>-0.324210</td>\n",
        "      <td>-0.064754</td>\n",
        "      <td>-0.159741</td>\n",
        "      <td>0.170555</td>\n",
        "      <td>-0.244521</td>\n",
        "      <td>0.287265</td>\n",
        "      <td>-0.270939</td>\n",
        "      <td>-0.631262</td>\n",
        "      <td>1.232126</td>\n",
        "      <td>-0.257106</td>\n",
        "      <td>-0.227657</td>\n",
        "      <td>-0.095356</td>\n",
        "      <td>-0.302953</td>\n",
        "      <td>-0.212216</td>\n",
        "      <td>-0.320711</td>\n",
        "      <td>-0.265104</td>\n",
        "      <td>-0.146824</td>\n",
        "      <td>-0.343249</td>\n",
        "      <td>-0.330907</td>\n",
        "      <td>-0.523963</td>\n",
        "      <td>-0.022811</td>\n",
        "      <td>-0.615373</td>\n",
        "      <td>-0.470836</td>\n",
        "      <td>-0.215873</td>\n",
        "      <td>-0.229521</td>\n",
        "      <td>-1.088115</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.148740</td>\n",
        "      <td>3.843065</td>\n",
        "      <td>-0.174081</td>\n",
        "      <td>0.929597</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.303334</td>\n",
        "      <td>-0.193784</td>\n",
        "      <td>-0.059103</td>\n",
        "      <td>-0.029567</td>\n",
        "      <td>2.231701</td>\n",
        "      <td>-0.243344</td>\n",
        "      <td>-0.204674</td>\n",
        "      <td>-0.214339</td>\n",
        "      <td>0.041410</td>\n",
        "      <td>-0.186730</td>\n",
        "      <td>-0.322852</td>\n",
        "      <td>-0.113742</td>\n",
        "      <td>-0.320583</td>\n",
        "      <td>-0.355277</td>\n",
        "      <td>-0.310863</td>\n",
        "      <td>-0.376732</td>\n",
        "      <td>-0.395786</td>\n",
        "      <td>-0.169413</td>\n",
        "      <td>-0.126703</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.077039</td>\n",
        "      <td>-0.02741</td>\n",
        "      <td>0.356846</td>\n",
        "      <td>-0.178466</td>\n",
        "      <td>0.423372</td>\n",
        "      <td>-0.239318</td>\n",
        "      <td>-0.234774</td>\n",
        "      <td>-0.185558</td>\n",
        "      <td>-0.185408</td>\n",
        "      <td>-0.149134</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>85592</th>\n",
        "      <td>-1.260154</td>\n",
        "      <td>-0.472416</td>\n",
        "      <td>0.049684</td>\n",
        "      <td>0.986194</td>\n",
        "      <td>-1.217414</td>\n",
        "      <td>-0.788233</td>\n",
        "      <td>-0.582832</td>\n",
        "      <td>-0.607084</td>\n",
        "      <td>-0.145542</td>\n",
        "      <td>-0.260604</td>\n",
        "      <td>-0.530985</td>\n",
        "      <td>-0.511814</td>\n",
        "      <td>-0.307197</td>\n",
        "      <td>-0.454470</td>\n",
        "      <td>-0.461415</td>\n",
        "      <td>-0.488431</td>\n",
        "      <td>-0.064754</td>\n",
        "      <td>-0.159741</td>\n",
        "      <td>-1.426257</td>\n",
        "      <td>-0.244521</td>\n",
        "      <td>-1.012913</td>\n",
        "      <td>-0.270939</td>\n",
        "      <td>-0.631262</td>\n",
        "      <td>-0.672460</td>\n",
        "      <td>-0.257106</td>\n",
        "      <td>-0.227657</td>\n",
        "      <td>-0.095356</td>\n",
        "      <td>-0.319257</td>\n",
        "      <td>-0.428944</td>\n",
        "      <td>-0.404146</td>\n",
        "      <td>-0.398203</td>\n",
        "      <td>-0.451278</td>\n",
        "      <td>-0.459311</td>\n",
        "      <td>-0.341828</td>\n",
        "      <td>-0.688791</td>\n",
        "      <td>-0.892680</td>\n",
        "      <td>-0.750410</td>\n",
        "      <td>-0.470836</td>\n",
        "      <td>-0.215873</td>\n",
        "      <td>-0.229521</td>\n",
        "      <td>1.022951</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.318523</td>\n",
        "      <td>-0.514431</td>\n",
        "      <td>-0.080277</td>\n",
        "      <td>-0.411136</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.770577</td>\n",
        "      <td>-0.193784</td>\n",
        "      <td>-0.254483</td>\n",
        "      <td>-0.450151</td>\n",
        "      <td>-0.581367</td>\n",
        "      <td>-0.243344</td>\n",
        "      <td>-0.201214</td>\n",
        "      <td>-0.212008</td>\n",
        "      <td>-0.299133</td>\n",
        "      <td>-0.222947</td>\n",
        "      <td>-0.259908</td>\n",
        "      <td>-0.229159</td>\n",
        "      <td>-0.331991</td>\n",
        "      <td>-0.745622</td>\n",
        "      <td>-0.310863</td>\n",
        "      <td>-0.376732</td>\n",
        "      <td>-0.395786</td>\n",
        "      <td>-0.169413</td>\n",
        "      <td>-0.126703</td>\n",
        "      <td>0.0</td>\n",
        "      <td>-0.077039</td>\n",
        "      <td>-0.02741</td>\n",
        "      <td>-1.855064</td>\n",
        "      <td>-0.178466</td>\n",
        "      <td>-0.531302</td>\n",
        "      <td>-0.239318</td>\n",
        "      <td>-0.234774</td>\n",
        "      <td>-0.660284</td>\n",
        "      <td>-0.201793</td>\n",
        "      <td>-0.560172</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "             C6        C8       C13       C15       C16       C24       C33  \\\n",
        "39086  0.920270  0.787711 -0.920991 -1.227806  1.427298  0.156098 -0.582832   \n",
        "58456 -1.405516 -1.129874  0.175557  1.224625 -0.688471  1.100429  0.021744   \n",
        "78321  0.556866 -0.499810 -0.920991 -0.512514 -0.688471 -0.788233 -0.582832   \n",
        "11816 -0.315304 -0.992904  0.175557  0.918071 -0.688471  1.100429  0.324032   \n",
        "85592 -1.260154 -0.472416  0.049684  0.986194 -1.217414 -0.788233 -0.582832   \n",
        "\n",
        "            C34       C35       C37       C38       C40       C43       C48  \\\n",
        "39086 -0.607084 -0.145542 -0.260604 -0.530985 -0.511814 -0.307197 -0.084944   \n",
        "58456  0.673144 -0.030023 -0.260604 -0.530985 -0.511814  0.160592 -0.454470   \n",
        "78321 -0.607084  0.143255 -0.260604  0.307589  1.556122  0.628380 -0.403467   \n",
        "11816  0.673144 -0.087783 -0.260604 -0.530985 -0.511814  0.160592 -0.336140   \n",
        "85592 -0.607084 -0.145542 -0.260604 -0.530985 -0.511814 -0.307197 -0.454470   \n",
        "\n",
        "            C51       C52       C53       C57       C58       C59       C60  \\\n",
        "39086  0.856588 -0.417385 -0.064754  4.753483 -1.019226 -0.244521  2.144662   \n",
        "58456 -0.461415 -0.488431 -0.064754 -0.159741 -1.426257 -0.244521 -1.012913   \n",
        "78321 -0.344962 -0.488431 -0.064754 -0.159741 -0.017305 -0.244521  1.030224   \n",
        "11816 -0.289949 -0.324210 -0.064754 -0.159741  0.170555 -0.244521  0.287265   \n",
        "85592 -0.461415 -0.488431 -0.064754 -0.159741 -1.426257 -0.244521 -1.012913   \n",
        "\n",
        "            C63       C64       C65       C66       C67       C70       C72  \\\n",
        "39086 -0.270939  0.835349 -0.400377 -0.257106  7.697360 -0.095356  0.213187   \n",
        "58456 -0.270939 -0.631262 -0.672460 -0.257106 -0.227657 -0.095356 -0.319257   \n",
        "78321 -0.270939 -0.413986  2.102794 -0.257106 -0.227657 -0.095356 -0.319257   \n",
        "11816 -0.270939 -0.631262  1.232126 -0.257106 -0.227657 -0.095356 -0.302953   \n",
        "85592 -0.270939 -0.631262 -0.672460 -0.257106 -0.227657 -0.095356 -0.319257   \n",
        "\n",
        "            C73       C74       C75       C76       C77       C78       C84  \\\n",
        "39086 -0.326114 -0.006994 -0.339306  0.003158 -0.034065 -0.320668  0.712246   \n",
        "58456 -0.428944 -0.404146 -0.398203 -0.451278 -0.459311 -0.341828 -0.688791   \n",
        "78321 -0.405888 -0.197703 -0.385682 -0.358325 -0.419371 -0.332613 -0.688791   \n",
        "11816 -0.212216 -0.320711 -0.265104 -0.146824 -0.343249 -0.330907 -0.523963   \n",
        "85592 -0.428944 -0.404146 -0.398203 -0.451278 -0.459311 -0.341828 -0.688791   \n",
        "\n",
        "            C89       C90       C91       C98       C99      C100  C102  \\\n",
        "39086  0.111015 -0.682891  0.784748 -0.215873 -0.229521  1.307667   0.0   \n",
        "58456 -0.892680 -0.750410 -0.470836 -0.215873 -0.229521 -1.088115   0.0   \n",
        "78321 -0.223550 -0.547854 -0.470836 -0.215873 -0.229521  0.099360   0.0   \n",
        "11816 -0.022811 -0.615373 -0.470836 -0.215873 -0.229521 -1.088115   0.0   \n",
        "85592 -0.892680 -0.750410 -0.470836 -0.215873 -0.229521  1.022951   0.0   \n",
        "\n",
        "           C103      C104      C106      C107  C110      C115      C117  \\\n",
        "39086  1.491983 -0.379254 -0.174081 -0.411136   0.0  1.409890 -0.193784   \n",
        "58456 -0.480501 -0.549129 -0.174081 -0.411136   0.0 -0.770577 -0.193784   \n",
        "78321 -0.346115 -0.411133  1.919848  3.208841   0.0 -0.770577 -0.193784   \n",
        "11816 -0.148740  3.843065 -0.174081  0.929597   0.0 -0.303334 -0.193784   \n",
        "85592 -0.318523 -0.514431 -0.080277 -0.411136   0.0 -0.770577 -0.193784   \n",
        "\n",
        "           C118      C119      C120      C122      C124      C127      C128  \\\n",
        "39086 -0.645244 -0.450151 -0.849279 -0.243344 -0.204674 -0.214339 -0.317650   \n",
        "58456 -0.645244 -0.450151 -0.849279 -0.243344 -0.204674 -0.214339 -0.317650   \n",
        "78321 -0.645244 -0.239859 -0.581367 -0.243344 -0.204674 -0.214339 -0.317650   \n",
        "11816 -0.059103 -0.029567  2.231701 -0.243344 -0.204674 -0.214339  0.041410   \n",
        "85592 -0.254483 -0.450151 -0.581367 -0.243344 -0.201214 -0.212008 -0.299133   \n",
        "\n",
        "           C129      C130      C139      C140      C155      C164      C170  \\\n",
        "39086 -0.338173 -0.330850 -0.229224 -0.339555 -0.105457 -0.310863 -0.376732   \n",
        "58456 -0.337152 -0.330406 -0.229011 -0.314011 -0.745622 -0.310863 -0.376732   \n",
        "78321 -0.338173 -0.330850 -0.229224 -0.339555 -0.542643 -0.310863 -0.376732   \n",
        "11816 -0.186730 -0.322852 -0.113742 -0.320583 -0.355277 -0.310863 -0.376732   \n",
        "85592 -0.222947 -0.259908 -0.229159 -0.331991 -0.745622 -0.310863 -0.376732   \n",
        "\n",
        "           C171      C172      C174  C176      C178     C189      C191  \\\n",
        "39086  1.160587 -0.169413 -0.126703   0.0 -0.077039 -0.02741  0.640425   \n",
        "58456 -0.395786 -0.169413 -0.126703   0.0 -0.077039 -0.02741 -1.855064   \n",
        "78321 -0.395786 -0.169413 -0.126703   0.0 -0.077039 -0.02741  0.980719   \n",
        "11816 -0.395786 -0.169413 -0.126703   0.0 -0.077039 -0.02741  0.356846   \n",
        "85592 -0.395786 -0.169413 -0.126703   0.0 -0.077039 -0.02741 -1.855064   \n",
        "\n",
        "           C196      C201      C202      C203      C211      C212      C213  \n",
        "39086 -0.178466  0.249795 -0.239318  3.462945 -0.660284 -0.201793 -0.560172  \n",
        "58456 -0.178466 -0.531302 -0.239318 -0.234774 -0.660284 -0.201793 -0.560172  \n",
        "78321 -0.178466 -0.097359 -0.239318 -0.234774 -0.660284 -0.201793 -0.560172  \n",
        "11816 -0.178466  0.423372 -0.239318 -0.234774 -0.185558 -0.185408 -0.149134  \n",
        "85592 -0.178466 -0.531302 -0.239318 -0.234774 -0.660284 -0.201793 -0.560172  "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Feature Selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectKBest, f_classif\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn import svm\n",
      "\n",
      "#coding\n",
      "X, y = dfc, df['C3'].replace({'N':0, 'Y':1})\n",
      "anova_svm = Pipeline([('anova', SelectKBest(f_classif, k=9)), ('svc', svm.SVC(kernel='linear'))])\n",
      "anova_svm.set_params(svc__C=0.1).fit(X, y)\n",
      "\n",
      "print anova_svm.score(X, y)\n",
      "\n",
      "filtered = [dfc.columns[i] for i in anova_svm.named_steps['anova'].get_support(indices=True)]\n",
      "print filtered\n",
      "\n",
      "#ranked_features = sorted(enumerate(anova_svm.named_steps['anova'].scores_), key=lambda x:x[1], reverse=True)\n",
      "#print [dfc.columns[e[0]] for e in ranked_features]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n",
        "['C6', 'C8', 'C13', 'C16', 'C24', 'C33', 'C34', 'C60', 'C100']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [41 46 66] are constant.\n",
        "  UserWarning)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "\n",
      "dfc = df.loc[:, [df.columns[i] for i in xrange(len(df.columns)) if df.dtypes[i]=='object' and df.columns[i]!='C3']]\n",
      "for col in dfc.columns:\n",
      "    dfc[col] = df[col].replace({name: n for n, name in enumerate(df[col].unique())})\n",
      "\n",
      "selector = SelectKBest(chi2, k=9).fit(dfc, y)\n",
      "filtered2 = [dfc.columns[i] for i in selector.get_support(indices=True)]\n",
      "print filtered2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['C4', 'C10', 'C12', 'C19', 'C22', 'C23', 'C31', 'C93', 'C95']\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Preprocessing (for Prediction)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "choosed = filtered + filtered2\n",
      "choosed.remove('C22')\n",
      "choosed.remove('C24')\n",
      "\n",
      "X = df.loc[:, choosed]\n",
      "y = df['C3'].replace({'N':0, 'Y':1})\n",
      "for col in X.columns:\n",
      "  try:\n",
      "    X[col].fillna(0, inplace=True)\n",
      "    X[col] = StandardScaler().fit_transform(X[col])\n",
      "  except:\n",
      "    X[col] = X[col].replace({name: n for n, name in enumerate(X[col].unique())})\n",
      "\n",
      "X.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C6</th>\n",
        "      <th>C8</th>\n",
        "      <th>C13</th>\n",
        "      <th>C16</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C60</th>\n",
        "      <th>C100</th>\n",
        "      <th>C4</th>\n",
        "      <th>C10</th>\n",
        "      <th>C12</th>\n",
        "      <th>C19</th>\n",
        "      <th>C23</th>\n",
        "      <th>C31</th>\n",
        "      <th>C93</th>\n",
        "      <th>C95</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>39086</th>\n",
        "      <td>0.920270</td>\n",
        "      <td>0.787711</td>\n",
        "      <td>-0.920991</td>\n",
        "      <td>1.427298</td>\n",
        "      <td>-0.582832</td>\n",
        "      <td>-0.607084</td>\n",
        "      <td>2.144662</td>\n",
        "      <td>1.307667</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>58456</th>\n",
        "      <td>-1.405516</td>\n",
        "      <td>-1.129874</td>\n",
        "      <td>0.175557</td>\n",
        "      <td>-0.688471</td>\n",
        "      <td>0.021744</td>\n",
        "      <td>0.673144</td>\n",
        "      <td>-1.012913</td>\n",
        "      <td>-1.088115</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>78321</th>\n",
        "      <td>0.556866</td>\n",
        "      <td>-0.499810</td>\n",
        "      <td>-0.920991</td>\n",
        "      <td>-0.688471</td>\n",
        "      <td>-0.582832</td>\n",
        "      <td>-0.607084</td>\n",
        "      <td>1.030224</td>\n",
        "      <td>0.099360</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11816</th>\n",
        "      <td>-0.315304</td>\n",
        "      <td>-0.992904</td>\n",
        "      <td>0.175557</td>\n",
        "      <td>-0.688471</td>\n",
        "      <td>0.324032</td>\n",
        "      <td>0.673144</td>\n",
        "      <td>0.287265</td>\n",
        "      <td>-1.088115</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>85592</th>\n",
        "      <td>-1.260154</td>\n",
        "      <td>-0.472416</td>\n",
        "      <td>0.049684</td>\n",
        "      <td>-1.217414</td>\n",
        "      <td>-0.582832</td>\n",
        "      <td>-0.607084</td>\n",
        "      <td>-1.012913</td>\n",
        "      <td>1.022951</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "             C6        C8       C13       C16       C33       C34       C60  \\\n",
        "39086  0.920270  0.787711 -0.920991  1.427298 -0.582832 -0.607084  2.144662   \n",
        "58456 -1.405516 -1.129874  0.175557 -0.688471  0.021744  0.673144 -1.012913   \n",
        "78321  0.556866 -0.499810 -0.920991 -0.688471 -0.582832 -0.607084  1.030224   \n",
        "11816 -0.315304 -0.992904  0.175557 -0.688471  0.324032  0.673144  0.287265   \n",
        "85592 -1.260154 -0.472416  0.049684 -1.217414 -0.582832 -0.607084 -1.012913   \n",
        "\n",
        "           C100  C4  C10  C12  C19  C23  C31  C93  C95  \n",
        "39086  1.307667   0    0    0    0    0    0    0    0  \n",
        "58456 -1.088115   0    1    1    1    0    1    1    1  \n",
        "78321  0.099360   0    1    0    0    0    0    2    2  \n",
        "11816 -1.088115   0    1    1    0    0    2    1    1  \n",
        "85592  1.022951   0    1    0    0    0    0    3    3  "
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Decision Tree Classifier (CART)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn import tree\n",
      "\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf0 = tree.DecisionTreeClassifier().fit(X_train, y_train) #CART\n",
      "clf0.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0.59275"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_code(tree, feature_names):\n",
      "  left = tree.tree_.children_left\n",
      "  right = tree.tree_.children_right\n",
      "  threshold = tree.tree_.threshold\n",
      "  features = [feature_names[i] for i in tree.tree_.feature]\n",
      "  value = tree.tree_.value\n",
      "\n",
      "  def recurse(left, right, threshold, features, node):\n",
      "    if threshold[node] != -2:\n",
      "      print \"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\"\n",
      "      if left[node] != -1:\n",
      "        recurse (left, right, threshold, features,left[node])\n",
      "      print \"} else {\"\n",
      "      if right[node] != -1:\n",
      "        recurse (left, right, threshold, features,right[node])\n",
      "      print \"}\"\n",
      "    else:\n",
      "      print \"return \" + str(value[node])\n",
      "  \n",
      "  recurse(left, right, threshold, features, 0)\n",
      "\n",
      "#get_code(clf, X.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Naive Bayes Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf1 = GaussianNB().fit(X_train, y_train)\n",
      "clf1.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.62549999999999994"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Logistic Regression (aka logit, MaxEnt) Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf2 = LogisticRegression().fit(X_train, y_train)\n",
      "clf2.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.65649999999999997"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Random Forest Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "clf3 = RandomForestClassifier(n_estimators=10, class_weight={0:1, 1:10}).fit(X_train, y_train)\n",
      "print clf3.score(X_test, y_test)\n",
      "\n",
      "print sorted(zip(choosed, clf3.feature_importances_), key=lambda x: x[1], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.643\n",
        "[('C8', 0.15914957459381712), ('C6', 0.13801254222035539), ('C93', 0.1034689536310556), ('C60', 0.10321482716056152), ('C100', 0.10009669521808073), ('C95', 0.088111342503554707), ('C13', 0.067699049396618194), ('C19', 0.059535368580185696), ('C16', 0.058396060631421734), ('C33', 0.035772325074561684), ('C12', 0.022347327513045804), ('C4', 0.021128910397190934), ('C31', 0.016550864591715495), ('C10', 0.015375796080084669), ('C34', 0.010079917880732928), ('C23', 0.0010604445270178471)]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##SVM Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn import svm\n",
      "\n",
      "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "\n",
      "#clf4 = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
      "clf4 = svm.SVC(kernel='rbf', probability=True).fit(X_train, y_train)\n",
      "clf4.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "0.65995525727069348"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Clustering and Choose Classifier for each group"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "\n",
      "#X_cData = X.loc[:, [c for c in filtered[:8] if c!='C24']].fillna(0)\n",
      "choosed_for_clustering = ['C8', 'C6', 'C60'] #[c for c in filtered[:8] if c!='C24']\n",
      "X_cData = X.loc[:, choosed_for_clustering]\n",
      "\n",
      "kmeans = KMeans(init='k-means++', n_clusters=3)\n",
      "kmeans.fit(X_cData)\n",
      "df['clabel'] = kmeans.labels_\n",
      "#df['clabel'].value_counts(sort=True)\n",
      "\n",
      "clfs = [None for i in xrange(3)]\n",
      "for i in xrange(3):\n",
      "    _X = df.loc[df['clabel']==i, choosed]\n",
      "    _y = df.loc[df['clabel']==i, 'C3'].replace({'N':0, 'Y':1})\n",
      "    for col in _X.columns:\n",
      "      try:\n",
      "        _X[col].fillna(0, inplace=True)\n",
      "        _X[col] = StandardScaler().fit_transform(_X[col])\n",
      "      except:\n",
      "        _X[col] = _X[col].replace({name: n for n, name in enumerate(_X[col].unique())})\n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(_X, _y, test_size=0.4, random_state=0)\n",
      "    clfs[i] = RandomForestClassifier(n_estimators=10, class_weight={0:1, 1:10}).fit(X_train, y_train)\n",
      "    score = clfs[i].score(X_test, y_test)\n",
      "    if score<0.65: clfs[i] = svm.SVC(kernel='rbf', probability=True).fit(X_train, y_train)\n",
      "    print clfs[i].score(X_test, y_test)\n",
      "\n",
      "#X_train.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.60549132948\n",
        "0.586186883343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.659955257271"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Voting Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import VotingClassifier\n",
      "\n",
      "vclf = VotingClassifier(estimators=[('naiveBayes', clf1), ('LogisticR', clf2), ('randomF', clf3), ('svc', clf4)], voting='soft', weights=[1,3,3,3]).fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "dfp = pd.read_csv('../../MB_PCUST_NPOUT_EXAM.txt', encoding='utf-8', sep='\\t', names=['C2']+['C'+str(i+4) for i in xrange(212)], na_values=['?'])\n",
      "\n",
      "Xp = dfp.loc[:, choosed]\n",
      "for col in Xp.columns:\n",
      "  try:\n",
      "    Xp[col].fillna(0, inplace=True)\n",
      "    Xp[col] = StandardScaler().fit_transform(Xp[col])\n",
      "  except:\n",
      "    Xp[col] = Xp[col].replace({name: n for n, name in enumerate(Xp[col].unique())})\n",
      "\n",
      "dfp['pred_C3'] = clf2.predict(Xp)\n",
      "dfp['C3'] = dfp['C24'].map(lambda x: 1 if x>0 else 0)\n",
      "\n",
      "print accuracy_score(dfp['C3'], dfp['pred_C3'])\n",
      "\n",
      "dfp.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.6503\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C2</th>\n",
        "      <th>C4</th>\n",
        "      <th>C5</th>\n",
        "      <th>C6</th>\n",
        "      <th>C7</th>\n",
        "      <th>C8</th>\n",
        "      <th>C9</th>\n",
        "      <th>C10</th>\n",
        "      <th>C11</th>\n",
        "      <th>C12</th>\n",
        "      <th>C13</th>\n",
        "      <th>C14</th>\n",
        "      <th>C15</th>\n",
        "      <th>C16</th>\n",
        "      <th>C17</th>\n",
        "      <th>C18</th>\n",
        "      <th>C19</th>\n",
        "      <th>C20</th>\n",
        "      <th>C21</th>\n",
        "      <th>C22</th>\n",
        "      <th>C23</th>\n",
        "      <th>C24</th>\n",
        "      <th>C25</th>\n",
        "      <th>C26</th>\n",
        "      <th>C27</th>\n",
        "      <th>C28</th>\n",
        "      <th>C29</th>\n",
        "      <th>C30</th>\n",
        "      <th>C31</th>\n",
        "      <th>C32</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C35</th>\n",
        "      <th>C36</th>\n",
        "      <th>C37</th>\n",
        "      <th>C38</th>\n",
        "      <th>C39</th>\n",
        "      <th>C40</th>\n",
        "      <th>C41</th>\n",
        "      <th>C42</th>\n",
        "      <th>C43</th>\n",
        "      <th>C44</th>\n",
        "      <th>C45</th>\n",
        "      <th>C46</th>\n",
        "      <th>C47</th>\n",
        "      <th>C48</th>\n",
        "      <th>C49</th>\n",
        "      <th>C50</th>\n",
        "      <th>C51</th>\n",
        "      <th>C52</th>\n",
        "      <th>C53</th>\n",
        "      <th>C54</th>\n",
        "      <th>C55</th>\n",
        "      <th>C56</th>\n",
        "      <th>C57</th>\n",
        "      <th>C58</th>\n",
        "      <th>C59</th>\n",
        "      <th>C60</th>\n",
        "      <th>C61</th>\n",
        "      <th>C62</th>\n",
        "      <th>C63</th>\n",
        "      <th>C64</th>\n",
        "      <th>C65</th>\n",
        "      <th>C66</th>\n",
        "      <th>C67</th>\n",
        "      <th>C68</th>\n",
        "      <th>C69</th>\n",
        "      <th>C70</th>\n",
        "      <th>C71</th>\n",
        "      <th>C72</th>\n",
        "      <th>C73</th>\n",
        "      <th>C74</th>\n",
        "      <th>C75</th>\n",
        "      <th>C76</th>\n",
        "      <th>C77</th>\n",
        "      <th>C78</th>\n",
        "      <th>C79</th>\n",
        "      <th>C80</th>\n",
        "      <th>C81</th>\n",
        "      <th>C82</th>\n",
        "      <th>C83</th>\n",
        "      <th>C84</th>\n",
        "      <th>C85</th>\n",
        "      <th>C86</th>\n",
        "      <th>C87</th>\n",
        "      <th>C88</th>\n",
        "      <th>C89</th>\n",
        "      <th>C90</th>\n",
        "      <th>C91</th>\n",
        "      <th>C92</th>\n",
        "      <th>C93</th>\n",
        "      <th>C94</th>\n",
        "      <th>C95</th>\n",
        "      <th>C96</th>\n",
        "      <th>C97</th>\n",
        "      <th>C98</th>\n",
        "      <th>C99</th>\n",
        "      <th>C100</th>\n",
        "      <th>C101</th>\n",
        "      <th>C102</th>\n",
        "      <th>C103</th>\n",
        "      <th>C104</th>\n",
        "      <th>C105</th>\n",
        "      <th>C106</th>\n",
        "      <th>C107</th>\n",
        "      <th>C108</th>\n",
        "      <th>C109</th>\n",
        "      <th>C110</th>\n",
        "      <th>C111</th>\n",
        "      <th>C112</th>\n",
        "      <th>C113</th>\n",
        "      <th>C114</th>\n",
        "      <th>C115</th>\n",
        "      <th>C116</th>\n",
        "      <th>C117</th>\n",
        "      <th>C118</th>\n",
        "      <th>C119</th>\n",
        "      <th>C120</th>\n",
        "      <th>C121</th>\n",
        "      <th>C122</th>\n",
        "      <th>C123</th>\n",
        "      <th>C124</th>\n",
        "      <th>C125</th>\n",
        "      <th>C126</th>\n",
        "      <th>C127</th>\n",
        "      <th>C128</th>\n",
        "      <th>C129</th>\n",
        "      <th>C130</th>\n",
        "      <th>C131</th>\n",
        "      <th>C132</th>\n",
        "      <th>C133</th>\n",
        "      <th>C134</th>\n",
        "      <th>C135</th>\n",
        "      <th>C136</th>\n",
        "      <th>C137</th>\n",
        "      <th>C138</th>\n",
        "      <th>C139</th>\n",
        "      <th>C140</th>\n",
        "      <th>C141</th>\n",
        "      <th>C142</th>\n",
        "      <th>C143</th>\n",
        "      <th>C144</th>\n",
        "      <th>C145</th>\n",
        "      <th>C146</th>\n",
        "      <th>C147</th>\n",
        "      <th>C148</th>\n",
        "      <th>C149</th>\n",
        "      <th>C150</th>\n",
        "      <th>C151</th>\n",
        "      <th>C152</th>\n",
        "      <th>C153</th>\n",
        "      <th>C154</th>\n",
        "      <th>C155</th>\n",
        "      <th>C156</th>\n",
        "      <th>C157</th>\n",
        "      <th>C158</th>\n",
        "      <th>C159</th>\n",
        "      <th>C160</th>\n",
        "      <th>C161</th>\n",
        "      <th>C162</th>\n",
        "      <th>C163</th>\n",
        "      <th>C164</th>\n",
        "      <th>C165</th>\n",
        "      <th>C166</th>\n",
        "      <th>C167</th>\n",
        "      <th>C168</th>\n",
        "      <th>C169</th>\n",
        "      <th>C170</th>\n",
        "      <th>C171</th>\n",
        "      <th>C172</th>\n",
        "      <th>C173</th>\n",
        "      <th>C174</th>\n",
        "      <th>C175</th>\n",
        "      <th>C176</th>\n",
        "      <th>C177</th>\n",
        "      <th>C178</th>\n",
        "      <th>C179</th>\n",
        "      <th>C180</th>\n",
        "      <th>C181</th>\n",
        "      <th>C182</th>\n",
        "      <th>C183</th>\n",
        "      <th>C184</th>\n",
        "      <th>C185</th>\n",
        "      <th>C186</th>\n",
        "      <th>C187</th>\n",
        "      <th>C188</th>\n",
        "      <th>C189</th>\n",
        "      <th>C190</th>\n",
        "      <th>C191</th>\n",
        "      <th>C192</th>\n",
        "      <th>C193</th>\n",
        "      <th>C194</th>\n",
        "      <th>C195</th>\n",
        "      <th>C196</th>\n",
        "      <th>C197</th>\n",
        "      <th>C198</th>\n",
        "      <th>C199</th>\n",
        "      <th>C200</th>\n",
        "      <th>C201</th>\n",
        "      <th>C202</th>\n",
        "      <th>C203</th>\n",
        "      <th>C204</th>\n",
        "      <th>C205</th>\n",
        "      <th>C206</th>\n",
        "      <th>C207</th>\n",
        "      <th>C208</th>\n",
        "      <th>C209</th>\n",
        "      <th>C210</th>\n",
        "      <th>C211</th>\n",
        "      <th>C212</th>\n",
        "      <th>C213</th>\n",
        "      <th>C214</th>\n",
        "      <th>C215</th>\n",
        "      <th>pred_C3</th>\n",
        "      <th>C3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>C0088856</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>45.0</td>\n",
        "      <td>\u96d9\u9b5a\u5ea7</td>\n",
        "      <td>14</td>\n",
        "      <td>\u64da\u9ede02</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u7121\u7d81\u7d04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>6</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Yes</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>C0268970</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>38.0</td>\n",
        "      <td>\u7345\u5b50\u5ea7</td>\n",
        "      <td>174</td>\n",
        "      <td>\u64da\u9ede07</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>4G</td>\n",
        "      <td>1136.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-70.0</td>\n",
        "      <td>8</td>\n",
        "      <td>6</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>\u9ad8</td>\n",
        "      <td>1.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>Yes</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>5.165101e+06</td>\n",
        "      <td>99.34</td>\n",
        "      <td>77.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>7.21</td>\n",
        "      <td>12.93</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>2.93</td>\n",
        "      <td>0.00</td>\n",
        "      <td>4.28</td>\n",
        "      <td>0.78</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.57</td>\n",
        "      <td>1.12</td>\n",
        "      <td>3.95</td>\n",
        "      <td>5.38</td>\n",
        "      <td>0.78</td>\n",
        "      <td>4.22</td>\n",
        "      <td>20.43</td>\n",
        "      <td>59.15</td>\n",
        "      <td>0.75</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.05</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.21</td>\n",
        "      <td>0.60</td>\n",
        "      <td>0.01</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u65b0\u71df\u5340</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u65b0\u71df\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>132.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>108701933.0</td>\n",
        "      <td>151396249.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>640602330.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>113758047.0</td>\n",
        "      <td>85067978.0</td>\n",
        "      <td>135352031.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>51434728.0</td>\n",
        "      <td>1.795074e+09</td>\n",
        "      <td>439151.0</td>\n",
        "      <td>326260868.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.906637e+09</td>\n",
        "      <td>0.0</td>\n",
        "      <td>557196876.0</td>\n",
        "      <td>5.169043e+09</td>\n",
        "      <td>448633971.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.716211e+09</td>\n",
        "      <td>570153410.0</td>\n",
        "      <td>99.35</td>\n",
        "      <td>77.32</td>\n",
        "      <td>7.21</td>\n",
        "      <td>12.93</td>\n",
        "      <td>12.93</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>79.21</td>\n",
        "      <td>59.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>90.26</td>\n",
        "      <td>77.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.94</td>\n",
        "      <td>0.86</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.14</td>\n",
        "      <td>59.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>19.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>37.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>232.0</td>\n",
        "      <td>903739.278320</td>\n",
        "      <td>0.174970</td>\n",
        "      <td>232.0</td>\n",
        "      <td>5.289064e+09</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>C0298512</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>62.0</td>\n",
        "      <td>\u5c04\u624b\u5ea7</td>\n",
        "      <td>73</td>\n",
        "      <td>\u64da\u9ede07</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-63.0</td>\n",
        "      <td>2</td>\n",
        "      <td>3</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>2.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>N</td>\n",
        "      <td>2</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>72.0</td>\n",
        "      <td>72.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>25.49</td>\n",
        "      <td>6.35</td>\n",
        "      <td>0.0</td>\n",
        "      <td>19.14</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.62</td>\n",
        "      <td>13.52</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.25</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.75</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.53</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.53</td>\n",
        "      <td>8.97</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.38</td>\n",
        "      <td>0.00</td>\n",
        "      <td>6.05</td>\n",
        "      <td>8.55</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.06</td>\n",
        "      <td>0.35</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.34</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u67f3\u71df\u5340</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>538.0</td>\n",
        "      <td>179.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>21.645</td>\n",
        "      <td>3.652</td>\n",
        "      <td>7.830</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>25.48</td>\n",
        "      <td>6.35</td>\n",
        "      <td>19.14</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.52</td>\n",
        "      <td>16.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.36</td>\n",
        "      <td>6.36</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>16.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>C0249782</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>56.0</td>\n",
        "      <td>\u91d1\u725b\u5ea7</td>\n",
        "      <td>226</td>\n",
        "      <td>\u64da\u9ede07</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-77.0</td>\n",
        "      <td>4</td>\n",
        "      <td>2</td>\n",
        "      <td>\u4f4e</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>Yes</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>21.43</td>\n",
        "      <td>5.22</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.64</td>\n",
        "      <td>2.57</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.07</td>\n",
        "      <td>9.57</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.64</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.19</td>\n",
        "      <td>0.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.40</td>\n",
        "      <td>2.57</td>\n",
        "      <td>7.13</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.00</td>\n",
        "      <td>9.17</td>\n",
        "      <td>2.87</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.32</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.41</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u65b0\u71df\u5340</td>\n",
        "      <td>\u53f0\u5357\u5e02</td>\n",
        "      <td>\u67f3\u71df\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>Yes</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>244.0</td>\n",
        "      <td>92.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>45.672</td>\n",
        "      <td>33.880</td>\n",
        "      <td>5.709</td>\n",
        "      <td>5.704305</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>22.35</td>\n",
        "      <td>6.14</td>\n",
        "      <td>13.64</td>\n",
        "      <td>2.57</td>\n",
        "      <td>2.57</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.14</td>\n",
        "      <td>16.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.70</td>\n",
        "      <td>6.14</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.56</td>\n",
        "      <td>0.71</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.29</td>\n",
        "      <td>14.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>7.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>C0180972</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>46.0</td>\n",
        "      <td>\u9b54\u7faf\u5ea7</td>\n",
        "      <td>83</td>\n",
        "      <td>\u64da\u9ede04</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>3G</td>\n",
        "      <td>383.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-73.0</td>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "      <td>\u4f4e</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>3.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7af6\u696dD</td>\n",
        "      <td>82.0</td>\n",
        "      <td>106.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>9.011243e+05</td>\n",
        "      <td>58.42</td>\n",
        "      <td>14.80</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.35</td>\n",
        "      <td>26.27</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.35</td>\n",
        "      <td>0.62</td>\n",
        "      <td>9.88</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.25</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.30</td>\n",
        "      <td>0.45</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.17</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>8.97</td>\n",
        "      <td>14.07</td>\n",
        "      <td>8.05</td>\n",
        "      <td>23.27</td>\n",
        "      <td>3.23</td>\n",
        "      <td>0.83</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.15</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.14</td>\n",
        "      <td>0.40</td>\n",
        "      <td>0.06</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u5f70\u5316\u7e23</td>\n",
        "      <td>\u548c\u7f8e\u93ae</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>93.0</td>\n",
        "      <td>72.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>45.726</td>\n",
        "      <td>46.141</td>\n",
        "      <td>28.992</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>562953.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6514284.0</td>\n",
        "      <td>45907574.0</td>\n",
        "      <td>581620.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.128205e+06</td>\n",
        "      <td>0.0</td>\n",
        "      <td>567134600.0</td>\n",
        "      <td>2.739706e+08</td>\n",
        "      <td>21208770.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>58.42</td>\n",
        "      <td>14.80</td>\n",
        "      <td>16.85</td>\n",
        "      <td>26.27</td>\n",
        "      <td>26.27</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>26.27</td>\n",
        "      <td>51.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>27.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>27.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>41.07</td>\n",
        "      <td>14.80</td>\n",
        "      <td>0.0</td>\n",
        "      <td>26.27</td>\n",
        "      <td>0.36</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.64</td>\n",
        "      <td>51.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>40.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>\u56fa\u7db2</td>\n",
        "      <td>24.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>259.0</td>\n",
        "      <td>57456.744141</td>\n",
        "      <td>0.063761</td>\n",
        "      <td>259.0</td>\n",
        "      <td>9.227513e+08</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "         C2    C4 C5    C6   C7   C8    C9 C10 C11 C12     C13  C14   C15  \\\n",
        "0  C0088856  NVIP  M  45.0  \u96d9\u9b5a\u5ea7   14  \u64da\u9ede02   N  \u6975\u4f4e  3G   183.0  \u7121\u7d81\u7d04   NaN   \n",
        "1  C0268970  NVIP  F  38.0  \u7345\u5b50\u5ea7  174  \u64da\u9ede07   N   \u4e2d  4G  1136.0  \u8cfc\u6a5f\u7d04 -70.0   \n",
        "2  C0298512  NVIP  M  62.0  \u5c04\u624b\u5ea7   73  \u64da\u9ede07   N  \u6975\u4f4e  3G   183.0  \u901a\u4fe1\u7d04 -63.0   \n",
        "3  C0249782  NVIP  M  56.0  \u91d1\u725b\u5ea7  226  \u64da\u9ede07   N  \u6975\u4f4e  3G   183.0  \u8cfc\u6a5f\u7d04 -77.0   \n",
        "4  C0180972  NVIP  M  46.0  \u9b54\u7faf\u5ea7   83  \u64da\u9ede04   N   \u4e2d  3G   383.0  \u901a\u4fe1\u7d04 -73.0   \n",
        "\n",
        "   C16  C17 C18 C19  C20  C21  C22 C23  C24  C25  C26  C27  C28  C29  C30  \\\n",
        "0    0    0  \u96f6\u5143  \u96f6\u5143  NaN  NaN    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "1    8    6   \u4e2d   \u9ad8  1.0  4.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "2    2    3  \u4f4e\u4e2d  \u4f4e\u4e2d  2.0  3.0  \u7af6\u696dB   N    2  1.0  1.0  NaN    1  NaN  1.0   \n",
        "3    4    2   \u4f4e  \u96f6\u5143  2.0  1.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "4    2    2   \u4f4e  \u4f4e\u4e2d  3.0  2.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "\n",
        "   C31   C32    C33  C34  C35  C36  C37  C38  C39  C40  C41  C42  C43  C44  \\\n",
        "0  \u7121NP   NaN    NaN  NaN    6    3    1    0    0    1    1    0    2  NaN   \n",
        "1  \u7121NP   NaN    NaN  NaN    4    1    0    1    0    1    1    0    2  Yes   \n",
        "2  \u7af6\u696dA  72.0   72.0  1.0    3    2    0    1    0    0    0    0    2  NaN   \n",
        "3  \u7121NP   NaN    NaN  NaN    8    3    1    2    0    1    1    0    1  Yes   \n",
        "4  \u7af6\u696dD  82.0  106.0  2.0    1    1    0    0    0    0    0    0    1  NaN   \n",
        "\n",
        "   C45 C46           C47    C48    C49  C50    C51    C52  C53   C54    C55  \\\n",
        "0  Yes  No           NaN    NaN    NaN  NaN    NaN    NaN  NaN   NaN    NaN   \n",
        "1  NaN  No  5.165101e+06  99.34  77.32  0.0   7.21  12.93  0.0  0.00   2.93   \n",
        "2  NaN  No           NaN  25.49   6.35  0.0  19.14   0.00  0.0  5.62  13.52   \n",
        "3  NaN  No           NaN  21.43   5.22  0.0  13.64   2.57  0.0  4.07   9.57   \n",
        "4  NaN  No  9.011243e+05  58.42  14.80  0.0  17.35  26.27  0.0  6.35   0.62   \n",
        "\n",
        "    C56   C57   C58  C59   C60   C61  C62   C63   C64   C65   C66   C67  C68  \\\n",
        "0   NaN   NaN   NaN  NaN   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  NaN   \n",
        "1  0.00  4.28  0.78  0.0  0.07  0.13  0.0  0.02  0.00  0.03  0.00  0.04  0.0   \n",
        "2  0.00  0.00  0.25  0.0  0.75  0.00  0.0  0.00  0.22  0.53  0.00  0.00  0.0   \n",
        "3  0.00  0.00  0.24  0.0  0.64  0.12  0.0  0.00  0.19  0.45  0.00  0.00  0.0   \n",
        "4  9.88  0.00  0.25  0.0  0.30  0.45  0.0  0.00  0.11  0.01  0.17  0.00  0.0   \n",
        "\n",
        "   C69  C70   C71   C72    C73   C74    C75   C76    C77    C78   C79  C80  \\\n",
        "0  NaN  NaN   NaN   NaN    NaN   NaN    NaN   NaN    NaN    NaN   NaN  NaN   \n",
        "1  0.0  0.0  3.57  1.12   3.95  5.38   0.78  4.22  20.43  59.15  0.75  0.0   \n",
        "2  0.0  0.0  0.00  1.53   8.97  0.00   0.38  0.00   6.05   8.55  0.00  0.0   \n",
        "3  0.0  0.0  0.00  0.40   2.57  7.13   0.22  0.00   9.17   2.87  0.00  0.0   \n",
        "4  0.0  0.0  0.00  8.97  14.07  8.05  23.27  3.23   0.83   0.00  0.00  0.0   \n",
        "\n",
        "   C81  C82   C83   C84   C85   C86   C87   C88   C89   C90   C91  C92  C93  \\\n",
        "0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN  NaN   \n",
        "1  0.0  0.0  0.04  0.01  0.04  0.05  0.01  0.04  0.21  0.60  0.01  \u53f0\u5357\u5e02  \u65b0\u71df\u5340   \n",
        "2  0.0  0.0  0.00  0.06  0.35  0.00  0.01  0.00  0.24  0.34  0.00  \u53f0\u5357\u5e02  \u67f3\u71df\u5340   \n",
        "3  0.0  0.0  0.00  0.02  0.11  0.32  0.01  0.00  0.41  0.13  0.00  \u53f0\u5357\u5e02  \u65b0\u71df\u5340   \n",
        "4  0.0  0.0  0.00  0.15  0.24  0.14  0.40  0.06  0.01  0.00  0.00  \u5f70\u5316\u7e23  \u548c\u7f8e\u93ae   \n",
        "\n",
        "   C94  C95 C96  C97  C98  C99   C100   C101  C102    C103    C104    C105  \\\n",
        "0  NaN  NaN  No   No  NaN  NaN    NaN    NaN   NaN     NaN     NaN     NaN   \n",
        "1  \u53f0\u5357\u5e02  \u65b0\u71df\u5340  No   No  0.0  0.0  132.0    0.0   0.0   0.000   0.000   0.000   \n",
        "2   \\N   \\N  No   No  0.0  0.0  538.0  179.0   0.0  21.645   3.652   7.830   \n",
        "3  \u53f0\u5357\u5e02  \u67f3\u71df\u5340  No  Yes  1.0  0.0  244.0   92.0   0.0  45.672  33.880   5.709   \n",
        "4   \\N   \\N  No   No  1.0  0.0   93.0   72.0   0.0  45.726  46.141  28.992   \n",
        "\n",
        "       C106  C107  C108  C109  C110  C111  C112  C113  C114  C115  C116  C117  \\\n",
        "0       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "1  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   3.0   0.0   0.0   \n",
        "2  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   \n",
        "3  5.704305   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n",
        "4  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   8.0   1.0   0.0   \n",
        "\n",
        "   C118  C119  C120  C121  C122         C123         C124  C125         C126  \\\n",
        "0   NaN   NaN   NaN   NaN   NaN          NaN          NaN   NaN          NaN   \n",
        "1   0.0   6.0   4.0   1.0   0.0  108701933.0  151396249.0   0.0  640602330.0   \n",
        "2   0.0   0.0   0.0   1.0   0.0          0.0          0.0   0.0          0.0   \n",
        "3   0.0   0.0   0.0   0.0   0.0          0.0          0.0   0.0          0.0   \n",
        "4   0.0   6.0  13.0   0.0   0.0          0.0     562953.0   0.0          0.0   \n",
        "\n",
        "   C127         C128        C129         C130  C131        C132          C133  \\\n",
        "0   NaN          NaN         NaN          NaN   NaN         NaN           NaN   \n",
        "1   0.0  113758047.0  85067978.0  135352031.0   0.0  51434728.0  1.795074e+09   \n",
        "2   0.0          0.0         0.0          0.0   0.0         0.0  0.000000e+00   \n",
        "3   0.0          0.0         0.0          0.0   0.0         0.0  0.000000e+00   \n",
        "4   0.0    6514284.0  45907574.0     581620.0   0.0         0.0  0.000000e+00   \n",
        "\n",
        "       C134         C135  C136  C137          C138  C139         C140  \\\n",
        "0       NaN          NaN   NaN   NaN           NaN   NaN          NaN   \n",
        "1  439151.0  326260868.0   0.0   0.0  1.906637e+09   0.0  557196876.0   \n",
        "2       0.0          0.0   0.0   0.0  0.000000e+00   0.0          0.0   \n",
        "3       0.0          0.0   0.0   0.0  0.000000e+00   0.0          0.0   \n",
        "4       0.0          0.0   0.0   0.0  1.128205e+06   0.0  567134600.0   \n",
        "\n",
        "           C141         C142  C143  C144          C145         C146   C147  \\\n",
        "0           NaN          NaN   NaN   NaN           NaN          NaN    NaN   \n",
        "1  5.169043e+09  448633971.0   0.0   0.0  1.716211e+09  570153410.0  99.35   \n",
        "2  0.000000e+00          0.0   0.0   0.0  0.000000e+00          0.0  25.48   \n",
        "3  0.000000e+00          0.0   0.0   0.0  0.000000e+00          0.0  22.35   \n",
        "4  2.739706e+08   21208770.0   0.0   0.0  0.000000e+00          0.0  58.42   \n",
        "\n",
        "    C148   C149   C150   C151  C152  C153   C154  C155  C156  C157  C158  \\\n",
        "0    NaN    NaN    NaN    NaN   NaN   NaN    NaN   NaN   NaN   NaN   NaN   \n",
        "1  77.32   7.21  12.93  12.93   0.0   0.0  79.21  59.0  24.0  19.0  13.0   \n",
        "2   6.35  19.14   0.00   0.00   0.0   0.0  13.52  16.0   4.0  12.0   0.0   \n",
        "3   6.14  13.64   2.57   2.57   0.0   0.0   6.14  16.0   8.0   6.0   2.0   \n",
        "4  14.80  16.85  26.27  26.27   0.0   0.0  26.27  51.0  12.0  10.0  28.0   \n",
        "\n",
        "   C159  C160  C161  C162  C163  C164  C165  C166  C167  C168  C169  C170  \\\n",
        "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "1  13.0   0.0   0.0  13.0   3.0   0.0   2.0   6.0   0.0   0.0   1.0   0.0   \n",
        "2   0.0   0.0   0.0   9.0   3.0   0.0   6.0   0.0   0.0   1.0   5.0   0.0   \n",
        "3   2.0   0.0   0.0   9.0   4.0   0.0   3.0   2.0   0.0   2.0   1.0   0.0   \n",
        "4  28.0   0.0   0.0  27.0   6.0   0.0   8.0  13.0   0.0   5.0   1.0   1.0   \n",
        "\n",
        "   C171  C172  C173  C174  C175  C176  C177  C178  C179  C180  C181  C182  \\\n",
        "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  13.0   \n",
        "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   9.0   \n",
        "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  10.0   \n",
        "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  27.0   \n",
        "\n",
        "   C183  C184  C185  C186   C187   C188  C189   C190  C191  C192  C193  C194  \\\n",
        "0   NaN   NaN   NaN   NaN   0.00   0.00   0.0   0.00  0.00   0.0  0.00   NaN   \n",
        "1   3.0   2.0   6.0   0.0  90.26  77.32   0.0  12.94  0.86   0.0  0.14  59.0   \n",
        "2   3.0   6.0   0.0   0.0   6.36   6.36   0.0   0.00  1.00   0.0  0.00  16.0   \n",
        "3   5.0   3.0   2.0   0.0   8.70   6.14   0.0   2.56  0.71   0.0  0.29  14.0   \n",
        "4   6.0   7.0  13.0   0.0  41.07  14.80   0.0  26.27  0.36   0.0  0.64  51.0   \n",
        "\n",
        "   C195  C196  C197  C198  C199  C200  C201  C202  C203  C204  C205  C206  \\\n",
        "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   0.0   0.0   0.0   \n",
        "1  24.0   0.0  19.0  13.0   0.0   0.0  17.0   0.0   2.0  37.0  24.0   0.0   \n",
        "2   4.0   0.0  12.0   0.0   0.0   3.0   9.0   0.0   0.0   4.0   4.0   0.0   \n",
        "3   6.0   0.0   6.0   2.0   0.0   3.0   3.0   0.0   0.0  10.0   8.0   0.0   \n",
        "4  12.0   0.0  11.0  28.0   0.0   6.0   1.0   3.0   0.0  40.0  12.0   0.0   \n",
        "\n",
        "   C207 C208  C209  C210   C211           C212      C213   C214          C215  \\\n",
        "0   0.0  NaN   NaN   0.0    0.0            NaN       NaN    NaN           NaN   \n",
        "1  13.0   \u696d\u8005   9.0   2.0  232.0  903739.278320  0.174970  232.0  5.289064e+09   \n",
        "2   0.0  \u7af6\u696dB   3.0   0.0    0.0            NaN       NaN    0.0  0.000000e+00   \n",
        "3   2.0   \u696d\u8005   7.0   1.0    0.0            NaN       NaN    0.0  0.000000e+00   \n",
        "4  28.0   \u56fa\u7db2  24.0   0.0  259.0   57456.744141  0.063761  259.0  9.227513e+08   \n",
        "\n",
        "   pred_C3  C3  \n",
        "0        1   0  \n",
        "1        0   0  \n",
        "2        1   1  \n",
        "3        1   0  \n",
        "4        1   0  "
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Prediction (each cluster)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xp_cData = dfp.loc[:, choosed_for_clustering]\n",
      "\n",
      "for col in Xp_cData.columns:\n",
      "    Xp_cData[col].fillna(0, inplace=True)\n",
      "    Xp_cData[col] = StandardScaler().fit_transform(Xp_cData[col])\n",
      "\n",
      "dfp['clabel'] = kmeans.predict(Xp_cData)\n",
      "\n",
      "for i in xrange(3):\n",
      "    _X = dfp.loc[dfp['clabel']==i, choosed]\n",
      "    for col in _X.columns:\n",
      "      try:\n",
      "        _X[col].fillna(0, inplace=True)\n",
      "        _X[col] = StandardScaler().fit_transform(_X[col])\n",
      "      except:\n",
      "        _X[col] = _X[col].replace({name: n for n, name in enumerate(_X[col].unique())})\n",
      "    dfp.loc[dfp['clabel']==i, 'pred_C3'] = clfs[i].predict(_X)\n",
      "\n",
      "print accuracy_score(dfp['C3'], dfp['pred_C3'])\n",
      "\n",
      "dfp.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5899\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>C2</th>\n",
        "      <th>C4</th>\n",
        "      <th>C5</th>\n",
        "      <th>C6</th>\n",
        "      <th>C7</th>\n",
        "      <th>C8</th>\n",
        "      <th>C9</th>\n",
        "      <th>C10</th>\n",
        "      <th>C11</th>\n",
        "      <th>C12</th>\n",
        "      <th>C13</th>\n",
        "      <th>C14</th>\n",
        "      <th>C15</th>\n",
        "      <th>C16</th>\n",
        "      <th>C17</th>\n",
        "      <th>C18</th>\n",
        "      <th>C19</th>\n",
        "      <th>C20</th>\n",
        "      <th>C21</th>\n",
        "      <th>C22</th>\n",
        "      <th>C23</th>\n",
        "      <th>C24</th>\n",
        "      <th>C25</th>\n",
        "      <th>C26</th>\n",
        "      <th>C27</th>\n",
        "      <th>C28</th>\n",
        "      <th>C29</th>\n",
        "      <th>C30</th>\n",
        "      <th>C31</th>\n",
        "      <th>C32</th>\n",
        "      <th>C33</th>\n",
        "      <th>C34</th>\n",
        "      <th>C35</th>\n",
        "      <th>C36</th>\n",
        "      <th>C37</th>\n",
        "      <th>C38</th>\n",
        "      <th>C39</th>\n",
        "      <th>C40</th>\n",
        "      <th>C41</th>\n",
        "      <th>C42</th>\n",
        "      <th>C43</th>\n",
        "      <th>C44</th>\n",
        "      <th>C45</th>\n",
        "      <th>C46</th>\n",
        "      <th>C47</th>\n",
        "      <th>C48</th>\n",
        "      <th>C49</th>\n",
        "      <th>C50</th>\n",
        "      <th>C51</th>\n",
        "      <th>C52</th>\n",
        "      <th>C53</th>\n",
        "      <th>C54</th>\n",
        "      <th>C55</th>\n",
        "      <th>C56</th>\n",
        "      <th>C57</th>\n",
        "      <th>C58</th>\n",
        "      <th>C59</th>\n",
        "      <th>C60</th>\n",
        "      <th>C61</th>\n",
        "      <th>C62</th>\n",
        "      <th>C63</th>\n",
        "      <th>C64</th>\n",
        "      <th>C65</th>\n",
        "      <th>C66</th>\n",
        "      <th>C67</th>\n",
        "      <th>C68</th>\n",
        "      <th>C69</th>\n",
        "      <th>C70</th>\n",
        "      <th>C71</th>\n",
        "      <th>C72</th>\n",
        "      <th>C73</th>\n",
        "      <th>C74</th>\n",
        "      <th>C75</th>\n",
        "      <th>C76</th>\n",
        "      <th>C77</th>\n",
        "      <th>C78</th>\n",
        "      <th>C79</th>\n",
        "      <th>C80</th>\n",
        "      <th>C81</th>\n",
        "      <th>C82</th>\n",
        "      <th>C83</th>\n",
        "      <th>C84</th>\n",
        "      <th>C85</th>\n",
        "      <th>C86</th>\n",
        "      <th>C87</th>\n",
        "      <th>C88</th>\n",
        "      <th>C89</th>\n",
        "      <th>C90</th>\n",
        "      <th>C91</th>\n",
        "      <th>C92</th>\n",
        "      <th>C93</th>\n",
        "      <th>C94</th>\n",
        "      <th>C95</th>\n",
        "      <th>C96</th>\n",
        "      <th>C97</th>\n",
        "      <th>C98</th>\n",
        "      <th>C99</th>\n",
        "      <th>C100</th>\n",
        "      <th>C101</th>\n",
        "      <th>C102</th>\n",
        "      <th>C103</th>\n",
        "      <th>C104</th>\n",
        "      <th>C105</th>\n",
        "      <th>C106</th>\n",
        "      <th>C107</th>\n",
        "      <th>C108</th>\n",
        "      <th>C109</th>\n",
        "      <th>C110</th>\n",
        "      <th>C111</th>\n",
        "      <th>C112</th>\n",
        "      <th>C113</th>\n",
        "      <th>C114</th>\n",
        "      <th>C115</th>\n",
        "      <th>C116</th>\n",
        "      <th>C117</th>\n",
        "      <th>C118</th>\n",
        "      <th>C119</th>\n",
        "      <th>C120</th>\n",
        "      <th>C121</th>\n",
        "      <th>C122</th>\n",
        "      <th>C123</th>\n",
        "      <th>C124</th>\n",
        "      <th>C125</th>\n",
        "      <th>C126</th>\n",
        "      <th>C127</th>\n",
        "      <th>C128</th>\n",
        "      <th>C129</th>\n",
        "      <th>C130</th>\n",
        "      <th>C131</th>\n",
        "      <th>C132</th>\n",
        "      <th>C133</th>\n",
        "      <th>C134</th>\n",
        "      <th>C135</th>\n",
        "      <th>C136</th>\n",
        "      <th>C137</th>\n",
        "      <th>C138</th>\n",
        "      <th>C139</th>\n",
        "      <th>C140</th>\n",
        "      <th>C141</th>\n",
        "      <th>C142</th>\n",
        "      <th>C143</th>\n",
        "      <th>C144</th>\n",
        "      <th>C145</th>\n",
        "      <th>C146</th>\n",
        "      <th>C147</th>\n",
        "      <th>C148</th>\n",
        "      <th>C149</th>\n",
        "      <th>C150</th>\n",
        "      <th>C151</th>\n",
        "      <th>C152</th>\n",
        "      <th>C153</th>\n",
        "      <th>C154</th>\n",
        "      <th>C155</th>\n",
        "      <th>C156</th>\n",
        "      <th>C157</th>\n",
        "      <th>C158</th>\n",
        "      <th>C159</th>\n",
        "      <th>C160</th>\n",
        "      <th>C161</th>\n",
        "      <th>C162</th>\n",
        "      <th>C163</th>\n",
        "      <th>C164</th>\n",
        "      <th>C165</th>\n",
        "      <th>C166</th>\n",
        "      <th>C167</th>\n",
        "      <th>C168</th>\n",
        "      <th>C169</th>\n",
        "      <th>C170</th>\n",
        "      <th>C171</th>\n",
        "      <th>C172</th>\n",
        "      <th>C173</th>\n",
        "      <th>C174</th>\n",
        "      <th>C175</th>\n",
        "      <th>C176</th>\n",
        "      <th>C177</th>\n",
        "      <th>C178</th>\n",
        "      <th>C179</th>\n",
        "      <th>C180</th>\n",
        "      <th>C181</th>\n",
        "      <th>C182</th>\n",
        "      <th>C183</th>\n",
        "      <th>C184</th>\n",
        "      <th>C185</th>\n",
        "      <th>C186</th>\n",
        "      <th>C187</th>\n",
        "      <th>C188</th>\n",
        "      <th>C189</th>\n",
        "      <th>C190</th>\n",
        "      <th>C191</th>\n",
        "      <th>C192</th>\n",
        "      <th>C193</th>\n",
        "      <th>C194</th>\n",
        "      <th>C195</th>\n",
        "      <th>C196</th>\n",
        "      <th>C197</th>\n",
        "      <th>C198</th>\n",
        "      <th>C199</th>\n",
        "      <th>C200</th>\n",
        "      <th>C201</th>\n",
        "      <th>C202</th>\n",
        "      <th>C203</th>\n",
        "      <th>C204</th>\n",
        "      <th>C205</th>\n",
        "      <th>C206</th>\n",
        "      <th>C207</th>\n",
        "      <th>C208</th>\n",
        "      <th>C209</th>\n",
        "      <th>C210</th>\n",
        "      <th>C211</th>\n",
        "      <th>C212</th>\n",
        "      <th>C213</th>\n",
        "      <th>C214</th>\n",
        "      <th>C215</th>\n",
        "      <th>pred_C3</th>\n",
        "      <th>C3</th>\n",
        "      <th>clabel</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>9995</th>\n",
        "      <td>C0294226</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>47.0</td>\n",
        "      <td>\u5929\u79e4\u5ea7</td>\n",
        "      <td>88</td>\n",
        "      <td>\u64da\u9ede05</td>\n",
        "      <td>Y</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>4G</td>\n",
        "      <td>1336.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>4</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>2.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>86.0</td>\n",
        "      <td>86.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>1.567282e+06</td>\n",
        "      <td>108.99</td>\n",
        "      <td>33.08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>62.34</td>\n",
        "      <td>13.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>25.57</td>\n",
        "      <td>34.97</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.8</td>\n",
        "      <td>0.30</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.57</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.23</td>\n",
        "      <td>0.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.25</td>\n",
        "      <td>2.77</td>\n",
        "      <td>7.70</td>\n",
        "      <td>33.17</td>\n",
        "      <td>7.47</td>\n",
        "      <td>12.62</td>\n",
        "      <td>10.92</td>\n",
        "      <td>31.07</td>\n",
        "      <td>1.77</td>\n",
        "      <td>1.27</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.30</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.10</td>\n",
        "      <td>0.29</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.01</td>\n",
        "      <td>\u5c4f\u6771\u7e23</td>\n",
        "      <td>\u5c4f\u6771\u5e02</td>\n",
        "      <td>\u5c4f\u6771\u7e23</td>\n",
        "      <td>\u5c4f\u6771\u5e02</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>228.0</td>\n",
        "      <td>15.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>307.476</td>\n",
        "      <td>41.996</td>\n",
        "      <td>253.324</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>16.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>26.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14259319.0</td>\n",
        "      <td>439665398.0</td>\n",
        "      <td>2.949158e+08</td>\n",
        "      <td>7.857726e+07</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>42562618.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11569936.0</td>\n",
        "      <td>305027092.0</td>\n",
        "      <td>7.929694e+08</td>\n",
        "      <td>7.430331e+08</td>\n",
        "      <td>4.815118e+08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9922937.0</td>\n",
        "      <td>76581435.0</td>\n",
        "      <td>9431279.0</td>\n",
        "      <td>108.98</td>\n",
        "      <td>33.09</td>\n",
        "      <td>62.34</td>\n",
        "      <td>13.32</td>\n",
        "      <td>13.32</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>33.34</td>\n",
        "      <td>103.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>37.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>29.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>29.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>46.41</td>\n",
        "      <td>33.08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>13.33</td>\n",
        "      <td>0.71</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.29</td>\n",
        "      <td>103.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>37.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>28.0</td>\n",
        "      <td>7.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>65.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>26.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>195.0</td>\n",
        "      <td>1.928009e+05</td>\n",
        "      <td>0.123016</td>\n",
        "      <td>195.0</td>\n",
        "      <td>1.604897e+09</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9996</th>\n",
        "      <td>C0263886</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>F</td>\n",
        "      <td>59.0</td>\n",
        "      <td>\u7261\u7f8a\u5ea7</td>\n",
        "      <td>188</td>\n",
        "      <td>\u64da\u9ede07</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-2.0</td>\n",
        "      <td>3</td>\n",
        "      <td>2</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>\u7af6\u696dB</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>Yes</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>5.67</td>\n",
        "      <td>10.38</td>\n",
        "      <td>0.40</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.34</td>\n",
        "      <td>0.63</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>16.45</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.45</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.45</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.00</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>\u56fa\u7db2</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9997</th>\n",
        "      <td>C0167683</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>32.0</td>\n",
        "      <td>\u5929\u880d\u5ea7</td>\n",
        "      <td>129</td>\n",
        "      <td>\u64da\u9ede06</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>4G</td>\n",
        "      <td>1336.0</td>\n",
        "      <td>\u901a\u4fe1\u7d04</td>\n",
        "      <td>-31.0</td>\n",
        "      <td>3</td>\n",
        "      <td>3</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>1.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u7af6\u696dC</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>Yes</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>2.453259e+07</td>\n",
        "      <td>144.78</td>\n",
        "      <td>115.93</td>\n",
        "      <td>0.0</td>\n",
        "      <td>18.77</td>\n",
        "      <td>10.08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>18.77</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.80</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>5.3</td>\n",
        "      <td>0.72</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.28</td>\n",
        "      <td>11.20</td>\n",
        "      <td>8.67</td>\n",
        "      <td>16.10</td>\n",
        "      <td>5.20</td>\n",
        "      <td>55.65</td>\n",
        "      <td>30.87</td>\n",
        "      <td>10.17</td>\n",
        "      <td>0.63</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.08</td>\n",
        "      <td>0.06</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.38</td>\n",
        "      <td>0.21</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.00</td>\n",
        "      <td>\u65b0\u5317\u5e02</td>\n",
        "      <td>\u571f\u57ce\u5340</td>\n",
        "      <td>\u65b0\u5317\u5e02</td>\n",
        "      <td>\u571f\u57ce\u5340</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>51.077</td>\n",
        "      <td>115.313</td>\n",
        "      <td>13.258</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>612945661.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>177152309.0</td>\n",
        "      <td>60247083.0</td>\n",
        "      <td>532005101.0</td>\n",
        "      <td>1.634267e+09</td>\n",
        "      <td>1.884671e+09</td>\n",
        "      <td>0.0</td>\n",
        "      <td>152925231.0</td>\n",
        "      <td>21941803.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.000222e+09</td>\n",
        "      <td>52418707.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>231547895.0</td>\n",
        "      <td>3.251698e+09</td>\n",
        "      <td>1.069934e+10</td>\n",
        "      <td>5.767356e+09</td>\n",
        "      <td>0.0</td>\n",
        "      <td>91557009.0</td>\n",
        "      <td>679913317.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>144.78</td>\n",
        "      <td>115.93</td>\n",
        "      <td>18.77</td>\n",
        "      <td>10.08</td>\n",
        "      <td>10.08</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>115.93</td>\n",
        "      <td>73.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>18.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>126.00</td>\n",
        "      <td>115.92</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.08</td>\n",
        "      <td>0.92</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.08</td>\n",
        "      <td>73.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>11.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>62.0</td>\n",
        "      <td>57.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>26.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>227.0</td>\n",
        "      <td>1.653876e+06</td>\n",
        "      <td>0.067415</td>\n",
        "      <td>227.0</td>\n",
        "      <td>2.512137e+10</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9998</th>\n",
        "      <td>C0132373</td>\n",
        "      <td>VIP4</td>\n",
        "      <td>M</td>\n",
        "      <td>62.0</td>\n",
        "      <td>\u5929\u79e4\u5ea7</td>\n",
        "      <td>248</td>\n",
        "      <td>\u64da\u9ede13</td>\n",
        "      <td>N</td>\n",
        "      <td>\u4e2d</td>\n",
        "      <td>3G</td>\n",
        "      <td>983.0</td>\n",
        "      <td>\u8cfc\u6a5f\u7d04</td>\n",
        "      <td>-50.0</td>\n",
        "      <td>5</td>\n",
        "      <td>5</td>\n",
        "      <td>\u4f4e\u4e2d</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>3.0</td>\n",
        "      <td>\u7121</td>\n",
        "      <td>N</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>257.13</td>\n",
        "      <td>46.80</td>\n",
        "      <td>0.0</td>\n",
        "      <td>149.55</td>\n",
        "      <td>60.58</td>\n",
        "      <td>0.0</td>\n",
        "      <td>115.73</td>\n",
        "      <td>33.82</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.18</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.58</td>\n",
        "      <td>0.24</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.45</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.70</td>\n",
        "      <td>4.35</td>\n",
        "      <td>47.37</td>\n",
        "      <td>122.25</td>\n",
        "      <td>24.65</td>\n",
        "      <td>30.93</td>\n",
        "      <td>4.32</td>\n",
        "      <td>10.50</td>\n",
        "      <td>6.12</td>\n",
        "      <td>5.95</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.18</td>\n",
        "      <td>0.48</td>\n",
        "      <td>0.10</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.04</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.02</td>\n",
        "      <td>\u82d7\u6817\u7e23</td>\n",
        "      <td>\u901a\u9704\u93ae</td>\n",
        "      <td>\\N</td>\n",
        "      <td>\\N</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>12.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>163.0</td>\n",
        "      <td>75.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>480.431</td>\n",
        "      <td>131.628</td>\n",
        "      <td>129.690</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>16.0</td>\n",
        "      <td>15.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>12.0</td>\n",
        "      <td>14.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>10.0</td>\n",
        "      <td>17.0</td>\n",
        "      <td>24.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>257.13</td>\n",
        "      <td>46.80</td>\n",
        "      <td>149.55</td>\n",
        "      <td>60.58</td>\n",
        "      <td>60.58</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>115.73</td>\n",
        "      <td>136.0</td>\n",
        "      <td>32.0</td>\n",
        "      <td>68.0</td>\n",
        "      <td>35.0</td>\n",
        "      <td>35.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>23.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>23.0</td>\n",
        "      <td>8.0</td>\n",
        "      <td>9.0</td>\n",
        "      <td>5.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>107.38</td>\n",
        "      <td>46.79</td>\n",
        "      <td>0.0</td>\n",
        "      <td>60.59</td>\n",
        "      <td>0.44</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.56</td>\n",
        "      <td>136.0</td>\n",
        "      <td>32.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>68.0</td>\n",
        "      <td>35.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>37.0</td>\n",
        "      <td>31.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>67.0</td>\n",
        "      <td>32.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>35.0</td>\n",
        "      <td>\u7af6\u696dA</td>\n",
        "      <td>54.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9999</th>\n",
        "      <td>C0010487</td>\n",
        "      <td>NVIP</td>\n",
        "      <td>M</td>\n",
        "      <td>45.0</td>\n",
        "      <td>\u5929\u880d\u5ea7</td>\n",
        "      <td>74</td>\n",
        "      <td>\u64da\u9ede02</td>\n",
        "      <td>N</td>\n",
        "      <td>\u6975\u4f4e</td>\n",
        "      <td>3G</td>\n",
        "      <td>183.0</td>\n",
        "      <td>\u7121\u7d81\u7d04</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>\u96f6\u5143</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7af6\u696dD</td>\n",
        "      <td>N</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>1</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>\u7121NP</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>6.86</td>\n",
        "      <td>4.43</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>2.43</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.65</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.35</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>1.27</td>\n",
        "      <td>1.50</td>\n",
        "      <td>0.13</td>\n",
        "      <td>0.00</td>\n",
        "      <td>2.97</td>\n",
        "      <td>0.23</td>\n",
        "      <td>0.77</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.18</td>\n",
        "      <td>0.22</td>\n",
        "      <td>0.02</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.43</td>\n",
        "      <td>0.03</td>\n",
        "      <td>0.11</td>\n",
        "      <td>0.00</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>No</td>\n",
        "      <td>No</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>6.87</td>\n",
        "      <td>4.43</td>\n",
        "      <td>0.00</td>\n",
        "      <td>2.43</td>\n",
        "      <td>2.43</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.43</td>\n",
        "      <td>15.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>4.0</td>\n",
        "      <td>3.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>1.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6.86</td>\n",
        "      <td>4.43</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.43</td>\n",
        "      <td>0.65</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.35</td>\n",
        "      <td>15.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>15.0</td>\n",
        "      <td>13.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>2.0</td>\n",
        "      <td>\u696d\u8005</td>\n",
        "      <td>6.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0.000000e+00</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "            C2    C4 C5    C6   C7   C8    C9 C10 C11 C12     C13  C14   C15  \\\n",
        "9995  C0294226  NVIP  F  47.0  \u5929\u79e4\u5ea7   88  \u64da\u9ede05   Y   \u4e2d  4G  1336.0  \u901a\u4fe1\u7d04   NaN   \n",
        "9996  C0263886  NVIP  F  59.0  \u7261\u7f8a\u5ea7  188  \u64da\u9ede07   N  \u6975\u4f4e  3G   183.0  \u8cfc\u6a5f\u7d04  -2.0   \n",
        "9997  C0167683  NVIP  M  32.0  \u5929\u880d\u5ea7  129  \u64da\u9ede06   N   \u4e2d  4G  1336.0  \u901a\u4fe1\u7d04 -31.0   \n",
        "9998  C0132373  VIP4  M  62.0  \u5929\u79e4\u5ea7  248  \u64da\u9ede13   N   \u4e2d  3G   983.0  \u8cfc\u6a5f\u7d04 -50.0   \n",
        "9999  C0010487  NVIP  M  45.0  \u5929\u880d\u5ea7   74  \u64da\u9ede02   N  \u6975\u4f4e  3G   183.0  \u7121\u7d81\u7d04   NaN   \n",
        "\n",
        "      C16  C17 C18 C19  C20  C21  C22 C23  C24  C25  C26  C27  C28  C29  C30  \\\n",
        "9995    4    4   \u4e2d  \u4f4e\u4e2d  2.0  4.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "9996    3    2  \u4f4e\u4e2d  \u4f4e\u4e2d  NaN  1.0  \u7af6\u696dB   N    1  NaN  1.0  NaN    1  NaN  NaN   \n",
        "9997    3    3   \u4e2d   \u4e2d  1.0  2.0  \u7af6\u696dC   N    1  NaN  NaN  NaN    1  NaN  NaN   \n",
        "9998    5    5  \u4f4e\u4e2d  \u96f6\u5143  NaN  3.0    \u7121   N    0  0.0  0.0  0.0    0  0.0  0.0   \n",
        "9999    0    0  \u96f6\u5143  \u96f6\u5143  NaN  NaN  \u7af6\u696dD   N    1  NaN  NaN  NaN    1  NaN  NaN   \n",
        "\n",
        "      C31   C32   C33  C34  C35  C36  C37  C38  C39  C40  C41  C42  C43  C44  \\\n",
        "9995  \u7af6\u696dB  86.0  86.0  1.0    3    3    0    0    0    0    0    0    3  NaN   \n",
        "9996  \u7121NP   NaN   NaN  NaN    2    1    0    1    0    0    0    0    2  NaN   \n",
        "9997  \u7121NP   NaN   NaN  NaN    1    1    0    0    0    0    0    0    1  Yes   \n",
        "9998  \u7121NP   NaN   NaN  NaN    4    1    1    1    0    0    1    0    3  NaN   \n",
        "9999  \u7121NP   NaN   NaN  NaN    4    4    0    0    0    0    0    0    3  NaN   \n",
        "\n",
        "      C45 C46           C47     C48     C49  C50     C51    C52  C53     C54  \\\n",
        "9995  NaN  No  1.567282e+06  108.99   33.08  0.0   62.34  13.32  0.0   25.57   \n",
        "9996  Yes  No           NaN   16.45    0.00  0.0    0.00  16.45  0.0    0.00   \n",
        "9997  NaN  No  2.453259e+07  144.78  115.93  0.0   18.77  10.08  0.0    0.00   \n",
        "9998  NaN  No           NaN  257.13   46.80  0.0  149.55  60.58  0.0  115.73   \n",
        "9999  NaN  No           NaN    6.86    4.43  0.0    0.00   2.43  0.0    0.00   \n",
        "\n",
        "        C55  C56  C57   C58  C59   C60   C61  C62  C63   C64   C65  C66   C67  \\\n",
        "9995  34.97  0.0  1.8  0.30  0.0  0.57  0.12  0.0  0.0  0.23  0.32  0.0  0.02   \n",
        "9996   0.00  0.0  0.0  0.00  0.0  0.00  1.00  0.0  0.0  0.00  0.00  0.0  0.00   \n",
        "9997  18.77  0.0  0.0  0.80  0.0  0.13  0.07  0.0  0.0  0.00  0.13  0.0  0.00   \n",
        "9998  33.82  0.0  0.0  0.18  0.0  0.58  0.24  0.0  0.0  0.45  0.13  0.0  0.00   \n",
        "9999   0.00  0.0  0.0  0.65  0.0  0.00  0.35  0.0  0.0  0.00  0.00  0.0  0.00   \n",
        "\n",
        "      C68   C69   C70   C71    C72     C73    C74    C75    C76    C77    C78  \\\n",
        "9995  0.0  0.00  0.25  2.77   7.70   33.17   7.47  12.62  10.92  31.07   1.77   \n",
        "9996  0.0  0.00  0.00  0.00   0.00    5.67  10.38   0.40   0.00   0.00   0.00   \n",
        "9997  5.3  0.72  0.00  0.28  11.20    8.67  16.10   5.20  55.65  30.87  10.17   \n",
        "9998  0.0  0.00  0.70  4.35  47.37  122.25  24.65  30.93   4.32  10.50   6.12   \n",
        "9999  0.0  0.00  0.00  0.00   1.27    1.50   0.13   0.00   2.97   0.23   0.77   \n",
        "\n",
        "       C79   C80  C81  C82   C83   C84   C85   C86   C87   C88   C89   C90  \\\n",
        "9995  1.27  0.00  0.0  0.0  0.03  0.07  0.30  0.07  0.12  0.10  0.29  0.02   \n",
        "9996  0.00  0.00  0.0  0.0  0.00  0.00  0.34  0.63  0.02  0.00  0.00  0.00   \n",
        "9997  0.63  0.04  0.0  0.0  0.00  0.08  0.06  0.11  0.04  0.38  0.21  0.07   \n",
        "9998  5.95  0.00  0.0  0.0  0.02  0.18  0.48  0.10  0.12  0.02  0.04  0.02   \n",
        "9999  0.00  0.00  0.0  0.0  0.00  0.18  0.22  0.02  0.00  0.43  0.03  0.11   \n",
        "\n",
        "       C91  C92  C93  C94  C95  C96  C97   C98  C99   C100  C101  C102  \\\n",
        "9995  0.01  \u5c4f\u6771\u7e23  \u5c4f\u6771\u5e02  \u5c4f\u6771\u7e23  \u5c4f\u6771\u5e02   No   No   0.0  1.0  228.0  15.0   0.0   \n",
        "9996  0.00  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN    NaN   NaN   NaN   \n",
        "9997  0.00  \u65b0\u5317\u5e02  \u571f\u57ce\u5340  \u65b0\u5317\u5e02  \u571f\u57ce\u5340   No   No   0.0  0.0    0.0   0.0   0.0   \n",
        "9998  0.02  \u82d7\u6817\u7e23  \u901a\u9704\u93ae   \\N   \\N   No   No  12.0  4.0  163.0  75.0   0.0   \n",
        "9999  0.00  NaN  NaN  NaN  NaN   No   No   NaN  NaN    NaN   NaN   NaN   \n",
        "\n",
        "         C103     C104     C105  C106  C107  C108  C109  C110  C111  C112  \\\n",
        "9995  307.476   41.996  253.324   0.0   0.0   0.0   0.0   0.0  10.0   0.0   \n",
        "9996      NaN      NaN      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "9997   51.077  115.313   13.258   0.0   2.0   0.0   0.0   0.0   6.0   3.0   \n",
        "9998  480.431  131.628  129.690   0.0   3.0   0.0   0.0   0.0  16.0  15.0   \n",
        "9999      NaN      NaN      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "\n",
        "      C113  C114  C115  C116  C117  C118  C119  C120  C121  C122  C123  \\\n",
        "9995   4.0   0.0  12.0  12.0   1.0  16.0   4.0  26.0   1.0   1.0   0.0   \n",
        "9996   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "9997  13.0   1.0   9.0   2.0   0.0  14.0   5.0  17.0   1.0   0.0   0.0   \n",
        "9998   9.0   2.0  12.0  14.0   0.0  10.0  17.0  24.0   5.0   0.0   0.0   \n",
        "9999   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
        "\n",
        "             C124  C125         C126        C127         C128          C129  \\\n",
        "9995          0.0   0.0          0.0  14259319.0  439665398.0  2.949158e+08   \n",
        "9996          NaN   NaN          NaN         NaN          NaN           NaN   \n",
        "9997  612945661.0   0.0  177152309.0  60247083.0  532005101.0  1.634267e+09   \n",
        "9998          0.0   0.0          0.0         0.0          0.0  0.000000e+00   \n",
        "9999          NaN   NaN          NaN         NaN          NaN           NaN   \n",
        "\n",
        "              C130  C131         C132        C133  C134          C135  \\\n",
        "9995  7.857726e+07   0.0          0.0         0.0   0.0  0.000000e+00   \n",
        "9996           NaN   NaN          NaN         NaN   NaN           NaN   \n",
        "9997  1.884671e+09   0.0  152925231.0  21941803.0   0.0  3.000222e+09   \n",
        "9998  0.000000e+00   0.0          0.0         0.0   0.0  0.000000e+00   \n",
        "9999           NaN   NaN          NaN         NaN   NaN           NaN   \n",
        "\n",
        "            C136  C137        C138         C139          C140          C141  \\\n",
        "9995  42562618.0   0.0  11569936.0  305027092.0  7.929694e+08  7.430331e+08   \n",
        "9996         NaN   NaN         NaN          NaN           NaN           NaN   \n",
        "9997  52418707.0   0.0         0.0  231547895.0  3.251698e+09  1.069934e+10   \n",
        "9998         0.0   0.0         0.0          0.0  0.000000e+00  0.000000e+00   \n",
        "9999         NaN   NaN         NaN          NaN           NaN           NaN   \n",
        "\n",
        "              C142  C143        C144         C145       C146    C147    C148  \\\n",
        "9995  4.815118e+08   0.0   9922937.0   76581435.0  9431279.0  108.98   33.09   \n",
        "9996           NaN   NaN         NaN          NaN        NaN   16.45    0.00   \n",
        "9997  5.767356e+09   0.0  91557009.0  679913317.0        0.0  144.78  115.93   \n",
        "9998  0.000000e+00   0.0         0.0          0.0        0.0  257.13   46.80   \n",
        "9999           NaN   NaN         NaN          NaN        NaN    6.87    4.43   \n",
        "\n",
        "        C149   C150   C151  C152  C153    C154   C155  C156  C157  C158  C159  \\\n",
        "9995   62.34  13.32  13.32   0.0   0.0   33.34  103.0  57.0  37.0   8.0   8.0   \n",
        "9996    0.00  16.45  16.45   0.0   0.0   16.45   17.0   0.0   0.0  17.0  17.0   \n",
        "9997   18.77  10.08  10.08   0.0   0.0  115.93   73.0  57.0  11.0   5.0   5.0   \n",
        "9998  149.55  60.58  60.58   0.0   0.0  115.73  136.0  32.0  68.0  35.0  35.0   \n",
        "9999    0.00   2.43   2.43   0.0   0.0    4.43   15.0  13.0   0.0   2.0   2.0   \n",
        "\n",
        "      C160  C161  C162  C163  C164  C165  C166  C167  C168  C169  C170  C171  \\\n",
        "9995   0.0   0.0  29.0  10.0   0.0  13.0   5.0   0.0   9.0   3.0   0.0   1.0   \n",
        "9996   0.0   0.0   2.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0   \n",
        "9997   0.0   0.0  18.0  10.0   0.0   5.0   3.0   0.0   0.0   5.0   0.0   0.0   \n",
        "9998   0.0   0.0  23.0   8.0   0.0   9.0   5.0   0.0   3.0   6.0   0.0   0.0   \n",
        "9999   0.0   0.0   4.0   3.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n",
        "\n",
        "      C172  C173  C174  C175  C176  C177  C178  C179  C180  C181  C182  C183  \\\n",
        "9995   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  29.0  10.0   \n",
        "9996   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   \n",
        "9997   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  18.0  10.0   \n",
        "9998   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  23.0   8.0   \n",
        "9999   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0   3.0   \n",
        "\n",
        "      C184  C185  C186    C187    C188  C189   C190  C191  C192  C193   C194  \\\n",
        "9995  13.0   5.0   0.0   46.41   33.08   0.0  13.33  0.71   0.0  0.29  103.0   \n",
        "9996   0.0   2.0   0.0   16.45    0.00   0.0  16.45  0.00   0.0  1.00   17.0   \n",
        "9997   5.0   3.0   0.0  126.00  115.92   0.0  10.08  0.92   0.0  0.08   73.0   \n",
        "9998   9.0   5.0   0.0  107.38   46.79   0.0  60.59  0.44   0.0  0.56  136.0   \n",
        "9999   0.0   1.0   0.0    6.86    4.43   0.0   2.43  0.65   0.0  0.35   15.0   \n",
        "\n",
        "      C195  C196  C197  C198  C199  C200  C201  C202  C203  C204  C205  C206  \\\n",
        "9995  57.0   0.0  37.0   8.0   0.0  28.0   7.0   0.0   2.0  65.0  57.0   0.0   \n",
        "9996   0.0   0.0   0.0  17.0   0.0   0.0   0.0   0.0   0.0  17.0   0.0   0.0   \n",
        "9997  57.0   0.0  11.0   5.0   0.0   0.0  11.0   0.0   0.0  62.0  57.0   0.0   \n",
        "9998  32.0   0.0  68.0  35.0   0.0  37.0  31.0   0.0   0.0  67.0  32.0   0.0   \n",
        "9999  13.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0  15.0  13.0   0.0   \n",
        "\n",
        "      C207 C208  C209  C210   C211          C212      C213   C214  \\\n",
        "9995   8.0   \u696d\u8005  26.0   0.0  195.0  1.928009e+05  0.123016  195.0   \n",
        "9996  17.0   \u56fa\u7db2   3.0   0.0    0.0           NaN       NaN    0.0   \n",
        "9997   5.0   \u696d\u8005  26.0   0.0  227.0  1.653876e+06  0.067415  227.0   \n",
        "9998  35.0  \u7af6\u696dA  54.0   0.0    0.0           NaN       NaN    0.0   \n",
        "9999   2.0   \u696d\u8005   6.0   0.0    0.0           NaN       NaN    0.0   \n",
        "\n",
        "              C215  pred_C3  C3  clabel  \n",
        "9995  1.604897e+09        0   0       2  \n",
        "9996  0.000000e+00        1   1       0  \n",
        "9997  2.512137e+10        1   1       1  \n",
        "9998  0.000000e+00        0   0       0  \n",
        "9999  0.000000e+00        1   1       1  "
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Ploting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "fpr1, tpr1, _ = roc_curve(y_test, clf1.predict_proba(X_test)[:, 1])\n",
      "fpr2, tpr2, _ = roc_curve(y_test, clf2.predict_proba(X_test)[:, 1])\n",
      "fpr3, tpr3, _ = roc_curve(y_test, clf3.predict_proba(X_test)[:, 1])\n",
      "fpr4, tpr4, _ = roc_curve(y_test, clf4.predict_proba(X_test)[:, 1])\n",
      "fprv, tprv, _ = roc_curve(y_test, vclf.predict_proba(X_test)[:, 1])\n",
      "\n",
      "plt.plot(fpr1, tpr1, label='Naive Bayes')\n",
      "plt.plot(fpr2, tpr2, label='Logistic Regression')\n",
      "plt.plot(fpr3, tpr3, label='Random Forest')\n",
      "plt.plot(fpr4, tpr4, label='SVM')\n",
      "plt.plot(fprv, tprv, label='Voting Classifier')\n",
      "\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('ROC curve')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhmEYGSwxMAzDMDJYYmAYhmFk/D8Z52PfAOoOwgAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x62e4f90>"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "C001 \u6708\u4efd C002 \u8a2d\u5099\u6d41\u6c34\u865f C003 \u662f\u5426NPOUT C004 VIP\u7b49\u7d1a C005 \u6027\u5225[\u7528\u6236] C006 \u5e74\u9f61[\u7528\u6236] C007 \u661f\u5ea7[\u7528\u6236] C008 [\u884c\u52d5]\u5e74\u8cc7 C009 \u64da\u9ede C010 \u662f\u5426\u70ba\u7279\u7d04\n",
      "\n",
      "C011 [\u7528\u6236]\u5e33\u55ae\u7e3d\u91d1\u984d(\u4f4e/\u4f4e\u4e2d/\u4e2d/\u4e2d\u9ad8/\u9ad8) C012 [\u884c\u52d5]\u9580\u865f\u8cc7\u8cbb\u985e\u578b C013 [\u884c\u52d5]\u9580\u865f\u8cc7\u8cbb\u8cbb\u7387 C014 \u6700\u5f8c\u7d81\u7d04\u985e\u578b C015 \u7d81\u7d04\u5230\u671f\u6708\u6578 C016 \u624b\u6a5f\u7d81\u7d04\u6b21\u6578(\u81ea\u958b\u53f0) C017 \u624b\u6a5f\u8cfc\u8cb7\u6b21\u6578(\u81ea\u958b\u53f0) C018 \u624b\u6a5f\u5e73\u5747\u8cfc\u8cb7\u91d1\u984d\u7d1a\u8ddd(\u81ea2008\u5e74) C019 \u624b\u6a5f\u6700\u8fd1\u8cfc\u8cb7\u91d1\u984d\u7d1a\u8ddd(\u81ea2008\u5e74) C020 \u901a\u4fe1\u7d81\u7d04\u6b21\u6578\n",
      "\n",
      "C021 \u8cfc\u6a5f\u7d81\u7d04\u6b21\u6578 C022 NP\u696d\u8005[\u7528\u6236] C023 \u5047NP\u72c0\u614b[\u7528\u6236] C024 NP\u6b21\u6578[\u7528\u6236] C025 NPIN\u4e2d\u83ef\u6b21\u6578[\u7528\u6236] C026 NPIN\u7af6\u696dA\u6b21\u6578[\u7528\u6236] C027 NPIN\u7af6\u696dB\u6b21\u6578[\u7528\u6236] C028 NPOUT\u4e2d\u83ef\u6b21\u6578[\u7528\u6236] C029 NPOUT\u7af6\u696dA\u6b21\u6578[\u7528\u6236] C030 NPOUT\u7af6\u696dB\u6b21\u6578[\u7528\u6236]\n",
      "\n",
      "C031 [\u884c\u52d5]\u5148\u524d\u662f\u5426\u70baNPIN C032 [\u884c\u52d5]\u6700\u8fd1\u7684NP\u6642\u9593 C033 [\u884c\u52d5]\u6700\u4e45\u7684NP\u6642\u9593 C034 [\u884c\u52d5]NP\u6b21\u6578 C035 [\u5ba2\u6236]\u7528\u6236\u8a2d\u5099\u7e3d\u6578 C036 [\u5ba2\u6236]\u884c\u52d5\u7528\u6236\u8a2d\u5099\u6578 C037 [\u5ba2\u6236]MOD\u7528\u6236\u8a2d\u5099\u6578 C038 [\u5ba2\u6236]\u5e02\u8a71\u7528\u6236\u8a2d\u5099\u6578 C039 [\u5ba2\u6236]\u56fa\u7db2\u975e\u5e02\u8a71\u7528\u6236\u8a2d\u5099\u6578 C040 [\u5ba2\u6236]\u5149\u4e16\u4ee3\u696d\u52d9\u7528\u6236\u8a2d\u5099\u6578\n",
      "\n",
      "C041 [\u5ba2\u6236]HiNet\u7528\u6236\u8a2d\u5099\u6578 C042 [\u5ba2\u6236]\u5176\u4ed6\u7528\u6236\u8a2d\u5099\u6578 C043 [\u5ba2\u6236]\u540c\u4e00\u5ba2\u6236\u6b78\u5c6c\u4e4b\u5bb6\u6236\u6578 C044 [\u7528\u6236]\u96fb\u5b50\u5e33\u55ae\u8b58\u5225 C045 [\u7528\u6236]\u4e0d\u5bc4\u9001\u5ee3\u544a\u8b58\u5225\u6b04 C046 [\u884c\u52d5]\u4e0d\u63a5\u53d7\u96fb\u8a71\u4fc3\u92b7\u8b58\u5225 C047 [\u884c\u52d5]\u6578\u64da\u7e3dMB\u91cf C048 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7e3d\u5206\u9418\u6578 C049 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u5206\u9418\u6578 C050 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u5206\u9418\u6578\n",
      "\n",
      "C051 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u5206\u9418\u6578 C052 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u5206\u9418\u6578 C053 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u5206\u9418\u6578 C054 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u5206\u9418\u6578 C055 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u5206\u9418\u6578 C056 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u5206\u9418\u6578 C057 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u5206\u9418\u6578 C058 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u5206\u9418\u6578\u6bd4\u4f8b C059 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u5206\u9418\u6578\u6bd4\u4f8b C060 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u5206\u9418\u6578\u6bd4\u4f8b\n",
      "\n",
      "C061 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u5206\u9418\u6578\u6bd4\u4f8b C062 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u5206\u9418\u6578\u6bd4\u4f8b C063 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u52a0\u503c\u5206\u9418\u6578\u6bd4\u4f8b C064 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u5206\u9418\u6578\u6bd4\u4f8b C065 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u5206\u9418\u6578\u6bd4\u4f8b C066 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u5206\u9418\u6578\u6bd4\u4f8b C067 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u5206\u9418\u6578\u6bd4\u4f8b C068 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb500_02 C069 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb502_04 C070 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb504_06\n",
      "\n",
      "C071 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb506_08 C072 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb508_10 C073 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb510_12 C074 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb512_14 C075 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb514_16 C076 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb516_18 C077 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb518_20 C078 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb520_22 C079 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb522_24 C080 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb500_02\u6bd4\u4f8b\n",
      "\n",
      "C081 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb502_04\u6bd4\u4f8b C082 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb504_06\u6bd4\u4f8b C083 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb506_08\u6bd4\u4f8b C084 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb508_10\u6bd4\u4f8b C085 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb510_12\u6bd4\u4f8b C086 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb512_14\u6bd4\u4f8b C087 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb514_16\u6bd4\u4f8b C088 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb516_18\u6bd4\u4f8b C089 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb518_20\u6bd4\u4f8b C090 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb520_22\u6bd4\u4f8b\n",
      "\n",
      "C091 [\u884c\u52d5]\u8a9e\u97f3\u5e73\u5747\u767c\u8a71\u5206\u9418\u6578\u6642\u6bb522_24\u6bd4\u4f8b C092 [\u884c\u52d5]\u5c45\u4f4f\u5730\u57ce\u5e02 C093 [\u884c\u52d5]\u5c45\u4f4f\u5730\u884c\u653f\u5340 C094 [\u884c\u52d5]\u5de5\u4f5c\u5730\u57ce\u5e02 C095 [\u884c\u52d5]\u5de5\u4f5c\u5730\u884c\u653f\u5340 C096 [\u884c\u52d5]\u66f4\u63db\u5c45\u4f4f\u5730 C097 [\u884c\u52d5]\u66f4\u63db\u4e0a\u73ed\u5730 C098 [\u884c\u52d5]\u5e73\u65e5\u5916\u5bbf\u5929\u6578 C099 [\u884c\u52d5]\u9031\u672b\u5916\u5bbf\u5929\u6578 C100 [\u884c\u52d5]\u5e73\u65e5\u5c45\u5bb6\u6642\u9593\n",
      "\n",
      "C101 [\u884c\u52d5]\u5047\u65e5\u5c45\u5bb6\u6642\u9593 C102 [\u884c\u52d5]\u5e73\u65e5\u79fb\u52d5\u8ddd\u96e2sumKM C103 [\u884c\u52d5]\u9031\u672b\u79fb\u52d5\u8ddd\u96e2sumKM C104 [\u884c\u52d5]\u5e73\u65e5\u79fb\u52d5\u6700\u9060\u8ddd\u96e2maxKM C105 [\u884c\u52d5]\u9031\u672b\u79fb\u52d5\u6700\u9060\u8ddd\u96e2maxKM C106 [\u884c\u52d5]\u901a\u52e4\u8ddd\u96e2 C107 [\u884c\u52d5]\u79d1\u6280\u5712\u5340 C108 [\u884c\u52d5]\u5047\u65e5\u642d\u4e58\u9ad8\u9435\u6b21\u6578 C109 [\u884c\u52d5]\u5e73\u65e5\u642d\u4e58\u9ad8\u9435\u6b21\u6578 C110 [\u884c\u52d5]\u5728\u570b\u5916\u7684\u5929\u6578\n",
      "\n",
      "C111 [\u884c\u52d5]\u4f4d\u65bc\u767e\u8ca8\u516c\u53f8\u7684\u5929\u6578 C112 [\u884c\u52d5]\u4f4d\u65bc\u8cfc\u7269\u4e2d\u5fc3\u7684\u5929\u6578 C113 [\u884c\u52d5]\u4f4d\u65bc\u751f\u6d3b\u91cf\u8ca9\u7684\u5929\u6578 C114 [\u884c\u52d5]\u4f4d\u65bc\u50a2\u98fe\u91cf\u8ca9\u7684\u5929\u6578 C115 [\u884c\u52d5]\u4f4d\u65bc\u65c5\u904a\u666f\u9ede\u7684\u5929\u6578 C116 [\u884c\u52d5]\u4f4d\u65bc\u96fb\u5f71\u9662\u7684\u5929\u6578 C117 [\u884c\u52d5]\u4f4d\u65bc\u5c55\u6f14\u7684\u5929\u6578 C118 [\u884c\u52d5]\u4f4d\u65bc\u9ad4\u80b2\u9928/\u5834\u7684\u5929\u6578 C119 [\u884c\u52d5]\u4f4d\u65bc\u706b\u8eca/\u9ad8\u9435\u7ad9\u7684\u5929\u6578 C120 [\u884c\u52d5]\u4f4d\u65bc\u91ab\u7642\u4fdd\u5065\u7684\u5929\u6578\n",
      "\n",
      "C121 [\u884c\u52d5]\u4f4d\u65bc\u6baf\u846c\u7684\u5929\u6578 C122 [\u884c\u52d5]\u4f4d\u65bc\u9ad8\u723e\u592b\u7403\u5834\u7684\u5929\u6578 C123 [\u884c\u52d5]\u5047\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C124 [\u884c\u52d5]\u5047\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C125 [\u884c\u52d5]\u5047\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C126 [\u884c\u52d5]\u5047\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C127 [\u884c\u52d5]\u5047\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C128 [\u884c\u52d5]\u5047\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C129 [\u884c\u52d5]\u5047\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C130 [\u884c\u52d5]\u5047\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00)\n",
      "\n",
      "C131 [\u884c\u52d5]\u5047\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C132 [\u884c\u52d5]\u5047\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C133 [\u884c\u52d5]\u5047\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C134 [\u884c\u52d5]\u5047\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C135 [\u884c\u52d5]\u5e73\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C136 [\u884c\u52d5]\u5e73\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C137 [\u884c\u52d5]\u5e73\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C138 [\u884c\u52d5]\u5e73\u65e5\u5728\u5bb6\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C139 [\u884c\u52d5]\u5e73\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C140 [\u884c\u52d5]\u5e73\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00)\n",
      "\n",
      "C141 [\u884c\u52d5]\u5e73\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C142 [\u884c\u52d5]\u5e73\u65e5\u5728\u5916\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C143 [\u884c\u52d5]\u5e73\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(0:00~6:00) C144 [\u884c\u52d5]\u5e73\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(6:00~12:00) C145 [\u884c\u52d5]\u5e73\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(12:00~18:00) C146 [\u884c\u52d5]\u5e73\u65e5\u5728\u8fa6\u516c\u5730\u884c\u52d5\u4e0a\u7db2\u91cf(18:00~24:00) C147 [\u884c\u52d5]\u8a9e\u97f3\u901a\u8a71\u5206\u9418\u6578 C148 [\u884c\u52d5]\u4e2d\u83ef\u884c\u52d5\u901a\u8a71\u5206\u9418\u6578 C149 [\u884c\u52d5]\u975e\u4e2d\u83ef\u884c\u52d5\u901a\u8a71\u5206\u9418\u6578 C150 [\u884c\u52d5]\u5e02\u8a71\u901a\u8a71\u5206\u9418\u6578\n",
      "\n",
      "C151 [\u884c\u52d5]\u4e2d\u83ef\u5e02\u8a71\u901a\u8a71\u5206\u9418\u6578 C152 [\u884c\u52d5]\u975e\u4e2d\u83ef\u5e02\u8a71\u901a\u8a71\u5206\u9418\u6578 C153 [\u884c\u52d5]\u570b\u969b\u901a\u8a71\u5206\u9418\u6578 C154 [\u884c\u52d5]\u6700\u5e38\u767c\u8a71\u884c\u52d5\u96fb\u4fe1\u696d\u8005\u5206\u9418\u6578 C155 [\u884c\u52d5]\u8a9e\u97f3\u901a\u8a71\u901a\u6578 C156 [\u884c\u52d5]\u4e2d\u83ef\u884c\u52d5\u901a\u8a71\u901a\u6578 C157 [\u884c\u52d5]\u975e\u4e2d\u83ef\u884c\u52d5\u901a\u8a71\u901a\u6578 C158 [\u884c\u52d5]\u5e02\u8a71\u901a\u8a71\u901a\u6578 C159 [\u884c\u52d5]\u4e2d\u83ef\u5e02\u8a71\u901a\u8a71\u901a\u6578 C160 [\u884c\u52d5]\u975e\u4e2d\u83ef\u5e02\u8a71\u901a\u8a71\u901a\u6578\n",
      "\n",
      "C161 [\u884c\u52d5]\u570b\u969b\u901a\u8a71\u901a\u6578 C162 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7e3d\u5c0d\u8c61\u6578 C163 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u5c0d\u8c61\u6578 C164 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u5c0d\u8c61\u6578 C165 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u5c0d\u8c61\u6578 C166 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u5c0d\u8c61\u6578 C167 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u5c0d\u8c61\u6578 C168 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u5c0d\u8c61\u6578 C169 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u5c0d\u8c61\u6578 C170 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u5c0d\u8c61\u6578\n",
      "\n",
      "C171 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u5c0d\u8c61\u6578 C172 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u5c0d\u8c61\u6578\u6bd4\u4f8b C173 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u5c0d\u8c61\u6578\u6bd4\u4f8b C174 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u5c0d\u8c61\u6578\u6bd4\u4f8b C175 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u5c0d\u8c61\u6578\u6bd4\u4f8b C176 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u5c0d\u8c61\u6578\u6bd4\u4f8b C177 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u52a0\u503c\u5c0d\u8c61\u6578\u6bd4\u4f8b C178 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u5c0d\u8c61\u6578\u6bd4\u4f8b C179 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u5c0d\u8c61\u6578\u6bd4\u4f8b C180 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u5c0d\u8c61\u6578\u6bd4\u4f8b\n",
      "\n",
      "C181 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u5c0d\u8c61\u6578\u6bd4\u4f8b C182 [\u884c\u52d5]\u767c\u8a71\u5c0d\u8c61\u6578 C183 [\u884c\u52d5]\u4e2d\u83ef\u884c\u52d5\u767c\u8a71\u5c0d\u8c61\u6578 C184 [\u884c\u52d5]\u975e\u4e2d\u83ef\u884c\u52d5\u767c\u8a71\u5c0d\u8c61\u6578 C185 [\u884c\u52d5]\u5e02\u8a71\u767c\u8a71\u5c0d\u8c61\u6578\n",
      "C186 [\u884c\u52d5]\u570b\u969b\u767c\u8a71\u5c0d\u8c61\u6578 C187 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7e3d\u5206\u9418\u6578 C188 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5167\u5206\u9418\u6578 C189 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5916\u5206\u9418\u6578 C190 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u5e02\u8a71\u5206\u9418\u6578\n",
      "\n",
      "C191 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5167\u5206\u9418\u6578\u6bd4\u4f8b C192 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5916\u5206\u9418\u6578\u6bd4\u4f8b C193 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u5e02\u8a71\u5206\u9418\u6578\u6bd4\u4f8b C194 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7e3d\u6b21\u6578 C195 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5167\u6b21\u6578 C196 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u71b1\u7dda\u6b21\u6578 C197 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7db2\u5916\u6b21\u6578 C198 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u5e02\u8a71\u6b21\u6578 C199 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u570b\u969b\u6b21\u6578 C200 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dA\u6b21\u6578\n",
      "\n",
      "C201 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dB\u6b21\u6578 C202 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dC\u6b21\u6578 C203 [\u884c\u52d5]\u8a9e\u97f3\u767c\u8a71\u7af6\u696dD\u6b21\u6578 C204 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7e3d\u6b21\u6578 C205 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5167\u6b21\u6578 C206 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u7db2\u5916\u6b21\u6578 C207 [\u884c\u52d5]\u8a9e\u97f3\u53d7\u8a71\u5e02\u8a71\u6b21\u6578 C208 [\u884c\u52d5]\u6700\u5e38\u767c\u8a71\u96fb\u4fe1\u696d\u8005 C209 [\u884c\u52d5]\u66fe\u7d93\u767c\u8a71\u57fa\u7ad9\u6578 C210 [\u884c\u52d5]\u6279\u50f9\u7c21\u8a0a\u6b21\u6578\n",
      "\n",
      "C211 [\u884c\u52d5]\u6279\u50f9\u6578\u64da\u9023\u7dda\u6b21\u6578 C212 [\u884c\u52d5]\u6578\u64da\u4e0a\u50b3MB C213 [\u884c\u52d5]\u6578\u64da\u4e0a\u50b3MB\u6bd4\u4f8b C214 [\u884c\u52d5]\u884c\u52d5\u6578\u64da\u6b21\u6578 C215 [\u884c\u52d5]\u884c\u52d5\u6578\u64da\u6d41\u91cf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('../../df_650.txt', encoding='utf-8', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}